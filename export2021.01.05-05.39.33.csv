Document Title,中文標題,Authors,Author Affiliations,Publication Title,Date Added To Xplore,Publication Year,Volume,Issue,Start Page,End Page,Abstract,ISSN,ISBNs,DOI,Funding Information,PDF Link,Author Keywords,IEEE Terms,INSPEC Controlled Terms,INSPEC Non-Controlled Terms,Mesh_Terms,Article Citation Count,Patent Citation Count,Reference Count,License,Online Date,Issue Date,Meeting Date,Publisher,Document Identifier
Research and improvement of feature words weight based on TFIDF algorithm,基於TFIDF算法的特徵詞重量的研究與改進,A. Guo; T. Yang,"Qilu University of Technology, Jinan 250353, China; Qilu University of Technology, Jinan 250353, China","2016 IEEE Information Technology, Networking, Electronic and Automation Control Conference",5-Sep-16,2016,,,415,419,"With the development of cloud era, more and more people have been attracted by Big data. More and more applications involve large data. Analysis methods of large data is particularly important. This paper mainly analyzes and research feature words weight which are used in unstructured data classification of big data. Firstly, we combine the traditional feature words weight calculation method and analyze the shortcoming of traditional TF-IDF algorithm, It doesn't think about feature words distribution. It can lead that some feature words weight which don't have strong discrimination have heavier weight. Aiming at the shortage of TFIDF algorithm, combining with practical effect to text classification, this paper modify traditional TFIDF algorithm formula, excluding the inner impact to disturb characteristic, adding the concept of intra-class dispersion, presenting a new TFIDF algorithm. In the experiment, experimental data comes from People news about the financial, military, entertainment and sports four categories, respectively calculating test value by using the traditional TFIDF algorithm and improved TFIDF algorithm. Results show that improved TFIDF algorithm has higher accuracy than traditional TFIDF algorithms.",,978-1-4673-9194-8,10.1109/ITNEC.2016.7560393,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7560393,TFIDF algorithm;Text classification;Feature selection;Feature weighting,Classification algorithms;Algorithm design and analysis;Text categorization;Dispersion;Documentation;Big data;Entropy,Big Data;cloud computing;data analysis;natural language processing;pattern classification;text analysis,TFIDF algorithm;Big Data;cloud computing;data analysis methods;unstructured data classification;feature word weight calculation method;feature word distribution;text classification;intra-class dispersion,,16,,12,,5-Sep-16,,,IEEE,IEEE Conferences
Improved TFIDF weighting techniques in document Retrieval,改進了文檔檢索中的TFIDF加權技術,F. Yamout; R. Lakkis,"Computer Science, Lebanese International University, Beirut, Lebanon; Computer Science, Lebanese International University, Beirut, Lebanon",2018 Thirteenth International Conference on Digital Information Management (ICDIM),26-Sep-19,2018,,,69,73,"In information retrieval, documents are usually retrieved using lexical matching which matches where words in a user's query with words found in a set of documents. A significant model used in information retrieval is the vector space model where these words are represented as a vector in space and are assigned weights using a favorite weighting technique called TFIDF (Term Frequency Inverse Document Frequency). In this thesis, we have devised three new weighting techniques to improve the TFIDF weighting technique. The first technique is Dispersed Words Weight Augmentation (DWWA) which gives more weight to the words distributed in most of the document's paragraphs; we consider that those words are more significant than words found in few paragraphs. The second technique is called Title Weight Augmentation (TWA) which gives more weight to the words found in the document's title and first paragraphs. The third technique is called First Ranked Words Weight Augmentation (FRWWA) which increments further the weight of the most frequent words in a document. We tested the three techniques, and we found more relevant documents were retrieved in our system.",,978-1-5386-5244-2,10.1109/ICDIM.2018.8847156,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8847156,Information Retrieval;TFIDF;Precision-recall,Testing;Search engines;Mathematical model;Computer science;Computational modeling;Organizations,information retrieval;pattern matching;text analysis;vectors,TFIDF weighting technique;Title Weight Augmentation;First Ranked Words Weight Augmentation;document retrieval;information retrieval;vector space model;Term Frequency Inverse Document Frequency;lexical matching;FRWWA weighting technique,,1,,11,,26-Sep-19,,,IEEE,IEEE Conferences
Text clustering based on the improved TFIDF by the iterative algorithm,基於迭代算法的改進TFIDF的文本聚類,Xingheng Wang; Jun Cao; Yao Liu; Shi Gao; Xue Deng,"School of Information Science and Technology, East China Normal University, Shanghai, China; Shanghai International Studies, University Library, China; School of Information Science and Technology, East China Normal University, Shanghai, China; School of Information Science and Technology, East China Normal University, Shanghai, China; School of Information Science and Technology, East China Normal University, Shanghai, China",2012 IEEE Symposium on Electrical & Electronics Engineering (EEESYM),6-Aug-12,2012,,,140,143,"Text clustering, an important part of the machine learning and pattern recognition, has extensive applications in the field of natural language processing. In this paper, a method is given to improve the classic TFIDF algorithm on its shortcomings. This paper classifies the text through Naive Bayesian classifier. And uses the iterative algorithm to optimize the selection of feature words, and then to optimize the classification ceaselessly. Experimental results show that the algorithm has preferable efficiency in feature-select and can increase classification accuracy.",,978-1-4673-2365-9,10.1109/EEESym.2012.6258608,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6258608,TFIDF;text clustering;VSM;Naive Bayesian;iterative algorithm,Accuracy;Text categorization;Filtering,iterative methods;learning (artificial intelligence);natural language processing;pattern clustering;text analysis,text clustering;iterative algorithm;improved TFIDF algorithm;machine learning;pattern recognition;natural language processing;Naive Bayesian classifier;feature words;feature-selection,,7,,5,,6-Aug-12,,,IEEE,IEEE Conferences
An Improved TFIDF Feature Selection Algorithm Based On Information Entropy,一種基於信息熵的改進TFIDF特徵選擇算法,Z. Yantao; T. Jianbo; W. Jiaqin,"College of Electrical and Information Engineering, Hunan University, Changsha 410082, P. R. China; Information and Electrical Engineering College, Naval Engineering University, Wuhan 430033, P. R. China. E-mail: yantao_z@hnu.cn; College of Electrical and Information Engineering, Hunan University, Changsha 410082, P. R. China; College of Electrical and Information Engineering, Hunan University, Changsha 410082, P. R. China",2007 Chinese Control Conference,15-Oct-07,2007,,,312,315,"The quality of text feature selection affects the accuracy of text categorization greatly. Due to the deficiency of traditional TFIDF without considering the distribution of feature words among classes, the paper analyzed the TFIDF feature selection algorithm, and proposed a new TFIDF feature selection method with concept of information entropy. Experimental results show the method is valid in improving the accuracy of text categorization.",1934-1768,978-7-81124-055-9,10.1109/CHICC.2006.4346845,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4346845,words information entropy;feature selection;TFIDF;data mining,Information entropy;Frequency;Educational institutions;Text categorization;Information analysis;Algorithm design and analysis;Data mining;Mutual information,data mining;text analysis,feature selection algorithm;information entropy;text feature selection;text categorization;data mining,,1,,12,,15-Oct-07,,,IEEE,IEEE Conferences
Improvement of Text Feature Selection Method Based on TFIDF,基於TFIDF的文本特徵選擇方法的改進,S. Qu; S. Wang; Y. Zou,"Sch. of Inf. Sci. & Eng., Univ. of Jinan, Jinan; Sch. of Inf. Sci. & Eng., Univ. of Jinan, Jinan; Sch. of Inf. Sci. & Eng., Univ. of Jinan, Jinan",2008 International Seminar on Future Information Technology and Management Engineering,9-Jan-09,2008,,,79,81,"TFIDF is a kind of common methods used to select the text feature, but it has many disadvantages. First, the method undervalues that this term can represent the characteristic of the documents of this class if it only frequently appears in the documents belongs to the same class while infrequently in the documents of the other class. Second TFIDF neglects the relations between the feature and the class. The paper proposed the improved TFIDF strategy, and combined with the text classification method of simple distance vector to compare to traditional TFIDF, and obtained the very good classified effect, the experiment proved its feasibility.",,978-0-7695-3480-0,10.1109/FITME.2008.25,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4746446,,Text categorization;Vocabulary;Frequency;Information management;Aggregates;Communications technology;Seminars;Information technology;Technology management;Engineering management,pattern classification;text analysis;vectors,text feature selection method;TFIDF;text classification method;distance vector,,18,,4,,9-Jan-09,,,IEEE,IEEE Conferences
A Text Feature Selection Algorithm Based on Improved TFIDF,基於改進TFIDF的文本特徵選擇算法,C. Yang; X. He,"Xi'an Polytech. Univ., Xi'an; Xi'an Polytech. Univ., Xi'an",2008 Chinese Conference on Pattern Recognition,31-Oct-08,2008,,,1,4,"In Chinese text categorization system, for most classifiers using vector space model (VSM), all attributes of documents construct a high dimensional feature space. And the high dimensionality of feature space is the bottleneck of categorization. TFIDF is a kind of common methods used to measure the terms in a document. The method is easy but it doesn't consider the unbalance distribution of terms among classes. This paper analyzed the TFIDF feature selection algorithm deeply, and proposed a new TFIDF feature selection method based on Gini index theory. Experimental results show the method is valid in improving the accuracy of text categorization.",,978-1-4244-2316-3,10.1109/CCPR.2008.87,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4663040,,Text categorization;Electronic mail;Frequency;Helium;Algorithm design and analysis;Entropy;Mutual information,natural language processing;text analysis,text feature selection algorithm;Chinese text categorization system;vector space model;TFIDF feature selection method;Gini index theory,,1,,8,,31-Oct-08,,,IEEE,IEEE Conferences
A Feature Selection Method based on Improved TFIDF,基於改進TFIDF的特徵選擇方法,W. Yong-qing; L. Pei-yu; Z. Zhen-fang,"Shandong Police college, Shandong Ji'Nan 250014, China. weiyongqing@sdpc.edu.cn; Shandong Normal University, Shandong Ji'Nan 250014, China. liupy@sdnu.edu.cn; Shandong Normal University, Shandong Ji'Nan 250014, China. zhuzhfyt@163.com",2008 Third International Conference on Pervasive Computing and Applications,13-Feb-09,2008,1,,94,97,"Feature selection is a valid method to reduce the dimension of vector in text categorization system. After analyzed several common evaluation functions for feature selection, we applied terms weight function to feature selection. A new evaluation function based on improved TFIDF method is presented; in this function the category information is introduced to feature items, and the feature items of relevant categories are selected to make up the shortcomings of the TFIDF. Experiments proved that the method is simple and feasible. It's advantageous in improving the efficiency of the selected feature subset.",,978-1-4244-2020-9,10.1109/ICPCA.2008.4783657,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4783657,,Frequency;Space technology;Text categorization;Feature extraction;Mutual information;Educational institutions;Computational complexity;Large-scale systems;Statistics;IP networks,feature extraction;text analysis;word processing,feature selection method;TFIDF;feature selection;text categorization system;evaluation function;feature subset,,2,,6,,13-Feb-09,,,IEEE,IEEE Conferences
Improved feature selection approach TFIDF in text mining,文本挖掘中改進的特徵選擇方法TFIDF,Li-Ping Jing; Hou-Kuan Huang; Hong-Bo Shi,"Sch. of Comput. & Inf. Technol., Northern JiaoTong Univ., Beijing, China; Sch. of Comput. & Inf. Technol., Northern JiaoTong Univ., Beijing, China; Sch. of Comput. & Inf. Technol., Northern JiaoTong Univ., Beijing, China",Proceedings. International Conference on Machine Learning and Cybernetics,19-Feb-03,2002,2,,944,946 vol.2,"This paper describes the feature selection method TFIDF (term frequency, inverse document frequency). With it, we process the data resource and set up the vector space model in order to provide a convenient data structure for text categorization. We calculate the precision of this method with the help of categorization results. According to the empirical results, we analyze its advantages and disadvantages and present a new TFIDF-based feature selection approach to improve its accuracy.",,0-7803-7508-4,10.1109/ICMLC.2002.1174522,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1174522,,Text mining;Frequency;Data mining;Text categorization;Data preprocessing;Indexing;Data structures;Learning systems;Classification algorithms;Mutual information,data mining;data structures;classification;indexing;feature extraction,term frequency;evaluation function;data structure;text categorization;vector space model;classification;TFIDF method;feature selection;text mining;inverse document frequency,,46,,8,,19-Feb-03,,,IEEE,IEEE Conferences
An Improved TFIDF Algorithm Based on Dual Parallel Adaptive Computing Model,基於雙並行自適應計算模型的改進TFIDF算法,Y. Gu; Y. Wang; J. Huan; Y. Sun; W. Jia,"ChangZhou University, School of Information Science & Engineering, Changzhou, China; ChangZhou University, School of Information Science & Engineering, Changzhou, China; ChangZhou University, School of Information Science & Engineering, Changzhou, China; ChangZhou University, School of Information Science & Engineering, Changzhou, China; Shandong Normal University, School of Information Science and Engineering, Shandong, China","2018 IEEE International Conference on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData)",3-Jun-19,2018,,,657,663,"The double parallel cloud computing framework based on GPU (Graphics Processing Unit) and MapReduce is proposed, which aims at the low efficiency for the large data sets on the stand-alone by text classification algorithm, constructs the adaptive computation process of double parallel computing and combines the advantage of improved TFIDF (term frequency-inverse document frequency) algorithm, and improves TFIDF text categorization algorithm with double parallel adaptive computing. In different operating environments, the efficiency of improved TFIDF algorithm will be compared with different computing nodes. The result shows that massive data can be processed effectively in high speed by improved TFIDF algorithm which adopts double parallel adaptive computing. With the number of nodes increasing, the algorithm execution efficiency with double parallel adaptive computing is getting more and more effective.",,978-1-5386-7975-3,10.1109/Cybermatics_2018.2018.00133,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8726798,Improved TFIDF Algorithm;MapReduce;GPU;Parallel Computation,Graphics processing units;Parallel processing;Task analysis;Computational modeling;Classification algorithms;Adaptation models;Instruction sets,cloud computing;graphics processing units;parallel processing;pattern classification;text analysis,text categorization algorithm;computing nodes;operating environments;double parallel computing;adaptive computation process;text classification algorithm;double parallel cloud;dual parallel adaptive computing model;algorithm execution efficiency;double parallel adaptive computing;term frequency-inverse document frequency;improved TFIDF algorithm,,1,,24,,3-Jun-19,,,IEEE,IEEE Conferences
A Image Retrieval Method Using TFIDF Based Weighting Scheme,基於TFIDF的加權方案的圖像檢索方法,Y. Suzuki; M. Mitsukawa; K. Kawagoe,"Coll. of Inf. Sci. & Technol., Ritsumeikan Univ., Kyoto; NA; NA",2008 19th International Workshop on Database and Expert Systems Applications,12-Sep-08,2008,,,112,116,"In this paper, we propose a retrieval method using textual information retrieval techniques, such as vector space model, for images. Many image retrieval systems are proposed. However, these systems are mainly based on pattern recognition techniques. Therefore, the features of images are also based on these recognition techniques, such as color histogram, and shape of the object in images. Generally, these systems do not consider weight of features, which means how important these features are, which are generally used in textual information retrieval systems. In this paper, we propose a method considering weight, such as TFIDF, to identify the importance degree of features. Using our proposed method, the system can retrieve intuitively similar retrieval target images to user's query images.",2378-3915,978-0-7695-3299-8,10.1109/DEXA.2008.106,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4624701,Content Based Information Retrieval;Image;Retrieval,Pixel;Feature extraction;Distance measurement;Image color analysis;Image retrieval;Earth;Zinc,image colour analysis;image recognition;image retrieval;text analysis;vectors,image retrieval method;TFIDF;weighting scheme;textual information retrieval techniques;vector space model;pattern recognition;color histogram;image querying,,6,,5,,12-Sep-08,,,IEEE,IEEE Conferences
Matching images with textual document using TFIDF method,使用TFIDF方法將圖像與文本文檔匹配,P. D. Arnesia; S. Madenda,"Information System Department, Gunadarma University, Depok, Indonesia; Information Technology Department, STMIK Jakarta STI&K, Jakarta, Indonesia",2012 5th International Congress on Image and Signal Processing,25-Feb-13,2012,,,1283,1289,"Image is used in any field, starting from newspapers, magazines, web sites, movie posters, up to scientific researches to enhance the story effects of the images. Editors, journalists, brochure illustrators, taxonomists in biological science, DNA research scientists, star classifying astronomers rely heavily on images appropriate with the accompanying texts. Sometimes the images themselves are more important than the accompanying texts. Then it is very important to find the best images to illustrate the text. This research consists of two stages, namely database forming stage and text-based image retrieval stage. As a tool to build a database for keywords or texts or documents annotated images, MIRA (Multimedia Information Retrieval Application) is employed. An application of TFIDF algorithm into MIRA is used to determine the weight of a term or word in a text or document that annotates an image and then compared to keywords extracted from a text or document. In this study, we compared the results of image search using Google search engine with our system, MIRA. Based on the results of text-based image retrieval using keyterm, it can be concluded that image search is successfully distributed. The developed system which is textbased image retrieval is capable of image searching which suit the hopes with optimal results.",,978-1-4673-0964-6,10.1109/CISP.2012.6469720,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6469720,Keyword;keyterm;TFIDF,Image retrieval;Google;Information retrieval;Frequency measurement;Multimedia communication;Image color analysis,content-based retrieval;document image processing;image matching;image retrieval;multimedia systems;search engines,image searching;keyterm;Google search engine;multimedia information retrieval application;MIRA;text-based image retrieval stage;database forming stage;TFIDF method;textual document;image matching,,1,,17,,25-Feb-13,,,IEEE,IEEE Conferences
Study for FAQ Processing in Internet Automatic Sales System,互聯網自動銷售系統常見問題處理研究,Z. Pu; B. Wang; L. Yang,NA; NA; NA,2010 International Forum on Information Technology and Applications,11-Nov-10,2010,2,,234,236,"Internet Automatic Sales System is be used to assist people in net business. Since part of the talking continent in purchasing is always asked frequently, so the statistic method like TFIDF is applied to deal this issue. Based on the experiment situation, baseline system based on TFIDF achieved very good effect. But the classic algorithm is not enough to reach real application requirement, the Dice method is introduced here. By using ANN linear regression, the coefficient between TFIDF and Dice has been gotten, and the new sentence similarity calculating algorithm improves the baseline system's performance. This paper just aimed at special field and used limited size of corpora. So FAQ (Frequently Asked Questions) is just one part of sales process QA (Question Answering) and other fields need more analysis and research in the future.",,978-1-4244-7622-0,10.1109/IFITA.2010.346,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5634836,Automatic Sales System;TFIDF;Dice;ANN;FAQ,Marketing and sales;Artificial neural networks;Internet;Databases;Linear regression;Computational modeling;Testing,Internet;neural nets;query processing;regression analysis;sales management,frequently asked questions processing;Internet automatic sales system;statistic method;TFIDF;Dice method;ANN linear regression;sentence similarity calculating algorithm;baseline system performance;question answering,,,,8,,11-Nov-10,,,IEEE,IEEE Conferences
Efficiency of TR-Classifier versus TFIDF,TR分類器與TFIDF的效率,M. Abbas; K. Sma簿li; D. Berkani,"Speech Process. Lab., crstdla, Algiers, Algeria; Parole Team, Inria-Loria, Nancy, France; Signal & Commun. Lab., Nat. Polytech. Sch., Algiers, Algeria",2010 First International Conference on Integrated Intelligent Computing,16-Sep-10,2010,,,233,237,"In this paper, we present a method of topic identification based on computing triggers pairs: TR-classifier (Triggers-based classifier). Indeed, it is used for the purpose to identify topics of texts. Hence, the first step to be realized is the construction of a vocabulary for each topic. Topic vocabularies are composed of words ranked according to their frequencies from the maximum to the minimum. We note that the size of each topic vocabulary is 400. For each word of the vocabulary, average mutual information (AMI) is calculated. The used triggers are selected according to the highest AMI values. In order to evaluate the TR Classifier, we compared it to the well-known TFIDF.",,978-1-4244-7963-4,10.1109/ICIIC.2010.60,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5571449,,Vocabulary;History;Mutual information;Adaptation model;Educational institutions;Speech;Computers,classification;text analysis;vocabulary,topic identification;triggers pairs;TR-classifier;triggers-based classifier;text topic;topic vocabulary;average mutual information,,,,20,,16-Sep-10,,,IEEE,IEEE Conferences
An Empirical Study on the Classification of Chinese News Articles by Machine Learning and Deep Learning Techniques,機器學習和深度學習技術對中國新聞文章分類的實證研究,C. Huang; Y. Jiang,"National Yunlin University of Science and Technology,Department of Information Management,Taiwan, R.O.C.; National Yunlin University of Science and Technology,Department of Information Management,Taiwan, R.O.C.",2019 International Conference on Machine Learning and Cybernetics (ICMLC),6-Jan-20,2019,,,1,6,"This study compares Chinese news classification results of machine learning (ML) and deep learning (DL). In processing ML, we chose Support Vector Machine (SVM) and Naive Bayes (NB) to form three models: Word2Vec-SVM, TFIDF-SVM, and TFIDF-NB. Since NB assumes that the words are independent, this is different from the concept of related word distribution in Word2Vec, so the combination with NB is excluded. In processing DL, we adopted Bidirectional Long Short-Term Memory (Bi-LSTM), Long Short-Term Memory (LSTM) and Convolutional Neural Network (CNN), and used Word2Vec for word embedding. Experimental results showed that with proper word preprocessing, the difference of classification accuracy of ML and DL models is actually very small. Although the results show that Bi-LSTM performs the most accurate and has the lowest Loss compared to other DL techniques, its implementation process is the most time consuming. This study affirms the excellent results of CNN, while its Loss is the highest of the DL models. We also found that Word2Vec-SVM was superior to TFIDF-SVM in terms of efficiency, but its accuracy is not as good as expected. To summarize the classification accuracy in Bi-LSTM, LSTM, CNN, Word2vec-SVM, TFIDF-SVM, and NB are 89.3%, 88%, and 87.54%, 85.32%, 87.35%, 86.56%, respectively.",2160-1348,978-1-7281-2816-0,10.1109/ICMLC48188.2019.8949309,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8949309,Machine learning;Deep learning;TFIDF;Word2Vec;News classification,,Bayes methods;convolutional neural nets;learning (artificial intelligence);natural language processing;pattern classification;support vector machines;text analysis,convolutional neural network;Bidirectional Long Short-Term Memory;related word distribution;TFIDF-NB;ML;Chinese news classification results;deep learning techniques;Machine learning;Chinese news articles;TFIDF-SVM;Word2Vec-SVM;classification accuracy;word preprocessing;word embedding;Bi-LSTM,,,,14,,6-Jan-20,,,IEEE,IEEE Conferences
Technology Research of Tibetan Hot Topics Extraction,藏族熱點話題提取技術研究,G. Xu; L. Qiu,"Sch. of Inf. Eng., Minzu Univ. of China, Beijing, China; Sch. of Inf. Eng., Minzu Univ. of China, Beijing, China",2015 IEEE 29th International Conference on Advanced Information Networking and Applications Workshops,30-Apr-15,2015,,,204,208,"With the increase of a large numbers of Tibetan information, Tibetan text processing has become popular and important. Tibetan hot topics extraction has become one of the Tibetan information analysis tools. This paper describes a method of the hot topics extraction from Tibetan text. First, construction of the dataset is described. Second, Tibetan word segmentation is presented. Third, the feature selection and the text representation are conducted. The classical TFIDF is used to calculate the weights of features. At last, statistical-based method is utilized to extract the hot topics. The experiment shows it can extract the topics effectively and the results can reflect the characteristics of hot topic category. It is helpful and meaningful for text classification, information retrieval as well as construction of high-quality corpus.",,978-1-4799-1775-4,10.1109/WAINA.2015.17,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7096173,tibetan information processing;hot topic extraction;feature selection;TFIDF weighting calculation,Feature extraction;XML;Text categorization;Information retrieval;Information processing;Monitoring,feature selection;information retrieval;linguistics;natural language processing;pattern classification;statistical analysis;text analysis;word processing,Tibetan hot topic extraction;high-quality corpus;information retrieval;text classification;statistical-based method;TFIDF;text representation;feature selection;Tibetan word segmentation;Tibetan information analysis tools;Tibetan text processing,,,,16,,30-Apr-15,,,IEEE,IEEE Conferences
Text categorization based on improved Rocchio algorithm,基於改進的Rocchio算法的文本分類,G. Gao; S. Guan,"Department of Automation, University of Science and Technology of China, Hefei, China; Department of Automation, University of Science and Technology of China, Hefei, China",2012 International Conference on Systems and Informatics (ICSAI2012),25-Jun-12,2012,,,2247,2250,"Text categorization is used to assign each text document to predefined categories. This paper presents a new text classification method for classifying Chinese text based on Rocchio algorithm. We firstly use the TFIDF to extract document vectors from the training documents which have been correctly categorized, and then use those document vectors to generate codebooks as classification models using the LBG and Rocchio algorithm. The codebook is then used to categorize the target documents using vector scores. We tested this method in the experiment and the result shows that this method can achieve better performance.",,978-1-4673-0199-2,10.1109/ICSAI.2012.6223499,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6223499,TFIDF;Text Categorization;LBG;Rocchio Algorithm,Classification algorithms;Support vector machine classification;Text categorization;Computational modeling;Vectors;Algorithm design and analysis;Training data,natural language processing;text analysis;vectors,text categorization;improved Rocchio algorithm;text document;text classification method;Chinese text;TFIDF;training documents;codebooks;LBG;target documents;vector scores,,5,,5,,25-Jun-12,,,IEEE,IEEE Conferences
Automated Hate Speech Detection on Twitter,Twitter上的自動仇恨語音檢測,G. Koushik; K. Rajeswari; S. K. Muthusamy,"Pimpri Chinchwad College of Engineering,Department of Computer Engineering,Pune,India; Pimpri Chinchwad College of Engineering,Department of Computer Engineering,Pune,India; FCA-ICT Inbound Logistics and Supply Chain,System Technology Group,Michigan,USA","2019 5th International Conference On Computing, Communication, Control And Automation (ICCUBEA)",30-Jun-20,2019,,,1,4,"With the sudden increase in micro-blogging websites such as Twitter, Facebook, and Tumbler, the communication between people becomes indirect and reliable; people from different educational backgrounds, cultures share their opinion on different aspects of life every day. This has resulted in conflicts among people. As a result, the use of hate speech becomes a very serious problem. Manual detection of such content from these websites is a very tedious task. Hate speech is the use of aggressive, violent or offensive language which targets a specific group of people sharing common property, this property can be their gender, ethnic group or their believes and regions. The proposed model is capable to detect hate content on Twitter automatically. This approach is based on a bag of words and TFIDF (term frequency-inverse document frequency) approach. These features are used to train machine learning classifiers. Exhaustive experiments are conducted on existing twitter dataset and the accuracy obtained by logistic regression classifier is equal to 94.11% on detecting whether a particular tweet is hateful or not.",,978-1-7281-4042-1,10.1109/ICCUBEA47591.2019.9128428,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9128428,Bag of Words;TFIDF;Hate Speech,,learning (artificial intelligence);pattern classification;regression analysis;social networking (online);Web sites,hate speech detection;websites;different educational backgrounds;life every day;manual detection;aggressive language;violent language;offensive language;specific group;common property;ethnic group;hate content;TFIDF approach;term frequency-inverse document frequency;existing twitter dataset,,,,12,,30-Jun-20,,,IEEE,IEEE Conferences
Improving classification performance by extending documents terms,通過擴展文檔條款來提高分類性能,Widodo; W. C. Wibowo,"Faculty of Computer Science, University of Indonesia, Jakarta, Indonesia; Faculty of Computer Science, University of Indonesia, Jakarta, Indonesia",2014 International Conference on Data and Software Engineering (ICODSE),19-Mar-15,2014,,,1,5,"Classification is a technique in data mining for categorizing objects. Text Classification is re-challenged for classifying very short documents or text as shown in social media collection. This paper proposes a method to improve the performance of classification on short documents. In this work, we expand words in every document before the documents are classified We use TFIDF model, Hidden Markov Model k-means clustering, and Latent Semantic Indexing (LSI) for expanding documents. The results show that extending document term by just 1 word will increase its accuracy, while extending by 2,4, and 8 words tend to give stable results.",,978-1-4799-7996-7,10.1109/ICODSE.2014.7062657,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7062657,text classification;TFIDF model;Hidden Markov Model k-means;Latent Semantic Indexing;extend words,Accuracy;Hidden Markov models;Bayes methods;Bagging;Text categorization;Semantics,category theory;classification;data mining;hidden Markov models;indexing;pattern clustering;text analysis,documents terms;data mining;object categorization;text classification;TFIDF model;hidden Markov model;k-means clustering;latent semantic indexing;LSI,,1,,15,,19-Mar-15,,,IEEE,IEEE Conferences
"R-tfidf, a Variety of tf-idf Term Weighting Strategy in Document Categorization",R-tfidf，文檔分類中的各種tf-idf術語加權策略,D. Zhu; J. Xiao,"Digital Dialogue Media Pty Ltd., Fremantle, WA, Australia; Sch. of Comput. & Security Sci., Edith Cowan Univ. Mt Lawley, Mt Lawley, WA, Australia","2011 Seventh International Conference on Semantics, Knowledge and Grids",1-Dec-11,2011,,,83,90,"Term weighting strategy plays an essential role in the areas related to text processing such as text categorization and information retrieval. In such systems, term frequency, inverse document frequency, and document length normalization are important factors to be considered when a term weighting strategy is developed. Term length normalization is proposed to give equal opportunities to retrieve both lengthy documents and shorter ones. However, terms in very short documents that may be useless for users, especially in the scenario of Web information retrieval, could be assigned very high weights, resulting in a situation where shorter documents are ranked higher than lengthy documents that are more relevant to users information needs. In this research, a new R-tfidf term weighting strategy is proposed to alleviate the side effects of document length normalization. Experimental results demonstrate the proposed approach can to some extent improve the performance of text categorization.",,978-1-4577-1323-1,10.1109/SKG.2011.44,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6088095,term-weighting;tf-idf;text categorization,Information retrieval;Text categorization;Training;Frequency estimation;Support vector machine classification;Time frequency analysis;Probabilistic logic,information retrieval;text analysis,R-tfidf;term weighting strategy;document categorization;text processing;inverse document frequency;document length normalization;information retrieval,,6,,20,,1-Dec-11,,,IEEE,IEEE Conferences
"TFIDF, LSI and multi-word in information retrieval and text categorization",TFIDF，LSI和多字信息檢索和文本分類,W. Zhang; T. Yoshida; X. Tang,"School of Knowledge Science, Japan Advanced Institute of Science and Technology, 1-1, Ashahidai, Tatsunokuchi, Ishikawa 923-1292, Japan; School of Knowledge Science, Japan Advanced Institute of Science and Technology, 1-1, Ashahidai, Tatsunokuchi, Ishikawa 923-1292, Japan; Institute of Systems Science, Academy of Mathematics and Systems Science, Chinese Academy of Sciences, Beijing 100080, China","2008 IEEE International Conference on Systems, Man and Cybernetics",7-Apr-09,2008,,,108,113,"Text representation, which is a fundamental and necessary process for text-based intelligent information processing, includes the tasks of determining the index terms for documents and producing the numeric vectors corresponding to the documents. In this paper, multi-word, which is regarded as containing more contextual semantics than individual word and possessing the favorable statistical characteristics, is proposed as an alternative index terms in vector space model for text representation with theoretical support. We investigate the traditional indexing methods as TF*IDF (term frequency inverse document frequency) and LSI (latent semantic indexing) for comparative study. The performances of TF*IDF, LSI and multi-word are examined on the tasks of text classification, which includes information retrieval (IR) and text categorization (TC), in Chinese and English document collection respectively. We also attempt to tune the rescaling factor of LSI and observe its effectiveness in text classification. The experimental results demonstrate that TF*IDF and multi-word are comparable when they are used for IR and TC and LSI is the poorest one of them. Moreover, the rescaling factor of LSI has an insignificant influence on its effectiveness on text classification for both Chinese and English text classification.",1062-922X,978-1-4244-2383-5,10.1109/ICSMC.2008.4811259,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4811259,text representation;TF*IDF;LSI;multi-word;text classification,Large scale integration;Information retrieval;Text categorization;Indexing;Frequency;Text mining;Information processing;Context modeling;Mathematics;Data mining,information retrieval;text analysis,TFIDF;LSI;information retrieval;text categorization;text representation;text-based intelligent information processing;contextual semantics;vector space model;traditional indexing methods;term frequency inverse document frequency;latent semantic indexing;rescaling factor;text classification,,18,,22,,7-Apr-09,,,IEEE,IEEE Conferences
Genre Classification using Feature Extraction and Deep Learning Techniques,使用特徵提取和深度學習技術進行體裁分類,A. Kumar; A. Rajpal; D. Rathore,"Department of Computer Science and Engineering, Delhi Technological University, Delhi, India; Computer Science and Engineering, Delhi Technological University, Delhi, India; Computer Science and Engineering, Delhi Technological University, Delhi, India",2018 10th International Conference on Knowledge and Systems Engineering (KSE),13-Dec-18,2018,,,175,180,"Music genre refers to categorisation of music on the basis of interaction between artists, market forces, and culture. It helps to organize music into collections by indicating similarities between compositions or musicians. Automatic genre classification is non-trivial as it is difficult to distinguish between different genres. Many times the boundaries are not clearly defined and genres are overlapping. In this paper we present a novel approach to classify a list of songs present on Spotify into mainly four genres-Christian, Metal, Country, Rap. Two different kinds of data - lyrics and album artwork are used for the classification process. Two Natural Language Processing techniques namely bag-Of-Words and Term Frequency-Inverse Document Frequency (TFIDF) are used to process the lyrical data. We apply machine learning algorithms like Random Forest, Support Vector Machine (SVM), Naive Bayes, Linear Support Vector Classifier (Linear SVC) and eXtreme Gradient Boosting (XGBoost) on lyrical data and Deep Convolutional Neural Network (CNN) on the album artwork to predict the genre. On application of machine learning algorithms on lyrical data obtained from bag-Of-Words a mean precision of 75.96% and a mean f-score of 75.92% is achieved. On application of the same set of algorithms on lyrical data obtained from TFIDF a mean precision of 76.85% and a mean f-score of 77.38% is achieved. In both cases XGBoost outperforms all the other algorithms giving a maximum precision of 79.30% and 80.16% and a maximum f-score of 79.6% and 84.09% for bag-Of-Words and TFIDF respectively. On application of deep neural network on album artwork, a precision of 82.46% and a f-score of 81.84% is achieved.",,978-1-5386-6113-0,10.1109/KSE.2018.8573325,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8573325,Album Artwork;bag-of-Words;Convolutional Neural Network (CNN);Genre Classification;Lyrics;Term Frequency-Inverse Document Frequency (TFIDF),Modeling;Convolutional neural networks;Support vector machines;Music;Art;Knowledge engineering,feature extraction;feedforward neural nets;learning (artificial intelligence);music;natural language processing;pattern classification;support vector machines,feature extraction;music genre;compositions;musicians;automatic genre classification;genres-Christian;album artwork;classification process;bag-Of-Words;TFIDF;mean precision;mean f-score;deep neural network;deep learning techniques;natural language processing techniques;term frequency-inverse document frequency,,,,12,,13-Dec-18,,,IEEE,IEEE Conferences
Analyzing TF-IDF and Word Embedding for Implementing Automation in Job Interview Grading,分析TF-IDF和單詞嵌入以在求職面試評分中實現自動化,A. W. Romadon; K. M. Lhaksmana; I. Kurniawan; D. Richasdy,"Telkom University,School of Computing,Bandung,Indonesia; Telkom University,School of Computing,Bandung,Indonesia; Telkom University,School of Computing,Bandung,Indonesia; Telkom University,School of Computing,Bandung,Indonesia",2020 8th International Conference on Information and Communication Technology (ICoICT),13-Aug-20,2020,,,1,4,"Selecting the best talents from a large number of job applicants is challenging, especially for big companies that usually receive tens of thousands of applicants for every job opening. One of the most costly and time-consuming applicant selection stages is the interview process, since it usually performs face to face meetings and involves third parties to do the interviews and analyze the result. To this end, Human Capital Directorate at Telkom Indonesia adopts AI technology to automate some stages of job applicant selection to reduce manual process and third-party involvement. In this paper, we investigate appropriate feature extraction methods to automate job interview grading for reducing bias and human errors. TFIDF, one of the most popular feature extractions, is compared with word embedding to find the optimal method and parameters in classifying interview verbatims with ANN classifier. Based on the test results, the average accuracy for TFIDF outperforms word embedding by 85.22% against 74.88%, respectively. Therefore, for the case of job interview grading using our dataset, TF-IDF performs better to reduce the number of dimensions.",,978-1-7281-6142-6,10.1109/ICoICT49345.2020.9166364,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9166364,job applicant selection;feature extraction;TFIDF;word embedding;ANN,Feature extraction;Interviews;Machine learning;Mathematical model;Recruitment;Text categorization;Task analysis,feature extraction;neural nets;text analysis,implementing automation;job applicants;big companies;job opening;costly time-consuming;interview process;face meetings;Human Capital Directorate;job applicant selection;third-party involvement;appropriate feature extraction methods;automate job interview grading;TFIDF;popular feature extractions;word embedding;interview verbatims;analyzing TF-IDF,,,,19,,13-Aug-20,,,IEEE,IEEE Conferences
Automatic keyword extraction for the meeting corpus using supervised approach and bigram expansion,使用監督方法和bigram擴展自動提取會議語料庫的關鍵字,Fei Liu; Feifan Liu; Yang Liu,"Department of Computer Science, The University of Texas at Dallas, USA; Department of Computer Science, The University of Texas at Dallas, USA; Department of Computer Science, The University of Texas at Dallas, USA",2008 IEEE Spoken Language Technology Workshop,6-Feb-09,2008,,,181,184,"In this paper, we tackle the problem of automatic keyword extraction in the meeting domain, a genre significantly different from written text. For the supervised framework, we proposed a rich set of features beyond the typical TFIDF measures, such as sentence salience weight, lexical features, summary sentences, and speaker information. We also evaluate different candidate sampling approaches for better model training and testing. In addition, we introduced a bigram expansion module which aims at extracting ldquoentity bigramsrdquo using Web resources. Using the ICSI meeting corpus, we demonstrate the effectiveness of the features and show that the supervised method and the bigram expansion module outperform the unsupervised TFIDF selection with POS (part-of-speech) filtering. Finally, we show the approaches introduced in this paper perform well on the speech recognition output.",,978-1-4244-3471-8,10.1109/SLT.2008.4777870,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4777870,keyword extraction;meeting transcripts;TFIDF;feature selection,Data mining;Sampling methods;Filtering;Frequency;Computer science;Testing;Speech recognition;Supervised learning;Mutual information;Decision making,natural language processing;speech recognition,automatic keyword extraction;bigram expansion;supervised approach;written text;TFIDF measures;sentence salience weight;lexical features;summary sentences;ICSI meeting corpus;speech recognition output,,11,,14,,6-Feb-09,,,IEEE,IEEE Conferences
A Method for Extracting Keywords from English Literature Based on Location Feature Weighting,基於位置特徵權重的英文文獻關鍵詞提取方法,X. Li,"School of Computer, Electronics and Information, Guangxi University,Nanning,China",2020 IEEE 20th International Conference on Communication Technology (ICCT),24-Dec-20,2020,,,1457,1460,"Natural language processing (NLP) is a frontier technology in the field of artificial intelligence. Keywords extraction is a key link in NLP and plays an important role in NLP. TFIDF algorithm is considered as the most important invention in information mining. This paper uses the position characteristics of words in the title and full text in the text, and makes weighted improvement on the basis of TFIDF algorithm to improve the accuracy of keyword extraction. In this paper, 400 articles of ACM were used as the training data set, 40 articles as the test set, and accuracy rate, recall rate and F1 value were used as the evaluation criteria. Experimental data show that this method improves the accuracy of keyword extraction and improves the performance of the original algorithm.",2576-7828,978-1-7281-8141-7,10.1109/ICCT50939.2020.9295829,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9295829,TFIDF;Keywords extraction;Position characteristics;English literature,Feature extraction;Data mining;Standards;Training data;Frequency measurement;Classification algorithms;Tagging,,,,,,8,,24-Dec-20,,,IEEE,IEEE Conferences
Comparision of String Matching Algorithms on Spam Email Detection,垃圾郵件檢測中字符串匹配算法的比較,C. Varol; H. M. T. Abdulhadi,"Computer Science Department, Sam Houston State University, Huntsville, Texas, USA; Software Engineering Department, Firat University, Elazig, Turkey","2018 International Congress on Big Data, Deep Learning and Fighting Cyber Terrorism (IBIGDELFT)",24-Jan-19,2018,,,6,11,"Email is one of the most expedient approach to transfer messages among people all over the world. Its features, specifically reliability, quickness, and low cost makes it popular and useful among people in most parts of businesses and society. On the other hand, this popularity also created new harmful actions, such as email attacks (spam) in cyberspace. Spam is arguably one of the main reasons of drowning the WWW with many copies of similar messages generated through anonymous senders, which yields to time/space wasting of the email account holder and also a large virus and malware threat to Email providers. In spite of employing various filters to handle spam problem such as machine learning and content-based filtering, spammers are still able to bypass these defense mechanisms. In this paper, we investigate the use of string matching algorithms for spam email detection. Particularly this work examines and compares the efficiency of six well-known string matching algorithms, namely Longest Common Subsequence (LCS), Levenshtein Distance (LD), Jaro, Jaro-Winkler, Bi-gram, and TFIDF on two various datasets which are Enron corpus and CSDMC2010 spam dataset. We observed that Bi-gram algorithm performs best in spam detection in both datasets.",,978-1-7281-0472-0,10.1109/IBIGDELFT.2018.8625317,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8625317,Bi-gram;Jaro distance;Jaro-Winkler;Levenshtein distance;Longest Common Subsequence;Spam detection;String Similarity;TFIDF,,Bayes methods;information filtering;invasive software;learning (artificial intelligence);string matching;unsolicited e-mail,email account holder;Email providers;spam problem;machine learning;string matching algorithms;spam email detection;CSDMC2010 spam dataset;Bi-gram algorithm;email attacks;longest common subsequence;LCS;Levenshtein distance;Jaro-Winkler;TFIDF;content-based filtering,,1,,22,,24-Jan-19,,,IEEE,IEEE Conferences
An evaluation on the efficiency of hybrid feature selection in spam email classification,垃圾郵件分類中混合特徵選擇效率的評估,M. Mohamad; A. Selamat,"Software Eng. Res. Group (SERG), Univ. Teknol. Malaysia, Johor Bahru, Malaysia; Software Eng. Res. Group (SERG), Univ. Teknol. Malaysia, Johor Bahru, Malaysia","2015 International Conference on Computer, Communications, and Control Technology (I4CT)",27-Aug-15,2015,,,227,231,"In this paper, a spam filtering technique, which implement a combination of two types of feature selection methods in its classification task will be discussed. Spam, which is also known as unwanted message always floods our electronic mail boxes, despite a spam filtering system provided by the email service provider. In addition, the issue of spam is always highlighted by Internet users and attracts many researchers to conduct research works on fighting the spam. A number of frameworks, algorithms, toolkits, systems and applications have been proposed, developed and applied by researchers and developers to protect us from spam. Several steps need to be considered in the classification task such as data pre-processing, feature selection, feature extraction, training and testing. One of the main processes in the classification task is called feature selection, which is used to reduce the dimensionality of word frequency without affecting the performance of the classification task. In conjunction with that, we had taken the initiative to conduct an experiment to test the efficiency of the proposed Hybrid Feature Selection, which is a combination of Term Frequency Inverse Document Frequency (TFIDF) with the rough set theory in spam email classification problem. The result shows that the proposed Hybrid Feature Selection return a good result.",,978-1-4799-7952-3,10.1109/I4CT.2015.7219571,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7219571,Spam;filtering;algorithm;feature selection;TFIDF;rough set theory,Filtering;Accuracy;Set theory;Unsolicited electronic mail;Machine learning algorithms;Testing,feature selection;information filtering;Internet;pattern classification;security of data;unsolicited e-mail,hybrid feature selection method;spam filtering technique;electronic mail boxes;email service provider;Internet;data preprocessing;feature extraction;term frequency inverse document frequency;TFIDF;spam email classification problem,,7,,14,,27-Aug-15,,,IEEE,IEEE Conferences
A support vector machine mixed with TF-IDF algorithm to categorize Bengali document,支持向量機與TF-IDF算法混合對孟加拉文文檔進行分類,M. S. Islam; F. E. M. Jubayer; S. I. Ahmed,"CSE, Shahjalal University of Science and Technology; Shahjalal University of Science and Technology; Shahjalal University of Science and Technology","2017 International Conference on Electrical, Computer and Communication Engineering (ECCE)",27-Apr-17,2017,,,191,196,"Document categorization is a technique through which the category of a document is determined. This paper deals with the automatic classification of Bangla documents. In this proposed categorization system, a support vector machine is used for classifying a document in predefine twelve categories. In this classification model TFIDF (term frequency-inverse document frequency) weighting with length normalization is used for feature selection after the preprocessing of data set is complete. It is shown that the results achieved by applying SVM to classify the category of a Bangla document are very promising as compared to conventional methods where features are chosen on the basis of bag-of-words. The accuracy of this proposed methodology is 92.57% for twelve categories.",,978-1-5090-5627-9,10.1109/ECACE.2017.7912904,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7912904,SVM;TFIDF;N-Gram;Supervised Learning,Support vector machines;Classification algorithms;Data models,document handling;pattern classification;support vector machines,support vector machine;TF-IDF algorithm;Bengali document categorization;automatic classification;Bangla documents;categorization system;document classification model;TFIDF weighting;term frequency-inverse document frequency;length normalization;feature selection;SVM;bag-of-words,,15,,31,,27-Apr-17,,,IEEE,IEEE Conferences
The Research of Search Engine Based on Semantic Web,基於語義網的搜索引擎研究,Y. Jin; Z. Lin; H. Lin,"Sch. of Math. & Comput. Sci., Guizhou Normal Univ., Guiyang; Sch. of Math. & Comput. Sci., Guizhou Normal Univ., Guiyang; Sch. of Math. & Comput. Sci., Guizhou Normal Univ., Guiyang",2008 International Symposium on Intelligent Information Technology Application Workshops,30-Dec-08,2008,,,360,363,"Search engines play important roles in the success of the Web, search engines helps any Internet user to rapidly find relevant information. But the unsolved problems of current search engines have led to the development of the semantic Web. In the environment of semantic Web, the search engines should be more useful and efficient for searching the relevant Web information. In this paper we have presented the architecture of a semantic search engine, and our work shows how the fundamental elements of the semantic search engine can be used in the fundamental task of information retrieval. And then an improved algorithm based on TFIDF algorithm was proposed to guarantee the retrieve information resources in a more efficient way.",,978-0-7695-3505-0,10.1109/IITA.Workshops.2008.193,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4731952,search engine;semantic web;information retrieval;TFIDF algorithm,Search engines;Semantic Web;Information retrieval;Indexing;Internet;Software algorithms;Ontologies;Information technology;Application software;Mathematics,information retrieval;search engines;semantic Web;statistical analysis,semantic Web;semantic search engine;Internet;information retrieval;term frequency-inverse frequency algorithm;information resource retrieval;statistical method,,7,,9,,30-Dec-08,,,IEEE,IEEE Conferences
Short text classification based on word2vec and improved TDFIDF merge weighting,基於word2vec和改進的TDFIDF合併權重的短文本分類,Z. Chen,"Wuhan University of Science and Technology,Wuhan,China,430065",2019 3rd International Conference on Electronic Information Technology and Computer Engineering (EITCE),18-May-20,2019,,,1719,1722,"With the development of information technology, the amount of information in contemporary society has proliferated exponentially. It contains not only the information we need, but also the redundant information that we do not need. Therefore, how to pass the massive data the algorithm processing, filtering out the information we do not need, has always been a hotspot in the field of information retrieval. TF-IDF is one of the statistical methods, but the traditional TF-IDF method simply highlights the importance of small frequency vocabulary, but it does not reflect the role of the keyword in the context; once encountered some very useful vocabulary, it will have a bad influence on the classification results. Therefore, we introduce the word2vec model and the improved TFIDF algorithm for combining weights. Experiments show that the model retrieval results are better than the traditional two models.",,978-1-7281-3584-7,10.1109/EITCE47263.2019.9094788,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9094788,TFIDF;word2vec;Short text classification;Imformation retrieval,Text categorization;Vocabulary;Training;Classification algorithms;Semantics;Predictive models;Frequency measurement,information filtering;information retrieval;pattern classification;statistical analysis;text analysis;vocabulary,information retrieval;statistical methods;frequency vocabulary;word2vec model;improved TF-IDF algorithm;model retrieval results;short text classification;information technology;redundant information;TDFIDF merge weighting;information filtering,,,,7,,18-May-20,,,IEEE,IEEE Conferences
A Study on Automatic Extraction of New Terms,自動提取新術語的研究,X. Zhang; A. C. Fang,"Dept. of Chinese, Translation & Linguistics, City Univ. of Hong Kong, Kowloon, China; Dept. of Chinese, Translation & Linguistics, City Univ. of Hong Kong, Kowloon, China",2011 Fourth International Symposium on Knowledge Acquisition and Modeling,23-Jan-12,2011,,,599,602,"This research explores to automatically predict new terms based on linguistic features and statistical behaviors of noun phrases during a special period. It integrates both syntactic function value and TF-IDF value into an automatic term extraction system to weight new term candidates. Research questions include: what are the linguistic and statistic properties of new terms during a special period? Will linguistic features contribute to prediction of new terms? And will statistic features like, TFIDF Value contribute to prediction of new terms? Correspondingly, a series of experiments are conducted on medical corpus to examine a group of new terms' distribution properties and syntactic features across two years in comparison. The results show there does exist significant difference between two groups of values. Regardless of this limitation, this research is meaningful as it attempts to realize automation of selection process of new medical terms, which will greatly avoid subjective decisions and reduce experts' workloads.",,978-1-4577-1788-8,10.1109/KAM.2011.162,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6137717,New term;old term;term extraction;TFIDF;SF-Value,Testing;Syntactics;Terminology;Abstracts;Pragmatics;Equations;Analysis of variance,information retrieval;statistical analysis,automatic new term extraction system;linguistic feature;statistical behavior;syntactic function value;TF-IDF value;noun phrase behavior,,,,9,,23-Jan-12,,,IEEE,IEEE Conferences
A topic-based cross-language retrieval model with PLSA and TF-IDF,使用PLSA和TF-IDF的基於主題的跨語言檢索模型,Z. Huo; J. Wu; Y. Lu; C. Li,"School of Data and Computer Science, Sun yat-sen University, Guangzhou, China; School of Data and Computer Science, Sun yat-sen University, Guangzhou, China; School of Data and Computer Science, Sun yat-sen University, Guangzhou, China; School of Data and Computer Science, Sun yat-sen University, Guangzhou, China",2018 IEEE 3rd International Conference on Big Data Analysis (ICBDA),28-May-18,2018,,,340,344,"Cross-language document retrieval is an important research topic in information retrieval. This paper proposes a cross-language retrieval model, which can retrieve English documents for a Chinese query. The model includes two parts: topic-processing and online retrieval. The topic-processing could be executed once the library of literature is updated. It extracts topics from semantics of texts and then clusters documents of different languages with the extracted topics. Three crucial algorithms are adopted in topic-processing: Probability Latent Semantic Analysis (PLSA) analyzes the topics of documents, Term Frequency-Inverse Document Frequency (TFIDF) identifies keywords for the topics, and word co-occurrence method with dictionary-based translation generates the association among words of different languages. Practical retrieval runs whenever a retrieval request is submitted by a user. It achieves our goal of cross-languages retrieval by analyzing the correlation between query terms and topics, and using document correlation results from topic-processing to find appropriate document results.",,978-1-5386-4794-3,10.1109/ICBDA.2018.8367704,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8367704,cross-language document retrieval;Probability Latent Semantic Analysis (PLSA);Term Frequency-Inverse Document Frequency (TFIDF);word co-occurrence analysis,Text processing;Correlation;Semantics;Biological system modeling;Computational modeling;Databases;Data models,language translation;natural language processing;probability;query processing;text analysis,topic-processing;Term Frequency-Inverse Document Frequency;retrieval request;cross-languages retrieval;document correlation results;cross-language document retrieval;information retrieval;English documents;online retrieval;topic extraction;Probability Latent Semantic Analysis;topic-based cross-language retrieval model;dictionary-based translation;word association;query terms;Chinese query,,1,,20,,28-May-18,,,IEEE,IEEE Conferences
A graph based method for Arabic document indexing,基於圖的阿拉伯文檔索引方法,M. S. El Bazzi; D. Mammass; T. Zaki; A. Ennaji,"IRF-SIC Laboratory, Faculty of sciences, Ibn Zohr University, Agadir, Morocco; IRF-SIC Laboratory, Faculty of sciences, Ibn Zohr University, Agadir, Morocco; IRF-SIC Laboratory, Faculty of sciences, Ibn Zohr University, Agadir, Morocco; LITIS Laboratory, university of Rouen, France","2016 7th International Conference on Sciences of Electronics, Technologies of Information and Telecommunications (SETIT)",8-Jun-17,2016,,,308,312,"Extracting knowledge from text data and taking its full advantage has been an important way to reduce its computation and accelerate processing, especially for large amounts of data. Thus, different approaches and methodologies for modeling and representing textual data have been proposed. In this paper, a graph-based approach for automatic indexing of unstructured data from an Arabic corpus has been proposed. First, each document in the collection is represented by a graph. After the generation of document graph, term weighting is computed to estimate the relevance of a term to the document. The graph representation offers the advantage that it allows for a much more expressive document modeling than the standard bag of words approach, and consequently, it improves classification performance. Experimental results show that the graph based indexing method is a promising approach for semantic and contextual indexation, and outperforms statistical based method (TFIDF) by 12% in F-measure.",,978-1-5090-4712-3,10.1109/SETIT.2016.7939885,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7939885,Arabic Text Mining;TFIDF;TextRank;graph representation;indexation;classification,Semantics;Telecommunications;Indexing;Weight measurement;Standards;Text mining,classification;document handling;graph theory;indexing,graph based method;Arabic document indexing;term weighting;classification;contextual indexation;semantic indexation;F-measure,,,,14,,8-Jun-17,,,IEEE,IEEE Conferences
Topic categorization of Tamil News Articles using PreTrained Word2Vec Embeddings with Convolutional Neural Network,使用預訓練的Word2Vec嵌入和卷積神經網絡對泰米爾語新聞報導進行主題分類,S. Ramraj; R. Arthi; S. Murugan; M. S. Julie,"SRM Institute of Science and Technology,Department of Software Engineering,Chennai,India; Sri Sai Ram Engineering College,Department of Information Technology,Chennai,India; Data Analytics C-DAC,Chennai,India; Sri Sai Ram Engineering,Department of Information Technology,Chennai,India",2020 International Conference on Computational Intelligence for Smart Power System and Sustainable Energy (CISPSSE),5-Oct-20,2020,,,1,4,"Almost all the problems in NLP are solved using various techniques from machine learning to Deep Learning. Still, there is mystery in language localization. NLP problems are unclear for languages other than English. The problems may be named as Entity Extraction, OCR or classification and prediction in sequence modelling. The amount of people using local language (Tamil, Telegu, Hindi etc) in the social media is increasing, so it is important to automate the process of classifying those contents. Here, the aim is to classify the Tamil news articles to its related topics (Sports, Cinema, Politics). In the existing work they have approached traditional machine learning methods with TFIDF of words as features. In this work we have compared the existing TFIDF feature learning along with Pre-Trained embeddings given to Convolutional Neural Networks (CNN). We found that CNN with pretrained embeddings gave better F1 score compare to TFIDF feature learned with Support Vector Machine (SVM), Naive Bayes (NB) algorithm.",,978-1-7281-7274-3,10.1109/CISPSSE49931.2020.9212248,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9212248,Tamil Text Classification;CNN;Pretrained Tamil embeddings,,convolutional neural nets;feature extraction;information retrieval;Internet;learning (artificial intelligence);natural language processing;pattern classification;text analysis,feature learning;OCR;pretrained Word2Vec embeddings;pretrained embeddings;convolutional neural networks;TFIDF feature;social media;sequence modelling;content classification;entity extraction;NLP problems;language localization;deep learning;machine learning;Tamil news articles;topic categorization,,,,14,,5-Oct-20,,,IEEE,IEEE Conferences
Experiments Study for Scientific Texts Domain Keyword Acquisition,科學文本領域關鍵詞獲取的實驗研究,X. L. Xiangfeng Luo; N. F. Ning Fang; W. X. Weimin Xu; S. Y. Sheng Yu; K. Y. Kai Yan; H. X. Huizhe Xiao,"Semantic Grid & Web Content Anal. Group, Shanghai Univ., Shanghai, China; Semantic Grid & Web Content Anal. Group, Shanghai Univ., Shanghai, China; Semantic Grid & Web Content Anal. Group, Shanghai Univ., Shanghai, China; Semantic Grid & Web Content Anal. Group, Shanghai Univ., Shanghai, China; Semantic Grid & Web Content Anal. Group, Shanghai Univ., Shanghai, China; Semantic Grid & Web Content Anal. Group, Shanghai Univ., Shanghai, China","2006 Semantics, Knowledge and Grid, Second International Conference on",20-Aug-12,2006,,,45,45,"Scientific texts domain keyword is one of the basic elements of the text high-level semantics acquisition, domain ontology building and the knowledge representation in semantic grid, knowledge grid and escience environment. It is also the indispensable foundation and prerequisite work of Web scientific texts automatic classification, clustering and personalized services. TFIDF based TDDF formula is proposed to extract scientific texts domain keyword. The experiments proved that TDDF formula extracting texts domain keyword is superior to the classic TFIDF formula does. Above discussions and achievements can provide certain support not only for the establishment of semantic grid, knowledge grid and escience environment, but also for the Web knowledge acquisition, representation and text information retrieval and so on.",,0-7695-2673-X,10.1109/SKG.2006.50,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5727682,Domain keyword;Knowledge Acquisition;Knowledge Grid;Semantic Grid,,grid computing;information retrieval;knowledge acquisition;ontologies (artificial intelligence);pattern clustering;scientific information systems;semantic Web;text analysis,scientific text domain keyword extraction;semantic acquisition;domain ontology;knowledge representation;semantic grid;knowledge grid;e-science environment;Web scientific text automatic classification;text clustering;personalized service;TFIDF;TDDF;Web knowledge acquisition;text information retrieval,,1,,9,,20-Aug-12,,,IEEE,IEEE Conferences
Textual Document Clustering Using Topic Models,使用主題模型的文本文檔聚類,X. Sun,"Knowledge Grid Group, Inst. of Comput. Technol., Beijing, China","2014 10th International Conference on Semantics, Knowledge and Grids",24-Nov-14,2014,,,1,4,"Document clustering is to group documents according to a certain semantic features defined on the document set for measuring the similarities between two documents. The keyword models such as the TFIDF model of document have been widely used as features for document clustering. But it lacks of semantic structure, which limit its further usage in document analysis. Topic model has been developed to discover multiple probabilistic distributions over the vocabulary, which can be seen as different topic dimensions of the document set. It has a richer semantic structure than the TFIDF models. Using topic model to cluster documents, one can obtain the not only the document ids of clusters but also the topic of the clusters and the global document set. There are two major ways to use the topic models in document clustering: one is based on the basic topic model and the other is based on new cluster-oriented topic models. In this paper, we evaluate the basic clustering performance of these two types of methods. We proposed several simple clustering methods based on the basic topic model and compare them with the cluster-oriented topic model and other major clustering methods. The experimental results show that the simple method can achieve the comparable clustering accuracy and recall rate to those latest models and algorithms.",,978-1-4799-6715-5,10.1109/SKG.2014.27,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6964656,document clustering;probabilistic topic model;Latent Dirichlet Allocation (LDA),Clustering algorithms;Probabilistic logic;Clustering methods;Semantics;Measurement;Computational modeling;Vocabulary,pattern clustering;probability;text analysis,textual document clustering;topic models;semantic features;keyword models;TFIDF model;document analysis;multiple probabilistic distributions,,3,,15,,24-Nov-14,,,IEEE,IEEE Conferences
A Method for Network Topic Attention Forecast Based on Feature Words,基於特徵詞的網絡話題註意力預測方法,C. Yan; S. Shi; H. Huang; R. Li,"Sch. of Comput. Sci. & Technol., Beijing Inst. of Technol., Beijing, China; Sch. of Comput. Sci. & Technol., Beijing Inst. of Technol., Beijing, China; Sch. of Comput. Sci. & Technol., Beijing Inst. of Technol., Beijing, China; Sch. of Comput. Sci. & Technol., Beijing Inst. of Technol., Beijing, China",2013 International Conference on Asian Language Processing,24-Oct-13,2013,,,211,214,"The number of people who obtain information and express ideas via the Internet is increasing rapidly. Research on identifying how much attention paid to a given online topic plays an important role in the field of public opinion management. We propose a method to predict the netizens' attention on a specific online topic in this paper. Firstly, we acquire the historical topics' attention-degrees by analyzing news, reviews and forum posts, then built up the Feature Words Set (FWS) and estimate the popularity of each feature word. After that, we extract the feature words from a new topic and evaluate their contribution to it. Finally, the new attention-degree is computed by comparing the new topic's feature words with those in FWS. We compare our method with the Support Vector Regression model on a data set of manually selected topics. Experimental results show that our approach is acceptable for predicting the attention-degree of online topics.",,978-0-7695-5063-3,10.1109/IALP.2013.61,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6646039,Hot Topic Detection;Feature Words Popularity;Topic's Attention-Degree;TFIDF,Feature extraction;Internet;Kernel;Training data;Educational institutions;Computer science;Support vector machines,Internet;regression analysis;social sciences computing;support vector machines,online topics;support vector regression;FWS;feature words set;forum posts;news;historical topic attention-degrees;public opinion management;Internet;network topic attention forecast,,1,,8,,24-Oct-13,,,IEEE,IEEE Conferences
Combining Missing Relative Distance and Information Retrieval Technique for Querying Missing Author in Directed Authorship Graph,結合缺失相對距離和信息檢索技術在有向作者圖中查詢缺失作者,P. Chaiwanarom; C. Lursinsap,"Dept. of Math., Chulalongkorn Univ., Bangkok; Dept. of Math., Chulalongkorn Univ., Bangkok",2009 International Conference on Computer and Automation Engineering,15-Nov-10,2009,,,36,40,"This paper proposed a new approach for imputing missing values called MIJI method.This method is the combination of two techniques, missing relative distance (MRD) and join frequency and inverse entity frequency (JFIEF). These techniques concentrate on the different aspects. The former technique focus to the relative position (i.e. offset and direction) among entities, small offset is high priority. The latter focus to the frequency of occurrence, high frequency is high priority. The accuracy of MRD is 61.50% and can be upgraded to 88.07% if using MIJI method.",,978-0-7695-3569-2,10.1109/ICCAE.2009.32,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4804484,missing data;imputation;authorship graph;TFIDF;MIJI;JFIEF;MRD,Frequency;Cleaning;Automation;Information retrieval;Mathematics;Data mining;Testing,query processing,information retrieval technique;missing relative distance;inverse entity frequency;join frequency;directed authorship graph;missing author querying,,,,7,,15-Nov-10,,,IEEE,IEEE Conferences
An improvement of weighted PageRank to handle the zero link similarity,加權PageRank的改進，以處理零鏈接相似性,S. Lee; Y. Kim; S. Lee; K. M. Lee,"Department of Computer Science, Chungbuk National University, Cheongju, Korea; Department of Computer Science, Chungbuk National University, Cheongju, Korea; Department of Mathmetics, Chungbuk National University, Cheongju, Korea; Department of Computer Science, Chungbuk National University, Cheongju, Korea",2014 Joint 7th International Conference on Soft Computing and Intelligent Systems (SCIS) and 15th International Symposium on Advanced Intelligent Systems (ISIS),19-Feb-15,2014,,,610,613,"The well-known PageRank algorithm makes use of the link structure to calculate a quality rank for pages. It basically delivers the same amount of probability to the neighboring pages of a page. As its extensions, the weighted PageRank algorithms have been proposed which give different weights to outgoing links from a page. Some weighted PageRank algorithm uses the inter-page similarities as weights. In Korean web pages, we have found that it sometimes happens to have zero value for the inter-page similarity of neighboring pages due to the language characteristics. This paper proposes an improved weighted PageRank algorithm that can deal with such zero inter-page similarities. The proposed method has been implemented using the MapReduce paradigm for big data handling, and has been evaluated over the Korean Wikipedia webpages and compared with two other methods.",,978-1-4799-5955-6,10.1109/SCIS-ISIS.2014.7044873,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7044873,PageRank;Weighted PageRank;Similarity;MapReduce;TFIDF,Vectors;Internet;Encyclopedias;Electronic publishing;Clustering algorithms;Web pages,Big Data;parallel processing;probability;Web sites,zero link similarity;quality rank;probability;weighted PageRank algorithms;Korean Web pages;zero inter-page similarities;MapReduce paradigm;Big Data handling;Korean Wikipedia,,,,21,,19-Feb-15,,,IEEE,IEEE Conferences
Use semantic meaning of coreference to improve classification text representation,使用共指的語義來改善分類文本的表示形式,Z. Li; M. Zhou,"School of Computer Science and Engineering University of Electronic Science and Technology of China Chengdu, P.R. China; School of Computer Science and Engineering University of Electronic Science and Technology of China Chengdu, P.R. China",2010 2nd IEEE International Conference on Information Management and Engineering,3-Jun-10,2010,,,416,420,"On large scale dataset, the effect of automatic text classification is now still far from perfect. It's a common agreement that more sufficient text semantic meaning be adopted in text representation to deal with the challenge. This paper introduces semantic meaning of coreference in and to improve traditional BOW representation. The result of text classification experiment shows that, contrasted with traditional BOW representation, the improved model increases the discernment to positive instances. And that the classification performance of the new BOW representation model is no less good than that of stemmed BOW representation model.",,978-1-4244-5263-7,10.1109/ICIME.2010.5478292,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5478292,text classification;coreference analysis;BOW;text representation;tfidf,Text categorization;Natural languages;Large-scale systems;Computer science;Data engineering;Information analysis;Agricultural engineering;History;Helium;Learning systems,data structures;pattern classification;text analysis,text representation;large scale dataset;automatic text classification;text semantic meaning;BOW representation model;coreference analysis,,2,,9,,3-Jun-10,,,IEEE,IEEE Conferences
Using Text Categorization to Find Job Opportunities,使用文本分類查找工作機會,S. Zhang; M. Gu,"Fac. of Comput. Sci., North China Univ. of Technol., Beijing, China; Fac. of Comput. Sci., North China Univ. of Technol., Beijing, China",2010 International Conference on Web Information Systems and Mining,13-Jan-11,2010,1,,25,29,"Text Classification is an important field of research. There are a number of approaches to classify text documents. However, there is an important challenge to improve the computational efficiency and recall. In this paper, we propose a novel framework to segment Chinese words, generate word vectors, train the corpus and make prediction. Based on the text classification technology, we successfully help the Chinese disabled persons to acquire job opportunities efficiently in real word. The results show that using this method to build the classifier yields better results than traditional methods. We also experimentally show that careful selection of a subset of features to represent the documents can improve the performance of the classifiers.",,978-1-4244-8438-6,10.1109/WISM.2010.47,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5662277,word segmentation;SVM;TFIDF;word vector,Classification algorithms;Text categorization;Hidden Markov models;Support vector machine classification;Training;Feature extraction,classification;handicapped aids;text analysis,text categorization;job opportunities;text classification;Chinese word segmentation;word vector;Chinese disabled person,,,,10,,13-Jan-11,,,IEEE,IEEE Conferences
Topic Identification of Noisy Arabic Texts Using Graph Approaches,圖法識別嘈雜的阿拉伯語文本,K. Abainia; S. Ouamour; H. Sayoud,"USTHB Univ., Algiers, France; USTHB Univ., Algiers, France; USTHB Univ., Algiers, France",2015 26th International Workshop on Database and Expert Systems Applications (DEXA),15-Feb-16,2015,,,254,258,"This paper deals with the problem of automatic topic identification of noisy Arabic texts. Actually, there exist several works in this field based on statistical and machine learning approaches for different text categories. Unfortunately, most of the proposed methods are effective in clean and long texts. In this research work, we use an in-house dataset of noisy Arabic texts, which are collected from several Arabic discussion forums related to 6 topics. In this investigation, we propose a graph approach called LIGA for topic identification task. This approach was firstly introduced for language identification field. Moreover, we propose two other extensions in order to enhance LIGA performances. The experiments undergone on the Arabic dataset have shown quite interesting performances, reaching about 98% of accuracy.",2378-3915,978-1-4673-7582-5,10.1109/DEXA.2015.63,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7406302,Topic Identification;Graph approach;Text Categorization;Natural Language Processing;TFIDF;Text mining,Training;Noise measurement;Text categorization;Text mining;Mathematical model;Discussion forums;Ontologies,graph theory;learning (artificial intelligence);natural language processing;statistical analysis;text analysis,language identification field;topic identification task;LIGA;text categories;machine learning approaches;statistical approaches;noisy Arabic texts;automatic topic identification;graph approaches,,3,,11,,15-Feb-16,,,IEEE,IEEE Conferences
Evaluating the effectiveness of features and sampling in extractive meeting summarization,在摘要會議總結中評估功能的有效性和抽樣,Shasha Xie; Yang Liu; Hui Lin,"Department of Computer Science, The University of Texas at Dallas, USA; Department of Computer Science, The University of Texas at Dallas, USA; Department of Electrical Engineering, University of Washington, USA",2008 IEEE Spoken Language Technology Workshop,6-Feb-09,2008,,,157,160,"Feature-based approaches are widely used in the task of extractive meeting summarization. In this paper, we analyze and evaluate the effectiveness of different types of features using forward feature selection in an SVM classifier. In addition to features used in prior studies, we introduce topic related features and demonstrate that these features are helpful for meeting summarization. We also propose a new way to resample the sentences based on their salience scores for model training and testing. The experimental results on both the human transcripts and recognition output, evaluated by the ROUGE summarization metrics, show that feature selection and data resampling help improve the system performance.",,978-1-4244-3471-8,10.1109/SLT.2008.4777864,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4777864,meeting summarization;forward feature selection;resampling;TFIDF,Sampling methods;Support vector machines;Support vector machine classification;Hidden Markov models;Speech analysis;Testing;Data mining;Speech recognition;Frequency;Computer science,feature extraction;pattern classification;speech processing;speech recognition;support vector machines,extractive meeting summarization;forward feature selection;SVM classifier;support vector machine;human transcripts;recognition output;ROUGE summarization metrics;data resampling;speech summarization,,3,,16,,6-Feb-09,,,IEEE,IEEE Conferences
Automation in Social Networking Comments With the Help of Robust fastText and CNN,借助功能強大的fastText和CNN進行社交網絡評論自動化,S. Mestry; H. Singh; R. Chauhan; V. Bisht; K. Tiwari,"Assistant Professor, Computer Department, MCT?s Rajiv Gandhi Institute of Technology, Mumbai, India; Student, Computer Department, MCT?s Rajiv Gandhi Institute of Technology, Mumbai, India; Student, Computer Department, MCT?s Rajiv Gandhi Institute of Technology, Mumbai, India; Student, Computer Department, MCT?s Rajiv Gandhi Institute of Technology, Mumbai, India; Student, Computer Department, MCT?s Rajiv Gandhi Institute of Technology, Mumbai, India",2019 1st International Conference on Innovations in Information and Communication Technology (ICIICT),21-Jun-19,2019,,,1,4,"Social networking and online conversation platforms provide us with the power to share our views and ideas. However, nowadays on social media platforms, many people are taking these platforms for granted, they see it as an opportunity to harass and target others leading to cyber-attack and cyber-bullying which lead to traumatic experiences and suicidal attempts in extreme cases. Manually identifying and classifying such comments is a very long, tiresome and unreliable process. To solve this challenge, we have developed a deep learning system which will identify such negative content on online discussion platforms and successfully classify them into proper labels. Our proposed model aims to apply the text-based Convolution Neural Network (CNN) with word embedding, using fastText word embedding technique. fastText has shown efficient and more accurate results compared to Word2Vec and GLOVE model. Our model aims to improve detecting different types of toxicity to improve the social media experience. Our model classifies such comments in six classes which are Toxic, Severe Toxic, Obscene, Threat, Insult and Identity-hate. Multi-Label Classification helps us to provide an automated solution for dealing with the toxic comments problem we are facing.",,978-1-7281-1604-4,10.1109/ICIICT1.2019.8741503,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8741503,CNN - Convolution Neural Network;RNN -Recurrent Neural Networks;TFIDF - Text Frequency Inverse Document Frequency;SVM - Support Vector Machines;GLOVE-Global Vector for Word Representation;fastText.,Social networking (online);Data models;Convolution;Training;Load modeling;Predictive models;Data visualization,convolutional neural nets;pattern classification;social networking (online);social sciences computing,social networking comments;CNN;online conversation platforms;social media platforms;cyber-attack;cyber-bullying;deep learning system;online discussion platforms;fastText word embedding technique;social media experience;toxic comments problem;multilabel classification;text-based convolution neural network,,2,,8,,21-Jun-19,,,IEEE,IEEE Conferences
Improved Text Classification to acquire job opportunities for Chinese disabled persons,改進文本分類以獲取中國殘疾人的工作機會,Shilin Zhang; Mei Gu,"Faculty of Computer Science, Network and Information Management Center, North China University of Technology, Beijing, China; Faculty of Computer Science, Network and Information Management Center, North China University of Technology, Beijing, China",2010 2nd International Conference on Advanced Computer Control,17-Jun-10,2010,4,,22,26,"Text Classification is an important field of research. There are a number of approaches to classify text documents. However, there is an important challenge to improve the computational efficiency and recall. In this paper, we propose a novel framework to segment Chinese words, generate word vectors, train the corpus and make prediction. Based on the text classification technology, we successfully help the Chinese disabled persons to acquire job opportunities efficiently in real word. The results show that using this method to build the classifier yields better results than traditional methods. We also experimentally show that careful selection of a subset of features to represent the documents can improve the performance of the classifiers.",,978-1-4244-5848-6,10.1109/ICACC.2010.5487237,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5487237,Word segmentation;SVM;TFIDF;Word Vector,Text categorization;Neural networks;Support vector machines;Computer science;Information management;Support vector machine classification;Internet;Organizing;Principal component analysis;Computational efficiency,handicapped aids;pattern classification;text analysis,text classification;job opportunities;Chinese disabled persons;Chinese words;word vectors,,,,12,,17-Jun-10,,,IEEE,IEEE Conferences
Research of Automatic Indexing Based on Semantic and Statistic Feature,基於語義和統計特徵的自動索引研究,Y. Zhang; X. Lv; S. Shi; H. Wang,"Chinese Inf. Process Res. Center, BISTU, Beijing, China; Chinese Inf. Process Res. Center, BISTU, Beijing, China; Chinese Inf. Process Res. Center, BISTU, Beijing, China; Chinese Inf. Process Res. Center, BISTU, Beijing, China",2009 International Conference on Artificial Intelligence and Computational Intelligence,12-Jan-10,2009,3,,77,80,"Automatic indexing is the foundation and core technology of automatic documents processing. Currently most of the documents don't have Keywords, and manual indexing consumes too much time and laborious, it is also highly subjective. This paper discusses the automatic indexing method on the calculation of a statistical and semantic analysis. In the basis of statistical methods, the use of semantic information to improve the accuracy of indexing. At the same time, based on the characteristics of the corpus, the right to the feature selection and optimization in terms of aspects of the program. Experiments show this method not only improves the accuracy of indexing, and improve efficiency.",,978-1-4244-3835-8,10.1109/AICI.2009.116,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5376531,Automatic Indexing;TFIDF;Vector Space Model;Semantic;Statistic,Machine assisted indexing;Statistics;Vocabulary;Documentation;Internet;Information retrieval;Artificial intelligence;Computational intelligence;Statistical analysis;Storage automation,document handling;indexing;programming language semantics;statistical analysis,automatic indexing method;automatic documents processing;semantic analysis;statistical analysis;feature selection;optimization,,,,9,,12-Jan-10,,,IEEE,IEEE Conferences
Improved Stacking Model Fusion Based on Weak Classifier and Word2vec,基於弱分類器和Word2vec的改進的堆疊模型融合,J. Liu; W. Shang; W. Lin,"School of Computer Science, Communication University of China, Beijing, China; School of Computer Science, Communication University of China, Beijing, China; School of Computer Science, Communication University of China, Beijing, China",2018 IEEE/ACIS 17th International Conference on Computer and Information Science (ICIS),20-Sep-18,2018,,,820,824,"Stacking model Fusion is a combination classification method for natural language processing and text categorization. Compared to a single weak classifier, model Fusion has the advantage of combining the classification strengths of multiple classifiers, so the combination classifier is often more accurate than a single classifier, and the research of this field has been developed rapidly in recent years, and the combination classifier has been applied in various natural language processing tasks. But only by using the prediction results of the first layer weak classifier to train the second layer classifier, it has a strong limitation, only considers the training of the classification result and ignores the semantic information. We think that the method of training the weak classifier by TFIDF to the document, the expression of the document is not enough, only the information about the frequency of the document and the document is lack of the semantic information of the word2vector. In this paper, a new combination classification method is proposed, which combines the various weak classifiers trained by TFIDF and Word2vector to express the documents in many aspects, and the feature expression can fully utilize the information provided by the document. It has better classification effect than individual word2vector expression and classification and simple weak classifier combination classification.",,978-1-5386-5892-5,10.1109/ICIS.2018.8466463,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8466463,model fusion;TFIDF;word2vec;combination classifier,Classification algorithms;Training;Stacking;Text categorization;Semantics;Computational modeling;Machine learning algorithms,learning (artificial intelligence);natural language processing;pattern classification;sensor fusion;text analysis,Word2vec;combination classification method;text categorization;classification strengths;combination classifier;natural language processing tasks;layer classifier;semantic information;simple weak classifier combination classification;stacking model fusion;word2vector expression,,3,,10,,20-Sep-18,,,IEEE,IEEE Conferences
Genre Classification using Word Embeddings and Deep Learning,使用詞嵌入和深度學習進行體裁分類,A. Kumar; A. Rajpal; D. Rathore,"Department of Computer Science and Engineering, Delhi Technological University, Delhi, India; Computer Science and Engineering, Delhi Technological University, Delhi, India; Computer Science and Engineering, Delhi Technological University, Delhi, India","2018 International Conference on Advances in Computing, Communications and Informatics (ICACCI)",2-Dec-18,2018,,,2142,2146,"Music genres refer to division of music into categories on the basis of interaction between artists, market forces and culture. They help to organize music into collections by indicating similarities between compositions or musicians. Automatic classification of genre is non-trivial as it is difficult to distinguish between different genres and many times the boundaries are not clearly defined and genres are overlapping. In this paper we try to classify a list of songs present on Spotify into mainly four genres - Christian, Metal, Country, Rap using their lyrics. We apply two Word Embedding techniques namely Word2Vec and Word2Vec with TFIDF (Term Frequency-Inverse Document Frequency) on the preprocessed data in order to map words of the lyrics into vectors consisting of real numbers. On application of machine learning algorithms like Support Vector Machine, Random Forest, XGBoost (eXtreme Gradient Boosting) and Deep Neural Networks on the resultant word vectors to predict the genre, we are able to achieve a mean accuracy of 61.70% and 71.05% in Simple Word2Vec and Word2Vec with TFIDF respectively with maximum accuracy of 65.0% and 74.0% using a 3 Layer Deep Learning model in case of both the techniques.",,978-1-5386-5314-2,10.1109/ICACCI.2018.8554816,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8554816,Genre classification;Simple Word2Vec;t-Distributed Stochastic Neighbor Embedding (TSNE);Word2Vec with TFIDF;Word Cloud,Music;Neural networks;Tag clouds;Support vector machines;Machine learning;Forestry;Feature extraction,learning (artificial intelligence);music;neural nets;pattern classification;support vector machines,music genres;automatic classification;resultant word vectors;genre classification;word embedding techniques;frequency-inverse document frequency;support vector machine;deep neural networks;3-layer deep learning model,,,,16,,2-Dec-18,,,IEEE,IEEE Conferences
Micro-blog Short Text Clustering Algorithm Based on Bootstrapping,基於自舉的微博短文本聚類算法,C. Jin; S. Zhang,"Huaiyin Institute of Technology,Faculty of Computer and Software Engineering,Huaian,China; Taiwan Chiao Tung University,Department of Management Science,Hsinchu,Taiwan",2019 12th International Symposium on Computational Intelligence and Design (ISCID),14-May-20,2019,2,,264,266,"In micro-blog short text clustering, the amount of text information contained in micro-blog short text is small, with timeliness, sparseness and singularity, so the artificial selection of attribute words has some limitations. This paper puts forward the feature extraction of text information in micro-blog using Bootstrapping algorithm, it can choose the higher theme information reflect the characteristics of words, and then use the improved TFIDF algorithm to calculate the weight of micro-blog based text clustering. Finally, K-means clustering algorithm is used to cluster micro-blog short text. The experimental results show that the clustering algorithm of micro-blog short text proposed in this paper is better than other algorithms, which improves the clustering effect of micro-blog short text.",2473-3547,978-1-7281-4653-9,10.1109/ISCID.2019.10143,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9092543,Micro-blog text;Bootstrapping algorithm;VSM;K-means clustering,Clustering algorithms;Feature extraction;Machine learning algorithms;Data mining;Blogs;Classification algorithms;Probabilistic logic,feature extraction;information retrieval;pattern clustering;statistical analysis;text analysis;Web sites,microblog short text clustering algorithm;text information;timeliness;sparseness;artificial selection;artificial selection;attribute words;singularity;feature extraction;bootstrapping algorithm;theme information;improved TFIDF algorithm;K-means clustering algorithm,,,,6,,14-May-20,,,IEEE,IEEE Conferences
Question Similarity Detection in Turkish Using Semantic Textual Similarity Methods,土耳其語中使用語義文本相似度方法的問題相似度檢測,E. Y覺ld覺z; Y. F覺nd覺k,"Bilgisayar ve Bilisim Fak., Istanbul Teknik Univ., Istanbul, Turkey; Muhendislik ve Doga Bilimleri Fak., Sabanci Univ., Istanbul, Turkey",2019 27th Signal Processing and Communications Applications Conference (SIU),22-Aug-19,2019,,,1,4,"In this study, we evaluate the performance of various semantic textual similarity methods on question similarity detection task in Turkish. Various handcrafted features and neural models, specifically siamese recurrent networks, are studied to detect questions which have a similar meaning to given question in a dataset. Several experiments have been performed to compare the performance of features and neural methods. Our Experiments demonstrate that siamese recurrent networks significantly outperforms traditional methods which are based on handcrafted features such as word and stem matching counts, TFIDF vectors and similarity of word embeddings. We also observed that the performance of siamese recurrent networks could be further improved by incorporating handcrafted features to the process.",2165-0608,978-1-7281-1904-5,10.1109/SIU.2019.8806308,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8806308,question similarity;textual similarity;question answering;natural language processing,Dogs;Semantics;Task analysis;Feature extraction;Natural language processing;Google;Recurrent neural networks,natural language processing;recurrent neural nets;text analysis,Turkish;handcrafted features;neural methods;semantic textual similarity methods;siamese recurrent networks;TFIDF vectors,,,,,,22-Aug-19,,,IEEE,IEEE Conferences
Improved Bayes Method Based on TF-IDF Feature and Grade Factor Feature for Chinese Information Classification,基於TF-IDF特徵和等級因子特徵的改進貝葉斯方法用於中文信息分類,Z. Qu; X. Song; S. Zheng; X. Wang; X. Song; Z. Li,"Beijing Univ. of Posts & Telecommun., Beijing, China; Beijing Univ. of Posts & Telecommun., Beijing, China; Beijing Univ. of Posts & Telecommun., Beijing, China; Beijing Univ. of Posts & Telecommun., Beijing, China; Beijing Univ. of Posts & Telecommun., Beijing, China; Beijing Univ. of Posts & Telecommun., Beijing, China",2018 IEEE International Conference on Big Data and Smart Computing (BigComp),28-May-18,2018,,,677,680,"Existing methods improved the accuracy of Bayes by weakening its feature independence assumption. However, these approaches only simply incorporate the learned feature into the formula of Naive Bayes, but they do not incorporate these features into its conditional probability. In addition, these feature weighting methods have received less attention and whose accuracy for information extraction and Chinese text classification still needs to be improved. In this paper, we propose a more effective and more accurate method for automatic information classification, called improved Bayes method based on TF-IDF feature weight and grade factor feature weight (TIGFIB), which estimates the conditional probabilities of Naive Bayes by TFIDF feature and imports grade factor feature into formula of Naive Bayes. Besides, we apply our improved Bayes method to Chinese text classification. Experiment shows that our improved Bayes method is superior to other feature weighting Naive Bayes methods.",2375-9356,978-1-5386-3649-7,10.1109/BigComp.2018.00124,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8367204,Improved Bayes;TF-IDF Feature Weight;Grade Factor Feature Weight;Chinese Text Classification;In formation Extraction,Bayes methods;Training;Feature extraction;Text categorization;Information retrieval;Decision trees;Task analysis,Bayes methods;learning (artificial intelligence);pattern classification;probability;text analysis,TF-IDF feature;feature independence assumption;learned feature;conditional probability;feature weighting methods;Chinese text classification;automatic information classification;grade factor feature weight;TFIDF feature;imports grade factor feature;Naive Bayes methods;Chinese information classification;improved Bayes method,,2,,15,,28-May-18,,,IEEE,IEEE Conferences
Improving Word Representation by Tuning Word2Vec Parameters with Deep Learning Model,通過使用深度學習模型調整Word2Vec參數來改善單詞表示,M. Tezgider; B. Y覺ld覺z; G. Ayd覺n,"Hacettepe ?niversitesi, Ankara, T羹rkiye; Bilgi Teknolojileri Ba?kanl覺?覺, T.C Cumhurba?kanl覺?覺, Ankara, T羹rkiye; Bilgisayar M羹hendisli?i B繹l羹m羹, F覺rat ?niversitesi, Elaz覺?, T羹rkiye",2018 International Conference on Artificial Intelligence and Data Processing (IDAP),24-Jan-19,2018,,,1,7,"Deep learning has become one of the most popular machine learning methods. The success in the text processing, analysis and classification has been significantly enhanced by using deep learning. This success is contributed by the quality of the word representations. TFIDF, FastText, Glove and Word2Vec are used for the word representation. In this work, we aimed to improve word representations by tuning Word2Vec parameters. The success of the word representations was measured by using a deep learning classification model. The minimum word count, vector size and window size parameters of Word2Vec were used for the measurement. 2,8 million Turkish texts consisting of 243 million words to create word embedding (word representations) and around 263 thousand documents consisting of 15 different classes for classification were used. We observed that correctly selected parameters increased the word representation quality and thus the accuracy of classification.",,978-1-5386-6878-8,10.1109/IDAP.2018.8620919,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8620919,Deep learning;text processing;text analysis;word representation;Word2Vec,Deep learning;Tuning;Text processing;Reactive power;Size measurement;Indexes,learning (artificial intelligence);natural language processing;pattern classification;text analysis;word processing,deep learning classification model;machine learning methods;word representation;Word2Vec parameter tuning;Turkish texts;TFIDF;FastText,,1,,0,,24-Jan-19,,,IEEE,IEEE Conferences
Performance Analysis of Multiple Classifiers using different Term Weighting Schemes for Sentiment Analysis,使用不同術語加權方案進行情感分析的多個分類器的性能分析,A. A. Anees; H. Prakash Gupta; A. P. Dalvi; S. Gopinath; B. R. Mohan,"National Institute of Technology,Department of Information Technology,Karnataka,Surathkal,Mangaluru,575025; National Institute of Technology,Department of Information Technology,Karnataka,Surathkal,Mangaluru,575025; National Institute of Technology,Department of Information Technology,Karnataka,Surathkal,Mangaluru,575025; National Institute of Technology,Department of Information Technology,Karnataka,Surathkal,Mangaluru,575025; National Institute of Technology,Department of Information Technology,Karnataka,Surathkal,Mangaluru,575025",2019 International Conference on Intelligent Computing and Control Systems (ICCS),16-Apr-20,2019,,,637,641,"Information sharing and review platforms has generated large volumes of opinionated data which is usually in unstructured form. With the help of Sentiment Analysis, this data can be transformed into structured data which can be useful for commercial applications such as product reviews and feedback, marketing analysis, etc. The purpose of this work is to analyzes the performance of three classifiers(SVM, Naive Bayes, and Logistic Regression) with respect to providing positive or negative sentiment for three different scenarios(Movie Reviews, Election Opinions, and Food Reviews). The three classifiers are compared using fixed set of preprocessing steps and four different weighting schemes(Term frequency inverse document frequency (TFIDF), Term frequency inverse class frequency (TFICF), Mutual Information (MI), and X2 statistic (CHI)). The controlled experimental results showed that Logistic Regression classifier performs better in terms of overall accuracy when MI is used as weighting scheme.",,978-1-5386-8113-8,10.1109/ICCS45141.2019.9065895,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9065895,text weighting schemes;machine learning classifiers;scenario,Sentiment analysis;Support vector machines;Machine learning;Logistics;Conferences;Voting;Control systems,naive Bayes methods;regression analysis;sentiment analysis;social networking (online);support vector machines,sentiment analysis;structured data;commercial applications;logistic regression classifier;performance analysis;term weighting schemes;review platforms;term frequency inverse class frequency;TFICF;term frequency inverse document frequency;TFIDF;Naive Bayes;SVM;information sharing platforms;mutual information,,,,13,,16-Apr-20,,,IEEE,IEEE Conferences
Construction Method of Sentiment Lexicon Based on Word2vec,基於Word2vec的情感詞典構建方法,Z. Yuan; L. Duan,"College of Computer Science and Technology, Chongqing University of Posts and Telecommunications, Chongqing, China; College of Software Engineering, Chongqing University of Posts and Telecommunications",2019 IEEE 8th Joint International Information Technology and Artificial Intelligence Conference (ITAIC),5-Aug-19,2019,,,848,851,"In natural language processing, sentiment lexicon is an effective method for sentiment analysis of text. Aiming at the shortcomings of existing sentiment lexicon in emotional and semantic expression, a method of constructing domain sentiment lexicon based on word2vec is proposed. Based on the existing Chinese affective dictionaries, this method uses TFIDF to measure the importance of vocabulary and the expression of word vectors in semantics to form the selection criteria and classification basis of seed vocabulary, and then forms a sentiment lexicon by category judgment. The comparative experiments show that this method has played a positive role in improving the accuracy of sentiment words classification and the construction of sentiment lexicon.",,978-1-5386-8178-7,10.1109/ITAIC.2019.8785471,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8785471,sentiment;lexicon;word2vec;analysis;vector,Vocabulary;Semantics;Dictionaries;Machine learning;Sentiment analysis;Ontologies,dictionaries;sentiment analysis;word processing,construction method;word2vec;domain sentiment lexicon;sentiment words classification;natural language processing;sentiment analysis;semantic expression;Chinese affective dictionaries;TFIDF;word vectors;selection criteria;seed vocabulary,,,,10,,5-Aug-19,,,IEEE,IEEE Conferences
Battlefield Situational Information Discovery Based on Ontology,基於本體的戰場態勢信息發現,W. Shan; J. Zhou; H. Hu; P. Wang,"Dept. of Commun., Second Artillery Command Coll., Wuhan, China; Dept. of Commun., Second Artillery Command Coll., Wuhan, China; Dept. of Commun., Second Artillery Command Coll., Wuhan, China; Grad. Sch. of Commun. Strategic, Nat. Defence Inf. Coll., Wuhan, China",2013 International Conference on Computer Sciences and Applications,19-Jun-14,2013,,,719,722,"Battlefield situational information discovery is a key part of information distribution, based on ontology model theory, this paper describes the information service concepts and relationships among them, then get battlefield situational information description in semantic level, then modify the feature weight calculation in TFIDF formula to improve the accuracy of service matching, filter out irrelevant services through clustering calculate to make battlefield situational information discovery more accurate and reliable.",,978-0-7695-5125-8,10.1109/CSA.2013.173,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6835699,battlefield situational information;ontology;service discovery,Ontologies;Semantics;Clustering algorithms;Algorithm design and analysis;Information services;Web services;Accuracy,information services;military computing;ontologies (artificial intelligence);pattern clustering,battlefield situational information discovery;information distribution;ontology model theory;information service;battlefield situational information description;TFIDF formula;service matching;clustering,,,,7,,19-Jun-14,,,IEEE,IEEE Conferences
Applying frequency and location information to keyword extraction in single document,將頻率和位置信息應用於單個文檔中的關鍵字提取,Y. Qin,"Department of Computer Science, Beijing Foreign Studies University, Beijing 100089, China",2012 IEEE 2nd International Conference on Cloud Computing and Intelligence Systems,14-Nov-13,2012,3,,1398,1402,"Keyword extraction from single document is not same to the task of text classification, in which a collection of texts can be compared and referred to. The paper focuses on the keyword extraction based on statistical information of words, that is, self features of keywords in the single document. Besides of general features such as word frequency and POS of a word, location features of a keyword are deep investigated and applied to select the candidate words. Experimental results of the extraction approach based on this method outperform TFIDF, TextRank and other unsupervised methods by comparing with them on the same corpus.",2376-595X,978-1-4673-1857-0,10.1109/CCIS.2012.6664615,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6664615,keyword extraction;single document;unsupervised approach,Feature extraction;Abstracts;Text categorization;Pragmatics;Frequency measurement,document handling;information retrieval,location information;frequency information;single document keyword extraction;words statistical information;POS;TFIDF;TextRank,,1,,12,,14-Nov-13,,,IEEE,IEEE Conferences
Optimization Design of Website Search Based on Vector Space Model,基於向量空間模型的網站搜索優化設計,Z. Tian; H. Zhang,"Sch. of Software, Henan Inst. of Eng., Zhengzhou, China; Sch. of Software, Henan Inst. of Eng., Zhengzhou, China",2011 Fourth International Symposium on Knowledge Acquisition and Modeling,23-Jan-12,2011,,,447,450,"With the rapid development of Internet, online information is rapidly expanding, the accuracy and efficiency of search is particularly important. This paper applies the technology of natural language understanding to the website search field, studies document representation theory and realizes the extraction of document eigen value using vector space model and TFIDF formula. Besides, it also provides basis for document classification.",,978-1-4577-1788-8,10.1109/KAM.2011.122,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6137677,Vector space model;Characteristic Value;website search,Vectors;Support vector machine classification;Feature extraction;Search engines;Web pages;Text mining;Vocabulary,document handling;eigenvalues and eigenfunctions;Internet;natural language processing;pattern classification;search engines;Web sites,optimization design;Web site search;vector space model;Internet;online information;natural language understanding;document representation theory;document eigen value extraction;TFIDF formula;document classification,,1,,5,,23-Jan-12,,,IEEE,IEEE Conferences
An Automated Approach for Software Bug Classification,一種自動進行軟件錯誤分類的方法,Neelofar; M. Y. Javed; H. Mohsin,"Dept. of Comput. Eng., Nat. Univ. of Sci. & Technol., Rawalpindi, Pakistan; Dept. of Comput. Eng., Nat. Univ. of Sci. & Technol., Rawalpindi, Pakistan; Dept. of Comput. Eng., Nat. Univ. of Sci. & Technol., Rawalpindi, Pakistan","2012 Sixth International Conference on Complex, Intelligent, and Software Intensive Systems",23-Jul-12,2012,,,414,419,"Open source projects for example Eclipse and Fire fox have open source bug repositories. User reports bugs to these repositories. Users of these repositories are usually non-technical and cannot assign correct class to these bugs. Triaging of bugs, to developer, to fix them is a tedious and time consuming task. Developers are usually expert in particular areas. For example, few developers are expert in GUI and others are in java functionality. Assigning a particular bug to relevant developer could save time and would help to maintain the interest level of developers by assigning bugs according to their interest. However, assigning right bug to right developer is quite difficult for triager without knowing the actual class, the bug belongs to. In this research, we have classified the bugs in different labels on the basis of summary of the bug. Multinomial Na簿ve Bayes text classifier is used for classification purpose. For feature selection, Chi-Square and TFIDF algorithms were used. Using Na簿ve Bayes and Chi-square, we get average of 83 % accuracy.",,978-1-4673-1233-2,10.1109/CISIS.2012.132,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6245635,Text mining;classification;software repositories;open source software projects;triaging;feature extraction,Training;Computer bugs;Accuracy;Data mining;Software;Classification algorithms;Testing,data mining;pattern classification;program debugging;public domain software;text analysis,software bug classification;open source projects;Eclipse;Firefox;open source bug repositories;bug triaging;multinomial naive Bayes text classifier;feature selection;chi-square algorithm;TFIDF algorithm,,8,,10,,23-Jul-12,,,IEEE,IEEE Conferences
Multi-Document summarization based on improved features and clustering,基於改進功能和聚類的多文檔摘要,Y. Xiong; H. Liu; L. Li,"Beijing University of Posts and Telecommunications, China; Beijing University of Posts and Telecommunications, China; Beijing University of Posts and Telecommunications, China",Proceedings of the 6th International Conference on Natural Language Processing and Knowledge Engineering(NLPKE-2010),30-Sep-10,2010,,,1,5,"Multi-Document summarization is an emerging technique for understanding the main purpose of many documents about the same topic. This paper proposes a new feature selection method to improve the summarization result. When calculating similarity, we use a modified TFIDF formula which achieves a better result. We adopt two ways for exactly extracting keywords. Experimental results demonstrate that our improved method performs better than the traditional one.",,978-1-4244-6899-7,10.1109/NLPKE.2010.5587834,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5587834,Multi-document summarization;feature selection;cluster;sentence selection,Telecommunications;Context,document handling;information retrieval;pattern clustering,multidocument summarization;TFIDF formula;keyword extraction;feature selection method;sentence selection,,2,,14,,30-Sep-10,,,IEEE,IEEE Conferences
Natural Language Processing based New Approach to Design Factoid Question Answering System,基於自然語言處理的Factoid問答系統設計新方法,M. Vinodkumar Sadhuram; A. Soni,"Chhatrapati Shivaji Institute of Technology,Durg,Chhattisgarh; Chhatrapati Shivaji Institute of Technology,Durg,Chhattisgarh",2020 Second International Conference on Inventive Research in Computing Applications (ICIRCA),1-Sep-20,2020,,,276,281,"The field of text mining which deals with the providing of answers to the questions of the users is also one of the hot topics for researchers. The difficulty seen in the proper answering of the questions needs to be resolved. The large variety of questions fails in the QA system. In this paper, Natural Language Processing (NLP) has been used which deals with the processing of the data that comes in any form like text, video, image, or audio. This NLP comes under the field of artificial intelligence (AI), which is used in the field of question answering (QA) system. Here proposed work for designing a system that works for factoid QA which will answer the questions that are asked by the users. Lexical Chain and Keyword analysis are used in our system for the answering of questions from a given set of articles. The reasoning system is used for the validity of the answering. The experiment here is done with the SQUAD dataset. In our experiment, the accuracy obtained for the passage retrieval using TFIDF is 69.69%. The overall average of the correct prediction of the answer is 69.93%.",,978-1-7281-5374-2,10.1109/ICIRCA48905.2020.9182972,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9182972,Factoid Question Answering System;Natural Language Processing;TF-IDF;Artificial Intelligence;S QUAD Dataset,Natural language processing;Computer architecture;Conferences;Knowledge discovery;Task analysis,artificial intelligence;data mining;natural language processing;question answering (information retrieval);text analysis,natural language processing;design factoid question answering system;text mining;proper answering;QA system;NLP;reasoning system;SQUAD dataset;TFIDF;passage retrieval;AI;artificial intelligence,,,,15,,1-Sep-20,,,IEEE,IEEE Conferences
Course recommendation based on semantic similarity analysis,基於語義相似度分析的課程推薦,H. Ma; X. Wang; J. Hou; Y. Lu,"Graduate Management Brigade, Defense Information Academy, Wuhan, China; Graduate Management Brigade, Defense Information Academy, Wuhan, China; Graduate Management Brigade, Defense Information Academy, Wuhan, China; The fourth department, Defense Information Academy, Wuhan, China",2017 3rd IEEE International Conference on Control Science and Systems Engineering (ICCSSE),30-Oct-17,2017,,,638,641,"For many students, course recommendation is a troublesome problem. To choose satisfying courses when they only have a little of information about the courses, they have to turn to common course schedule systems for help, but the result is disappointing. To solve the problem, the method of scoring similarity of courses and clustering courses based on course descriptions is presented. Different from the method, this paper applies semantic similarity analysis into course selection, realizes a course recommendation system. Each course description is first modeled as a document, and a cleantokenize-TFIDF-Word2Vec-Doc2Vec pipeline is built to create vectors for each course from which cosine similarities will be calculated. The result is even better than the above method through evaluation.",,978-1-5386-0484-7,10.1109/CCSSE.2017.8088011,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8088011,course recommendation;semantic similarity;evaluation,Semantics;Large scale integration;Clustering algorithms;Algorithm design and analysis;Schedules;Data mining;Vocabulary,document handling;educational administrative data processing;educational courses;recommender systems,course description;semantic similarity analysis;course selection;course recommendation system;cleantokenize-TFIDF-Word2Vec-Doc2Vec pipeline;cosine similarities;common course schedule systems;clustering courses,,7,,5,,30-Oct-17,,,IEEE,IEEE Conferences
Evaluation of classification methods for Indonesian text emotion detection,印尼文字情感檢測分類方法的評價,Muljono; N. A. S. Winarsih; C. Supriyanto,"Department of Informatics Engineering, Dian Nuswantoro University, Semarang, Indonesia; Department of Informatics Engineering, Dian Nuswantoro University, Semarang, Indonesia; Department of Informatics Engineering, Dian Nuswantoro University, Semarang, Indonesia",2016 International Seminar on Application for Technology of Information and Communication (ISemantic),9-Mar-17,2016,,,130,133,"This paper presents Indonesian text emotion detection and evaluates the performances of four different classification methods: Naive Bayes (NB), J48, K-Nearest Neighbor (KNN) and Support Vector Machine-Sequential Minimal Optimization (SVM-SMO). The experiment uses Indonesian text corpus, containing 1000 sentences which consists of six emotion classes: anger, disgust, fear, joy, sadness, and surprise. Preprocessing step which consists of tokenization, case normalization, stopword removal, stemming and TFIDF are used to extract the features of text emotion. We conduct 10-fold cross validation and split validation for the experiment. Based on the result, we conclude that SVM-SMO classifier gives the best performance. In the 10-fold cross validation, the result shows that the accuracy of NB, J48, KNN and SVM-SMO are 80.2%, 80.8%, 68.1%, and 85.5% respectively. The same conclusion is also demonstrated by the split validation, the highest accuracy of 86% is also achieved by SVM-SMO.",,978-1-5090-2326-4,10.1109/ISEMANTIC.2016.7873824,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7873824,Indonesian Text Emotion Detection;SVM-SMO;J48;Naive Bayes;KNN,Niobium;Support vector machines;Training;Seminars;Emotion recognition;Testing;Feature extraction,Bayes methods;behavioural sciences computing;emotion recognition;learning (artificial intelligence);optimisation;pattern classification;support vector machines;text analysis,Indonesian text emotion detection;naive Bayes;J48;K-nearest neighbor;support vector machine-sequential minimal optimization;anger emotion;disgust emotion;fear emotion;joy emotion;sadness emotion;surprise emotion;tokenization;case normalization;stopword removal;stemming;TFIDF;feature extraction;SVM-SMO classification method;NB classification method;J48 classification method;KNN classification method;term frequency inverse document frequency,,5,,16,,9-Mar-17,,,IEEE,IEEE Conferences
The construction and maintenance of the frequently asked question,常見問題的構建和維護,F. Li; L. Liu,"School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China",2010 IEEE 2nd Symposium on Web Society,21-Oct-10,2010,,,296,300,"With the development of Question Answering System which is a hot topic in the area of Artificial Intelligence, the set of FAQ (Frequently Asked Question) has become a widely used knowledge base and it do play an important role in Question Answering System. Besides this, it is also important in Information Retrieval. Therefore, the problem of how to construct and maintain the FAQ automatically has attracted many researchers ' attention. In this paper, we put forward a method aims at solving the problem. We quote the ?Concept Hierarchy Structure??for the first time which combined with the theory of text classification. We implement a method of computing similarity between sentences named TFIDF in the construction and maintenance of the FAQ. We do some experiments to verify our method and analyze the shortcomings of the method. From the experiment, we can see that the method introduced in this paper can reach a nice result.",2158-6993,978-1-4244-6359-6,10.1109/SWS.2010.5607438,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5607438,,Software;Search engines;Internet;Hardware;Maintenance engineering;Computers;Monitoring,classification;information retrieval;knowledge based systems;software maintenance;text analysis,question answering system;artificial intelligence;frequently asked question;knowledge base;information retrieval;concept hierarchy structure;text classification;TFIDF method;FAQ construction;FAQ maintenance,,,,8,,21-Oct-10,,,IEEE,IEEE Conferences
Quest for the information: using intelligent search for finding telemedical sites,尋求信息：使用智能搜索查找遠程醫療站點,M. Zorman; V. Podgorelec; P. Kokol,"Fac. of Electr. Eng. & Comput. Sci., Maribor Univ., Slovenia; NA; NA","SMC'98 Conference Proceedings. 1998 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.98CH36218)",6-Aug-02,1998,4,,4086,4091 vol.4,"We present an intelligent search tool, which we developed in order to automate search and evaluation of Web sites. We used TFIDF heuristics to determine term frequency and decision trees to evaluate the quality of sites. The training set for the decision tree contained manually evaluated Web sites. Each Web site was described by the combination of various attributes, complexity metrics and the evaluation. The intelligent search tool is equipped with a user friendly interface, which enables people to exploit the tool to its limits with minimum effort, in their quest for information. For testing purposes, we looked for sites with telemedical content. The set of sites, which was the result of using intelligent search tool was evaluated by a group of students.",1062-922X,0-7803-4778-1,10.1109/ICSMC.1998.726729,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=726729,,Fractals;Java;Decision trees;Databases;Information filtering;Information filters;Current measurement;Frequency measurement;Equations;Navigation,telemedicine;medical computing;information resources;information retrieval;online front-ends;user interfaces;human factors;knowledge based systems,information quest;Web sites;telemedical sites;intelligent search tool;TFIDF heuristics;term frequency;decision trees;training set;decision tree;complexity metrics;user friendly interface;telemedical content,,1,,7,,6-Aug-02,,,IEEE,IEEE Conferences
Research on archives text classification based on Naive bayes,基於樸素貝葉斯的檔案文本分類研究,P. Liu; H. Yu; T. Xu; C. Lan,"State Key Laboratory of Chinese Language and Information Technology of Ministry of Education, Northwest University for Nationalities, Lanzhou, China; State Key Laboratory of Chinese Language and Information Technology of Ministry of Education, Northwest University for Nationalities, Lanzhou, China; State Key Laboratory of Chinese Language and Information Technology of Ministry of Education, Northwest University for Nationalities, Lanzhou, China; State Key Laboratory of Chinese Language and Information Technology of Ministry of Education, Northwest University for Nationalities, Lanzhou, China","2017 IEEE 2nd Information Technology, Networking, Electronic and Automation Control Conference (ITNEC)",8-Feb-18,2017,,,187,190,"This paper analyzes the data resources of archives in Gansu Province by combining with the characteristics of archives resources, and combines with Naive Bayesian classification algorithm to realize the application of archives resource classification. According to the characteristics of the file data, select the attribute that matches the text of the file text, and use the TFIDF algorithm in the file text feature attribute selection. The experimental results show that the classification model is suitable for the classification of archival text resources, and the function of automatic classification of archives is realized. Compared with the traditional Naive Bayesian classification method, the classification model proposed in this paper is 1% -2% for the classification efficiency of archives, it is a more effective classification model for the archives.",,978-1-5090-6414-4,10.1109/ITNEC.2017.8284934,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8284934,archives text resource;file feature;text classification;Naive Bayesian classification,,Bayes methods;learning (artificial intelligence);pattern classification;text analysis,archives resource classification;file data;TFIDF algorithm;file text feature attribute selection;traditional Naive Bayesian classification method;archives text classification;Gansu Province;naive Bayesian classification algorithm,,4,,8,,8-Feb-18,,,IEEE,IEEE Conferences
A Comparative Study of Chinese Patent Literature Automatic Classification Based on Deep Learning,基於深度學習的中國專利文獻自動分類比較研究,L. Lyu; T. Han,National Science Library Chinese Academy of Sciences; National Science Library Chinese Academy of Sciences,2019 ACM/IEEE Joint Conference on Digital Libraries (JCDL),8-Aug-19,2019,,,345,346,"Patent literature automatic classification is of great significance to literature retrieval and management. In this study, deep learning technique is used for Chinese patent literature classification, and automatic classification accuracy rates of one existing model and six deep learning models are compared. Compared with ""TFIDF+Logistic Regression"" model, the deep learning model has better effect of patent literature automatic classification. Furthermore, the ""Word2Vec+GRU+TextCNN"" model in seven models has the highest classification accuracy rate, and attention mechanism has little effect on classification results.",,978-1-7281-1547-4,10.1109/JCDL.2019.00063,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8791193,Deep learning;Patent literature;Automatic classification;Word embedding;Patent text mining,Patents;Deep learning;Feature extraction;Semantics;Analytical models;Logistics;Classification algorithms,classification;convolutional neural nets;information retrieval;learning (artificial intelligence);natural language processing;patents;pattern classification;regression analysis;text analysis,Chinese patent literature automatic classification;literature retrieval;deep learning technique;Word2Vec+GRU+TextCNN model;TFIDF+logistic regression model,,1,,5,,8-Aug-19,,,IEEE,IEEE Conferences
Using machine learning techniques for automatic evaluation of Web sites,使用機器學習技術對網站進行自動評估,M. Zorman; V. Podgorelec; P. Kokol; S. H. Babic,"Fac. of Electr. Eng. & Comput. Sci., Maribor Univ., Slovenia; NA; NA; NA",Proceedings Third International Conference on Computational Intelligence and Multimedia Applications. ICCIMA'99 (Cat. No.PR00300),6-Aug-02,1999,,,169,173,"We present an intelligent search tool which we developed in order to automate search and evaluation of Web sites. We used TFIDF heuristics to determine term frequency and decision trees to evaluate the quality of sites. Training set for the decision tree contained manually evaluated Web sites. Each Web site was described by the combination of various attributes, complexity metrics and the evaluation. The intelligent search tool is equipped with a user-friendly interface, which enables people to exploit the tool to its limits with minimum effort. For testing purposes, we looked for sites with different content. The set of sites which was the result of using the intelligent search tool has been evaluated by a group of students.",,0-7695-0300-4,10.1109/ICCIMA.1999.798523,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=798523,,Machine learning;Helium;Decision support systems;Fiber reinforced plastics,online front-ends;information resources;information retrieval;learning (artificial intelligence);decision trees;user interfaces;interactive systems;knowledge based systems,machine learning techniques;automatic evaluation;Web site evaluation;intelligent search tool;TFIDF heuristics;term frequency;decision trees;manually evaluated Web sites;complexity metrics;user-friendly interface,,2,,,,6-Aug-02,,,IEEE,IEEE Conferences
Text Similarity in Vector Space Models: A Comparative Study,向量空間模型中的文本相似性：比較研究,O. Shahmirzadi; A. Lugowski; K. Younge,EPFL; PatRF; EPFL,2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA),17-Feb-20,2019,,,659,666,"Automatic measurement of semantic text similarity is an important task in natural language processing. In this paper, we evaluate the performance of different vector space models to perform this task. We address the real-world problem of modeling patent-to-patent similarity and compare TFIDF (and related extensions), topic models (e.g., latent semantic indexing), and neural models (e.g., paragraph vectors). Contrary to expectations, the added computational cost of text embedding methods is justified only when: 1) the target text is condensed; and 2) the similarity comparison is trivial. Otherwise, TFIDF performs surprisingly well in other cases: in particular for longer and more technical texts or for making finer-grained distinctions between nearest neighbours. Unexpectedly, extensions to the TFIDF method, such as adding noun phrases or calculating term weights incrementally, were not helpful in our context.",,978-1-7281-4550-1,10.1109/ICMLA.2019.00120,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8999168,"text similarity , vector space model , text embedding , patent , big data",Patents;Semantics;Predictive models;Vocabulary;Context modeling;Task analysis;Computational modeling,natural language processing;nearest neighbour methods;patents;text analysis;vectors,patent-to-patent similarity;latent semantic indexing;neural models;paragraph vectors;text embedding methods;technical texts;nearest neighbours;TFIDF method;automatic measurement;semantic text similarity;natural language processing;vector space models,,,,19,,17-Feb-20,,,IEEE,IEEE Conferences
Latent Semantic Analysis Boosted Convolutional Neural Networks for Document Classification,潛在語義分析促進卷積神經網絡進行文檔分類,E. Gultepe; M. Kamkarhaghighi; M. Makrehchi,"Computer, and Software Engineering, University of Ontario Institute of Technology, Department of Electrical, Oshawa, ON, Canada; Computer, and Software Engineering, University of Ontario Institute of Technology, Department of Electrical, Oshawa, ON, Canada; Computer, and Software Engineering, University of Ontario Institute of Technology, Department of Electrical, Oshawa, ON, Canada","2018 5th International Conference on Behavioral, Economic, and Socio-Cultural Computing (BESC)",25-Apr-19,2018,,,93,98,"Convolutional neural networks (CNNs) have been shown to be effective in document classification tasks. CNNs can be setup using various architectures with many different parameter settings, which may make them difficult to implement. For many document classification tasks, data transformed with ngrams (typically using uni, bi, and trigrams) and term-frequency inverse-document-frequency (TFIDF) weighting are still considered effective baseline models when used with linear classifiers such as logistic regression, especially in smaller datasets with less than 500K observations. A parsimonious CNN baseline model for sentiment classification should replicate the easy use of linear methods. In this study, we introduce a Latent Semantic Analysis (LSA) based CNN model, in which natively trained LSA word vectors are used as input into parallel 1-dimensional convolutional layers (1D-CNNs). The LSA word vector model is obtained by applying singular value decomposition (SVD) on the data transformed by a unigram and TFIDF weighting. Thus, the convolutional layers are designed with window sizes that are best suited for LSA word vectors. This parsimonious LSA -based CNN model exceeds the accuracy of all linear classifiers utilizing ngrams with TFIDF on all analyzed datasets, with average improvement of 0.73% by the top performing LSA-based CNN models. This may be due to the fact that CNNs are better adept at capturing word relationships in phrases and sentences that are not necessarily in the training corpus. Furthermore, the LSA-based CNN model exceeds the performance of word2vec-based CNN models as well. Thus, the success of LSA-based CNNs may potentiate their use as a baseline in classification tasks alongside linear models. Also, we provide guiding principles to simplify the application of LSA-based CNNs in document classification tasks.",,978-1-7281-0207-8,10.1109/BESC.2018.8697314,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8697314,,Training;Task analysis;Biological system modeling;Vocabulary;Neural networks;Semantics;Analytical models,convolutional neural nets;pattern classification;singular value decomposition;text analysis,term-frequency inverse-document-frequency;TFIDF;linear classifiers;parsimonious CNN baseline model;sentiment classification;LSA word vectors;parallel 1-dimensional convolutional layers;LSA word vector model;parsimonious LSA;LSA-based CNN model;word2vec-based CNN models;linear models;document classification tasks;Latent Semantic Analysis boosted convolutional neural networks,,,,33,,25-Apr-19,,,IEEE,IEEE Conferences
An Efficient Text Classification Using fastText for Bahasa Indonesia Documents Classification,使用fastText進行印度尼西亞語文檔分類的高效文本分類,A. Amalia; O. S. Sitompul; E. B. Nababan; T. Mantoro,"Universitas Sumatera Utara,Department of Computer Science,Medan,Indonesia; Universitas Sumatera Utara,Department of Information Technology,Medan,Indonesia; Universitas Sumatera Utara,Department of Information Technology,Medan,Indonesia; Sampoerna University,Department of Computer Science,Jakarta,Indonesia","2020 International Conference on Data Science, Artificial Intelligence, and Business Analytics (DATABIA)",10-Sep-20,2020,,,69,75,"Text classification using a simple word representation with a linear classifier often considered as strong baselines to gain the best performances. However, a simple word representation like Bag of Word (BOW) has a deficiency of curse dimensionality, so it is only suitable for small datasets. BOW also needs some dependent pre-processing steps like stopwords-removal and stemming. Therefore, the BOW model cannot be implemented automatically because of the dependency in a specific language. On the other hand, deep neural network classifiers can eliminate the pre-processing prerequisite, but this model not efficient in time processing and need a large dataset for the learning process. It becomes a challenge for language that has limitation resources like Bahasa Indonesia. Another novel approach of text classifier is using the fastText model for text classification. This model can minimize pre-processing dependencies and more efficient in training time processing. However, there hasn't been much observation whether the fastText model outperformed the BOW model for small datasets. This paper aims to compare text classification using the TFIDF model as one of the BOW models with a fastText model for 500 news articles in Bahasa Indonesia. The result of this study showed both models gain an outstanding performance, which is 0.97 F-Score. The TFIDF model needs longer pre-processing stages and requiring more training time. Meanwhile, the fastText model only needs to tune some hyperparameters and get similar performance results to the TFIDF model. Based on this study, we can conclude that the fastText model is efficient text classification.",,978-1-7281-9792-0,10.1109/DATABIA50434.2020.9190447,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9190447,fastText;text classification;efficient text classification;Bahasa Indonesia,Text categorization;Neural networks;Training;Classification algorithms;Libraries;Machine learning;Semantics,learning (artificial intelligence);natural language processing;neural nets;pattern classification;text analysis,fastText model;BOW model;TFIDF model;text classification;Bahasa Indonesia documents classification;word representation;deep neural network classifiers;learning process;Bag of Word,,,,18,,10-Sep-20,,,IEEE,IEEE Conferences
Enhanced Topic Identification Algorithm for Arabic Corpora,阿拉伯語料庫的增強主題識別算法,A. Alsaad; M. Abbod,"Dept. of Electron. & Comput. Eng., Brunel Univ., Uxbridge, UK; Dept. of Electron. & Comput. Eng., Brunel Univ., Uxbridge, UK",2015 17th UKSim-AMSS International Conference on Modelling and Simulation (UKSim),26-Sep-16,2015,,,90,94,"During the past few years, the construction of digitalized content is rapidly increasing, raising the demand of information retrieval, data mining and automatic data tagging applications. There are few researches in this field for Arabic data due to the complex nature of Arabic language and the lack of standard corpora. In addition, most work focuses on improving Arabic stemming algorithms, or topic identification and classification methods and experiments. No work has been conducted to include an efficient stemming method within the classification algorithm, which would lead to more efficient outcome. In this paper, we propose a new approach to identify significant keywords for Arabic corpora. That is done by implementing advanced stemming and root extraction algorithm, as well as Term Frequency/Inverse Document Frequency (TFIDF) topic identification method. Our results show that combining advanced stemming, root extraction and TFIDF techniques, lead to extracting a highly significant terms represented by Arabic roots. These roots weights higher TFIDF values than terms extracted without the use of advanced stemming and root extraction methods. Decreasing the size of indexed words and improving the feature selection process.",,978-1-4799-8713-9,10.1109/UKSim.2015.77,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7576527,root extraction; feature selection; topic identification; natural language processing; data mining; text mining,Feature extraction;Text categorization;Classification algorithms;Algorithm design and analysis;Information retrieval;Internet,data mining;information retrieval;natural language processing;pattern classification;text analysis,feature selection process;root extraction methods;Arabic roots;TFIDF techniques;term frequency-inverse document frequency topic identification method;root extraction algorithm;classification algorithm;efficient stemming method;Arabic stemming algorithms;Arabic language;Arabic data;automatic data tagging applications;data mining;information retrieval;digitalized content construction;Arabic corpora;topic identification algorithm enhancement,,1,,17,,26-Sep-16,,,IEEE,IEEE Conferences
Formal concept analysis and document clustering via granular computing,通過粒度計算進行正式概念分析和文檔聚類,T. Y. Lin; I. Chiang,"Department of Computer Science, San Jose State Univ, CA, USA; Graduate Institute of Medical Informatics, Taipei Medical University, Taiwan","2006 IEEE International Conference on Systems, Man and Cybernetics",16-Jul-07,2006,6,,4763,4767,A text/web document is a knowledge representation of a human idea (a structured set of thoughts). This paper refines TFIDF and extended TFIDF(ETFIDF)[16]; These values really measures the co-occurrences of tokens. The ETFID captures the semantic more accurately. Tokens with high TFIDF values are called keywords. The sets of (n+1) Co-occurring keywords with High ETFIDF are called n-granules. The collection of keywords and n-granules can be interpreted geometrically; they form a non-closed simplicial complex. The corresponding non-closed polyhedron is called latent semantic space(LSS). LSS is a geometric knowledge base that provides the semantic to search engine.,1062-922X,1-4244-0099-6,10.1109/ICSMC.2006.385058,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4274667,Keyword;simplex;granules;Latent semantic space,Text analysis;Humans;Set theory;Cybernetics;Knowledge representation;Search engines;Topology;Extraterrestrial measurements;Uncertainty;Computer science,knowledge representation;pattern clustering;search engines;text analysis,formal concept analysis;document clustering;granular computing;text document;Web document;knowledge representation;extended TFIDF;token cooccurrences;keywords;latent semantic space;geometric knowledge base;search engine,,,,30,,16-Jul-07,,,IEEE,IEEE Conferences
Document Categorization with Entropy Based TF/IDF Classifier,使用基於熵的TF / IDF分類器對文檔進行分類,Y. Lu; Y. Huang,"Coll. of Inf. Eng., Zhejiang Univ. of Technologe, Hangzhou, China; NA",2009 WRI Global Congress on Intelligent Systems,21-Aug-09,2009,4,,269,273,"The task of text categorization is assigning a given text document to one or more predefined categories. High availability of digital data requires methods for automatic processing of this data. Day-by day increase of this digital data gives rise to the need of fast and better text classifiers. This paper mainly focuses on classifying data in context of text categorization. This paper reports a study conducted on 20 news group dataset, using TFIDF in the context of document categorization. Feature selection is added to this result to improvise the categorization. The results achieved using this algorithm are very promising when compared to conventional methods with features chosen on the basis of bag-of-words text.",2155-6091,978-0-7695-3571-5,10.1109/GCIS.2009.311,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5209295,TFIDF;Entropy;Mutual gain information,Entropy;Text categorization;Clustering algorithms;Mutual information;Information filtering;Information filters;Intelligent systems;Educational institutions;Availability;Computer science,text analysis,document categorization;entropy;TF/IDF classifier;text categorization;feature selection;bag-of-words text;mutual gain information,,3,,6,,21-Aug-09,,,IEEE,IEEE Conferences
Natural Language Processing and Classification Methods for the Maintenance and Optimization of US Weapon Systems,自然語言處理和分類方法,N. Bruno; T. Jun; H. Tessier,NA; NA; NA,2019 Systems and Information Engineering Design Symposium (SIEDS),13-Jun-19,2019,,,1,6,"The Logistics Management Institute (LMI) works with the US Department of Defense (DoD) in analyzing maintenance logs on US weapons systems. A major issue in processing this data is determining how to extract useful information from disorganized short-form texts in order to optimize the maintenance of these systems. Unlike text from other corpora, these text entries are only a few words in length and do not conform to lexical convention. LMI has provided a subset of about 10 million of these maintenance logs, each labeled with action-object pairs. The goals of this research are to construct a model that predicts action-object pairs and provide a metric to assess its validity. Prior to analysis, the entries are vectorized by either TFIDF and TSVD, or Word2vec. Several models are applied, including logistic regression, k-NN, SVM, decision trees, LSA, and DBSCAN clustering. Unsupervised models are tested in addition to supervised models due to the ambiguity regarding the validity of the provided ground truth values. The results of these tests yield accuracy scores of about 0.53 for action words and 0.73 for object words. Furthermore, the results from clustering provides evidence for discrepancies in the ground truth values. Taking this into consideration, prior models are adjusted and accuracy scores increased to 0.78 for action words.",,978-1-7281-0998-5,10.1109/SIEDS.2019.8735587,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8735587,Natural Language Processing;Text Mining;TFIDF;Word2vec,Maintenance engineering;Weapons;Pattern recognition;Natural language processing;Logistics;Dictionaries;Support vector machines,decision trees;logistics;military computing;military equipment;natural language processing;pattern classification;pattern clustering;regression analysis;support vector machines;text analysis;weapons,action-object pairs;Word2vec;logistic regression;unsupervised models;supervised models;action words;object words;prior models;natural language processing;classification methods;US weapon systems;LMI;maintenance logs;weapons systems;disorganized short-form texts;text entries;lexical convention;ground truth values,,,,14,,13-Jun-19,,,IEEE,IEEE Conferences
Bi-directional Relevance Matching between Medical Corpora,醫療語料庫之間的雙向關聯匹配,J. Yang; J. Ward; E. Gharavi; J. Dawson; R. Alvarado,NA; NA; NA; NA; NA,2019 Systems and Information Engineering Design Symposium (SIEDS),13-Jun-19,2019,,,1,6,"Readily available, trustworthy, and usable medical information is vital to promoting global health. Cochrane is a non-profit medical organization that conducts and publishes systematic reviews of medical research findings. Over 3000 Cochrane Reviews are presently used as evidence in Wikipedia articles. Currently, Cochrane's researchers manually search Wikipedia pages related to medicine in order to identify Wikipedia articles that can be improved with Cochrane evidence. Our aim is to streamline this process by applying existing document similarity and information retrieval methods to automatically link Wikipedia articles and Cochrane Reviews. Potential challenges to this project include document length and the specificity of the corpora. These challenges distinguish this problem from ordinary document representation and retrieval problems. For our methodology, we worked with data from 7400 Cochrane Reviews, ranging from one to several pages in length, and 33,000 Wikipedia articles categorized as medical. We explored different methods of document vectorization including TFIDF, LDA, LSA, word2Vec, and doc2Vec. For every document in both corpora, their similarity to each document in the opposing set was calculated using established vector similarity metrics such as cosine similarity and KL-divergence. Labeled data for this unsupervised task was not available. Models were evaluated by comparing the results to two standards: (1) Cochrane Reviews currently cited in Wikipedia articles and (2) a data set provided by a medical expert that indicates which Cochrane Reviews could be considered for specific Wikipedia articles. Our system performs best using TFIDF document representation and cosine similarity.",,978-1-7281-0998-5,10.1109/SIEDS.2019.8735639,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8735639,Document Similarity;Cochrane;Medical Document Analysis;Automated Citation Recommendation,Encyclopedias;Electronic publishing;Internet;Measurement;Information retrieval;Biomedical imaging,data mining;information retrieval;learning (artificial intelligence);medical information systems;natural language processing;pattern classification;text analysis;Web sites,medical expert;specific Wikipedia articles;medical corpora;usable medical information;nonprofit medical organization;medical research findings;search Wikipedia pages;document similarity;cochrane reviews;cochrane evidence;Cochrane researchers;bi-directional relevance matching;TFIDF;LDA;LSA;word2Vec;doc2vec;KL-divergence,,,,15,,13-Jun-19,,,IEEE,IEEE Conferences
Two-Step Ranking Document Using the Ontology-Based Causality Detection,使用基於本體的因果關係檢測的兩步排序文檔,A. A. I. N. Eka Karyawati; L. A. A. Rahning Putri,"Computer Science/Informatics Department, Udayana University, Bali, Indonesia; Computer Science/Informatics Department, Udayana University, Bali, Indonesia","2018 5th International Conference on Information Technology, Computer, and Electrical Engineering (ICITACEE)",16-Dec-18,2018,,,287,292,"Typically, answering a question automatically was performed by using keyword-based methods. These methods may work well for some simpler cases. However, to answer more complex questions such as why-questions, needs semantic-based method such as ontology-based method to detect the presence of causal relationships in documents. The proposed method considers the domain ontology to rank documents. The novelty of this research is a two-step document ranking method to answer questions, which uses a combination of it TFIDF and similarity based on causality-detection. The proposed method involves the proximity-based model for detecting the causality and also uses vector space model for representing the documents and the questions. The results showed a significant improvement of the baseline method (i.e., phrase-keyword method), where the it MRR values increase around 81 times, P@1 around 9.4 times, P@5 around 6 times, and P@10 around 6 times. The proposed method also improved the semantic it TFIDF method with query expansion, where the it MRR could be improved 80%, P@1 153%, P@5 45%, and P@10 improved 33%.",,978-1-5386-5529-0,10.1109/ICITACEE.2018.8576913,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8576913,Ontology-based information retrieval;Document retrieval;Proximity-based model;Why-question;Vector space model,Semantics;Ontologies;Mathematical model;Pattern matching;Information retrieval;Knowledge based systems;Indexes,causality;ontologies (artificial intelligence);query processing;question answering (information retrieval);text analysis,two-step ranking document;query expansion;question answering;TFIDF method;phrase-keyword method;baseline method;vector space model;proximity-based model;causal relationships;keyword-based methods;ontology-based causality detection,,,,20,,16-Dec-18,,,IEEE,IEEE Conferences
Automatic Text Classification of ICD-10 Related CoD from Complex and Free Text Forensic Autopsy Reports,從復雜和自由文本法醫驗屍報告中自動對ICD-10相關CoD進行文本分類,G. Mujtaba; L. Shuib; R. G. Raj; R. Rajandram; K. Shaikh,"Dept. of Inf. Syst., Univ. of Malaya, Kuala Lumpur, Malaysia; Dept. of Inf. Syst., Univ. of Malaya, Kuala Lumpur, Malaysia; Dept. of Artificial Intell., Univ. of Malaya, Kuala Lumpur, Malaysia; Dept. of Surg., Univ. of Malaya, Kuala Lumpur, Malaysia; Dept. of Community Med., Shaheed Mohtarma Benazir Bhutto Med. Univ., Larkana, Pakistan",2016 15th IEEE International Conference on Machine Learning and Applications (ICMLA),2-Feb-17,2016,,,1055,1058,"Forensic autopsy focuses on revealing the cause of death (CoD) by examination of a dead body. In this research study, various feature extraction schemes, feature value representation schemes and text classification algorithms have been applied on forensic autopsy reports to discover the suitable feature extraction approach, feature value representation approach and text classification approach. From experimental results, it was found that the unigram features outperformed bigram, trigram and hybrids of unigram, bigram and trigram features. Moreover, TF and TFiDF feature value representation schemes were proven more suitable than binary representation and normalized TFiDF schemes. Finally, SVM decision models outperformed RF and NB.",,978-1-5090-6167-9,10.1109/ICMLA.2016.0191,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7838295,Forensic Autopsy Reports;Machine Learning;Text Classification Techniques;Feature Extraction;Feature Value Representation Schemes,Autopsy;Feature extraction;Forensics;Support vector machines;Niobium;Radio frequency;Text categorization,decision making;digital forensics;feature extraction;pattern classification;support vector machines;text analysis,automatic text classification;ICD-10 related CoD;free text forensic autopsy reports;cause of death;dead body examination;feature extraction;unigram features;bigram features;trigram features;TFiDF feature value representation;TF feature value representation;SVM decision models,,6,,21,,2-Feb-17,,,IEEE,IEEE Conferences
A configurable-hardware document-similarity classifier to detect web attacks,用於檢測Web攻擊的可配置硬件文檔相似性分類器,C. Ulmer; M. Gokhale,"Sandia National Laboratories, CA, USA; Lawrence Livermore National Laboratory, USA","2010 IEEE International Symposium on Parallel & Distributed Processing, Workshops and Phd Forum (IPDPSW)",24-May-10,2010,,,1,8,"This paper describes our approach to adapting a text document similarity classifier based on the Term Frequency Inverse Document Frequency (TFIDF) metric to reconfigurable hardware. The TFIDF classifier is used to detect web attacks in HTTP data. In our reconfigurable hardware approach, we design a streaming, real-time classifier by simplifying an existing sequential algorithm and manipulating the classifier's model to allow decision information to be represented compactly. We have developed a set of software tools to help automate the process of converting training data to synthesizable hardware and to provide a means of trading off between accuracy and resource utilization. The Xilinx Virtex 5-LX implementation requires two orders of magnitude less memory than the original algorithm. At 166MB/s (80X the software) the hardware implementation is able to achieve Gigabit network throughput at the same accuracy as the original algorithm.",,978-1-4244-6534-7,10.1109/IPDPSW.2010.5470737,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5470737,,Frequency;Hardware;Laboratories;Training data;Throughput;Web pages;Algorithm design and analysis;Software tools;Network synthesis;Resource management,field programmable gate arrays;Internet;pattern classification;security of data;text analysis,configurable-hardware document;document similarity classifier;term frequency inverse document frequency;TFIDF metric;reconfigurable hardware;Web attack detection;Xilinx Virtex 5-LX,,2,,13,,24-May-10,,,IEEE,IEEE Conferences
Latent Semantic Analysis Model as a Representation of Free-Association Word Norms,潛在語義分析模型以自由聯想詞規範為代表,D. Ortega-Pacheco; N. Arias-Trejo; J. B. B. Mart穩nez,"Inst. Politec. Nac., Escuela Super. de Computo, Mexico City, Mexico; Fac. de Psicologia, Univ. Nac. Autonoma de Mexico, Mexico City, Mexico; Fac. de Psicologia, Univ. Nac. Autonoma de Mexico, Mexico City, Mexico",2012 11th Mexican International Conference on Artificial Intelligence,24-Dec-12,2012,,,21,25,"The current work aims to validate, by means of a computational model, an empirical database of free word association norms of Mexican Spanish. Specifically, this work has two main goals: (1) to detect the associated weight of word word pairs, and (2) to provide an understanding of a lexical network formed beyond an input-output word pair, similar to the mediated priming effect reported experimentally. We used the Term Frequency-Inverse Document Frequency weighting (TFIDF) to obtain the associated weight between an input output word pair and to calculate the TFIDF-Matrix which is used as an input in the Latent Semantic Analysis (LSA) Model. The LSA model is a semantic representation at the lexical level that allows us to understand semantic relationships beyond input-output word pairs. Our computational model replicates and further explains previous experimental work on lexical networks.",,978-1-4673-4731-0,10.1109/MICAI.2012.13,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6387240,Latent Semantic Analysis;TF IDF Weighting;Lexical Semantic Priming;Free Word-Association Norms,Artificial intelligence,matrix algebra;natural language processing;semantic Web;text analysis,latent semantic analysis model;free-association word norm;computational model;empirical database;free word association norm;Mexican Spanish;word-word pair;lexical network;input-output word pair;mediated priming effect;term frequency-inverse document frequency weighting;TFIDF-matrix;LSA model;lexical level semantic representation;semantic relationship understanding,,2,,23,,24-Dec-12,,,IEEE,IEEE Conferences
Machine intelligence based personality prediction using social profile data,使用社交檔案數據的基於機器智能的個性預測,G. V. Rohit; K. R. Bharadwaj; R. Hemanth; B. Pruthvi; M. V. Manoj Kumar,"Nitte Meenakshi Institute of Technology,Department of Information Science and Engineering,Bengaluru,Karnataka,India,560064; Nitte Meenakshi Institute of Technology,Department of Information Science and Engineering,Bengaluru,Karnataka,India,560064; Nitte Meenakshi Institute of Technology,Department of Information Science and Engineering,Bengaluru,Karnataka,India,560064; Nitte Meenakshi Institute of Technology,Department of Information Science and Engineering,Bengaluru,Karnataka,India,560064; Nitte Meenakshi Institute of Technology,Department of Information Science and Engineering,Bengaluru,Karnataka,India,560064",2020 Third International Conference on Smart Systems and Inventive Technology (ICSSIT),6-Oct-20,2020,,,1003,1008,"Social network usage is growing exponentially every day. Different information are typically exchanged via social media platforms such as Facebook. User knowledge and what they have conveyed through changes in status are useful for learning about the behavior and human personality assessment. This work aims at setting up a framework that can predict the individual's personality based on Facebook user details. In order to analyze the individual's personality, big five model is used. The aim of this research is to predict the personality of user by using the status information present in their social media profile. Based on the analysis result, the user's personality is further classified into one of the categories present in the OCEAN model. The accuracy of personality prediction achieved by using Random Forest Classifier is 64.25%. The mean squared error is achieved using random forest regressor is 5.25.",,978-1-7281-5821-1,10.1109/ICSSIT48917.2020.9214175,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9214175,Personality prediction;Big Five Model;Random Forest;TFIDF Vectorizer,Forestry;Facebook;Training;Analytical models;Oceans;Conferences,mean square error methods;pattern classification;random forests;regression analysis;social networking (online),human personality assessment;Facebook user details;big five model;status information;social media profile;machine intelligence based personality prediction;social profile data;social network usage;social media platforms;user knowledge;OCEAN model;random forest classifier;mean squared error;random forest regressor,,,,21,,6-Oct-20,,,IEEE,IEEE Conferences
Sentiment Analysis using Unlabeled Email data,使用未標記的電子郵件數據進行情感分析,R. S. Hag Ali; N. El Gayar,"Heriot-Watt University,School of Mathematical and Computer Science,Dubai,United Arab Emirates; Heriot-Watt University,School of Mathematical and Computer Science,Dubai,United Arab Emirates",2019 International Conference on Computational Intelligence and Knowledge Economy (ICCIKE),20-Feb-20,2019,,,328,333,"Sentiment Analysis (SA) in the context of text mining is an automated process to detect subjectivity information, such as opinions, attitudes, emotions and feeling. Most prior work in SA view it as a text classification problem which needs labeled data to train the model. However, it is tough to get a labeled dataset. Most of the times we will need to do it by hand. Another issue is that the lack of portability across different domains makes it hard to use the same labeled data in different applications. Thus, we need to create labeled data for each domain manually. In this paper, we will use sentiment analysis to analyze the Enron email dataset. This work aims to find the best techniques to label the dataset automatically and avoid manual labeling. The training data is used to build a classifier using a supervised machine learning algorithm. In the labeling phase, we compare the lexicon labeling with k-mean labeling. Lexicon labeling gave better and reliable results. We used this labeled dataset to train the classifier. We used TF-IDF for feature extraction, to train Na簿ve Bayes and Support vector machine (SVM) classifiers.",,978-1-7281-3778-0,10.1109/ICCIKE47802.2019.9004372,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9004372,Sentiment analysis;k-means;TFIDF;support vector machine,Electronic mail;Feature extraction;Sentiment analysis;Support vector machines;Data mining;Labeling,data mining;feature extraction;learning (artificial intelligence);pattern classification;sentiment analysis;support vector machines,sentiment analysis;unlabeled email data;text mining;text classification problem;labeled dataset;Enron email dataset;manual labeling;training data;labeling phase;lexicon labeling;k-mean labeling,,,,25,,20-Feb-20,,,IEEE,IEEE Conferences
The Use of Horizontal Visibility Graphs to Identify the Words that Define the Informational Structure of a Text,使用水平能見度圖識別定義文本信息結構的單詞,D. V. Lande; A. A. Snarskii; E. V. Yagunova; E. V. Pronoza,"Inst. for Inf. Recording NAS of Ukraine, NTUU ?Kiev Polytech. Inst.?? Kiev, Ukraine; Inst. for Inf. Recording NAS of Ukraine, NTUU ?Kiev Polytech. Inst.?? Kiev, Ukraine; St.-Petersburg State Univ., St. Petersburg, Russia; St.-Petersburg State Univ., St. Petersburg, Russia",2013 12th Mexican International Conference on Artificial Intelligence,23-Jan-14,2013,,,209,215,"A compactified horizontal visibility graph for the language network and identification of the words that define the informational structure of a text is proposed. It was found that the networks constructed in such a way are scale free, and have a property that among the nodes with largest degrees there are words that determine not only communicative text structure, but also its informational structure.",,978-1-4799-2605-3,10.1109/MICAI.2013.33,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6714670,horizontal visibility graph;language network;dispersion estimated value;TFIDF;text coherence;informational structure,Dispersion;Coherence;Complex networks;Signal processing algorithms;Rivers;Digital signal processing;Information retrieval,graph theory;network theory (graphs);text analysis,horizontal visibility graphs;text informational structure;language network;words identification;communicative text structure,,6,,23,,23-Jan-14,,,IEEE,IEEE Conferences
Bengali Fake News Detection,孟加拉假新聞檢測,F. Islam; M. M. Alam; S. M. Shahadat Hossain; A. Motaleb; S. Yeasmin; M. Hasan; R. M. Rahman,"North South University,Department of Electrical and Computer Engineering,Dhaka,Bangladesh; North South University,Department of Electrical and Computer Engineering,Dhaka,Bangladesh; North South University,Department of Electrical and Computer Engineering,Dhaka,Bangladesh; North South University,Department of Electrical and Computer Engineering,Dhaka,Bangladesh; North South University,Department of Electrical and Computer Engineering,Dhaka,Bangladesh; North South University,Department of Electrical and Computer Engineering,Dhaka,Bangladesh; North South University,Department of Electrical and Computer Engineering,Dhaka,Bangladesh",2020 IEEE 10th International Conference on Intelligent Systems (IS),18-Sep-20,2020,,,281,287,"Yellow journalism has become a buzzword for everyone nowadays. Increasing use of internet and social media makes people more vulnerable to fake news. To gain popularity and to have profit through clickbait news publisher and social media circulate fake news to deceive people by creating interesting content of a specific topic. The spread of falsified news has become severe in recent times throughout the world. Though recently some existing system is made to classify and to detect fake news for English news article, not much work has been reported for Bengali news. In this work, we consider Bengali fake news classification considering South Asian Context. More than 200 million people speak Bengali and their way of communication is Bengali. In our Bengali fake news classification system, data mining algorithm is used to classify fake and real news. We have also introduced web interface based on our classifier to check whether a news article written in Bengali language fake or real. The classification model has 85% accuracy with random forest classifier.",1541-1672,978-1-7281-5456-5,10.1109/IS48319.2020.9199931,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9199931,fakenews;datamining;nlp;bengaliparser;banglanews;random forest;na簿ve bayes;logistic regression;dtm;tfidf;textmining;facebook fake news,Feature extraction;Statistical analysis;IEEE Sections;Forestry;Facebook;Motion pictures,data mining;Internet;natural language processing;pattern classification;social networking (online);Web sites,Bengali fake news detection;social media;clickbait news publisher;falsified news;English news article;Bengali fake news classification system;Bengali language;web interface;data mining,,,,18,,18-Sep-20,,,IEEE,IEEE Conferences
Automatic Stopword Detection Using Term Ranking between Written and Machine Speech Recognition Transcribed Reviews,使用書面和機器語音識別轉錄評論之間的術語排名進行自動停用詞檢測,J. J. Hind; M. Mahyoub; D. Woods; C. Wong; A. Hussain; D. Al-Jumeily,LivingLens; LivingLens; LivingLens; LivingLens; Liverpool John Moores University; Liverpool John Moores University,2019 12th International Conference on Developments in eSystems Engineering (DeSE),23-Apr-20,2019,,,301,308,"Video feedback and machine speech recognition are fast-becoming a popular choice for companies to gain insight into their products. In conjunction with this, text analytics can be used to extract insight from these video translations. Currently, there is little work in the area to analyse and compare techniques for natural language processing, information retrieval and information extraction. A commonly practiced technique in text analytics is the extraction of stop words; words whose presence do not contribute context or information to a document. In this paper, we explore statistical techniques for the automated extraction of stop words, comparing 4 datasets from written and translated reviews. Using statistical variations of the successful technique `term ranking', we evaluate their performance using a common list of stop words. Results suggest that variation, TFnormIDFnorm, was the most successful with a best performing precision rate of 46.7% and a recall rate of 86.6%. The best results were seen in the largest dataset using written reviews, however comparison of the remaining 3 datasets revealed that spoken text performed 0.4% better in precision than the next best dataset and 2.6% better in recall. Initial results show marginally better performance in machine speech recognition transcribed texts from videos in comparison to comparably size datasets of written reviews.",2161-1351,978-1-7281-3021-7,10.1109/DeSE.2019.00063,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073508,Term Ranking;TFIDF;Machine Speech Recognition (MSR);stop words;marketing;reviews.,Ranking (statistics);Speech recognition;Measurement;Text mining;Dictionaries,information retrieval;natural language processing;speech recognition;statistical analysis;text analysis,written translated reviews;statistical variations;spoken text;automatic Stopword detection;transcribed reviews;video feedback;text analytics;video translations;natural language processing;information retrieval;information extraction;statistical techniques;term ranking;machine speech recognition transcribed reviews,,,,20,,23-Apr-20,,,IEEE,IEEE Conferences
On the Effectiveness of Extracting Important Words from Proxy Logs,從代理日誌中提取重要單詞的有效性,M. Mimura,"Nat. Defense Acad., Yokosuka, Japan",2018 Sixth International Symposium on Computing and Networking Workshops (CANDARW),27-Dec-18,2018,,,424,430,"Modern http-based malware imitates benign traffic to evade detection. To detect unseen malicious traffic, many methods using machine learning techniques have been proposed. These methods took advantage of the characteristic of malicious traffic, and usually require additional parameters which are not obtained from essential security devices such as a proxy server or IDS (Intrusion Detection System). Thus, most previous methods are not applicable to actual information systems. To tackle a realistic threat, a linguistic-based detection method for proxy logs has been proposed. This method extracts words as feature vectors automatically with natural language techniques, and discriminates between benign traffic and malicious traffic. The previous method generates a corpus from the whole extracted words which contain trivial words. To generate discriminative feature representation, a corpus has to be effectively summarized. This paper extracts important words from proxy logs to summarize the corpus. To define the word importance score, this paper uses term frequency and document frequency. Our method summarizes the corpus and improves the detection rate. We conducted cross-validation and timeline analysis with captured pcap files from Exploit Kit (EK) between 2014 and 2016. The experimental result shows that our method improves the accuracy. The best F-measure achieves 1.00 in the cross-validation and timeline analysis.",,978-1-5386-9184-7,10.1109/CANDARW.2018.00084,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8590938,"Proxy Log, Exploit Kit, Paragraph Vector, Doc2vec, TFIDF",Feature extraction;Servers;Information systems;Natural language processing;Malware;Machine learning;Security,feature extraction;invasive software;learning (artificial intelligence);natural language processing,proxy logs;benign traffic;machine learning techniques;essential security devices;proxy server;linguistic-based detection method;feature vectors;natural language techniques;discriminative feature representation;word importance score;intrusion detection system;information systems;http-based malware;malicious traffic;F-measure;cross-validation analysis;timeline analysis;exploit kit;term frequency;document frequency,,,,30,,27-Dec-18,,,IEEE,IEEE Conferences
Improving Government-Data Learning via Distributed Clustering Analysis,通過分佈式聚類分析改善政府數據學習,Y. Zhong,"Res. Inst. of Electron. Sci. & Technol., Univ. of Electron. Sci. Technol. of China, Chengdu, China",2016 7th International Conference on Cloud Computing and Big Data (CCBD),17-Jul-17,2016,,,231,236,"Clustering analysis is a study which is of great value, and the large-scale government-data needed to be handled by cluster analysis is growing increasingly. Efficient analysis techniques of large-scale data need to be adopted to handle the large-scale data. Traditional model of serial programming has serious scalability shortage, which don't satisfy the need of the large-scale government-data handling for computing and storage resources. Distributed computing technology represented by the MapReduce has good scalability, and can greatly improve the execution efficiency of data-intensive algorithm, and give play to the computing power of compute cluster based on general hardware. Based on the background of ""data platform for public petition"", it aims to study how to combine the cluster analysis technology with the current massive government-data, extracting useful information from the mass characteristics hidden in the data through the cluster analysis technology, which can provide comprehensive analyse for system managers and decision makers. This paper focus on the study of combining basic distributed clustering algorithm and TF-IDF algorithm, developing the cases feature analysis module based on distributed clustering algorithm. Based on distributed clustering algorithm, according to the information of the cases, do clustering analysis of cases according to its characteristics, and then get several hidden information through serveral decisional result.",,978-1-5090-3555-7,10.1109/CCBD.2016.053,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7979911,government-data;distributed clustering algorithm;TFIDF algorithm;parallel computing;feature selection;analysis of cases,Clustering algorithms;Algorithm design and analysis;Data models;Programming;Analytical models;Ecosystems;Distributed computing,data handling;government data processing;learning (artificial intelligence);parallel processing;pattern clustering;storage management,government-data learning improvement;distributed clustering analysis;large-scale government-data;storage resources;distributed computing;MapReduce;data-intensive algorithm;public petition;information extraction;TF-IDF algorithm,,,,11,,17-Jul-17,,,IEEE,IEEE Conferences
Extrovert and Introvert Classification based on Myers-Briggs Type Indicator(MBTI) using Support Vector Machine (SVM),支持向量機（SVM）基於Myers-Briggs類型指示符（MBTI）的外向和內向分類,M. N. Sahono; F. U. Sidiastahta; G. F. Shidik; A. Z. Fanani; Muljono; S. Nuraisha; E. Lutfina,"Universitas Dian Nuswantoro,Faculty of Computer Science,Semarang,Indonesia; Universitas Dian Nuswantoro,Faculty of Computer Science,Semarang,Indonesia; Universitas Dian Nuswantoro,Faculty of Computer Science,Semarang,Indonesia; Universitas Dian Nuswantoro,Faculty of Computer Science,Semarang,Indonesia; Universitas Dian Nuswantoro,Faculty of Computer Science,Semarang,Indonesia; Universitas Dian Nuswantoro,Faculty of Computer Science,Semarang,Indonesia; Universitas Dian Nuswantoro,Faculty of Computer Science,Semarang,Indonesia",2020 International Seminar on Application for Technology of Information and Communication (iSemantic),26-Oct-20,2020,,,572,577,"Personality is a characteristic of each individual who describes their behavior and influences their interactions with other individuals. Every individual has various way to express their feelings, one of them through social media. On social media, humans can create and share a variety of content about various objects, describe activities, to express their thoughts, opinions, and feelings. This study aims to classify human personalities based on the MBTI method that focused on Extrovert and Introvert class, seen from their tweets. Humans able to better understand and improve themselves by recognizing their weaknesses and strengths. The dataset used in this study is a public dataset from Kaggle, consists of 8676 data that posted on Twitter. Various feature combinations have been compared using Support Vector Machine (SVM) classifier. The deployment of solution have been described. Accuracies up to 84.07% were achieved using the methods detailed in this work.",,978-1-7281-9068-6,10.1109/iSemantic50169.2020.9234288,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9234288,personality classification;Extrovert;Introvert;Myers-Briggs Type Indicator (MBTI);TFIDF;Support Vector Machine,,pattern classification;psychology;social networking (online);support vector machines,SVM;social media;human personalities;MBTI method;public dataset;support vector machine classifier;extrovert classification;introvert classification;Myers-Briggs type indicator;Twitter,,,,14,,26-Oct-20,,,IEEE,IEEE Conferences
Utilizing User Generated Contents to describe Tourism Areas of Interest,利用用戶生成的內容來描述旅遊勝地,B. Devkota; H. Miyazaki; N. Pahari,"Asian Institute of Technology,Department of ICT,Pathumthani,Thailand; Asian Institute of Technology,Department of ICT,Pathumthani,Thailand; King Mongkut?s Institute of Technology Ladkrabang,Faculty of Engineering,Bangkok,Thailand",2019 First International Conference on Smart Technology & Urban Development (STUD),2-Mar-20,2019,,,1,6,"The use of available place databases (like GeoNames and traditional maps) to obtain descriptive keywords of a user-defined place is not possible because such data sources mainly maintain location definitions of the well-known places only. Traditional sources may not be updated dynamically and may not ensure diverse information. Additionally, they do not give any information on the popularity, e.g., which is more popular among the places indexed by the same keyword. A bottom-up approach, based on real user attention, can address these problems. We propose a method to describe tourism area of interest (TAOI) by aggregating user generated social media text. We match the co-occurrence of important keywords in a particular location and select such words to describe TAOIs. We applied the proposed method to data on micro blogging service Twitter and photo sharing service Flickr and confirmed that our method made it possible to extract TAOI description. The recommended bottom-up approach enables the extraction of valuable information that is not possible by using traditional top-down approaches.",,978-1-7281-6435-9,10.1109/STUD49732.2019.9018810,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9018810,Tourism Area of Interest;Twitter;Flickr;TFIDF;User Generated Contents,Flickr;Twitter;Semantics;Data mining;User-generated content;Databases,computer mediated communication;social networking (online);text analysis;travel industry,Flickr;Twitter;photo sharing service;micro blogging service;TAOI description;social media text;user attention;keyword;diverse information;location definitions;data sources;user-defined place;descriptive keywords;GeoNames;available place databases;tourism area;user generated contents,,,,20,,2-Mar-20,,,IEEE,IEEE Conferences
Semantic Keyword Selection for Automatic Video Annotation,自動視頻註釋的語義關鍵字選擇,A. S. Imran; L. Rahadianti; F. A. Cheikh; S. Y. Yayilgan,"Dept. of Comput. Sci. & Media Technol., Gjovik Univ. Coll., Gjovik, Norway; Dept. of Comput. Sci. & Media Technol., Gjovik Univ. Coll., Gjovik, Norway; Dept. of Comput. Sci. & Media Technol., Gjovik Univ. Coll., Gjovik, Norway; Dept. of Comput. Sci. & Media Technol., Gjovik Univ. Coll., Gjovik, Norway",2013 International Conference on Signal-Image Technology & Internet-Based Systems,30-Jan-14,2013,,,241,246,"Choosing descriptive keywords to best describe digital media content is crucial for many applications, especially those involving content-based indexing or retrieval. Traditionally such keywords are selected manually, which is labor intensive, restrictive to a limited set of words and inherently subjective to the annotator. Therefore, in this paper, we propose an automatic and objective keyword selection method for annotating video. We specifically used lecture videos and surrogate documents, e.g. transcripts, to extract potential candidate keywords. These potential keywords are then filtered based on a set of seed words to select fewer but more descriptive keywords. The seed words are extracted from the title of the video and subject category. We propose a new objective method to select top ranking keywords based on visual similarity and word sense disambiguation. To validate this approach, the selected keywords are compared to subjectively selected keywords obtained experimentally. Furthermore, the proposed ranking method is also compared to traditional term frequency inverse document frequency (TF-IDF) and state of the art latent dirichlet allocation (LDA) method. The obtained results show that the words selected by the proposed objective method correlate highly with those selected by viewers. In general, the proposed method performs better than TF-IDF and LDA.",,978-1-4799-3211-5,10.1109/SITIS.2013.49,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6727198,semantic keyword selection;video annotation;automatic;objective;descriptive;TFIDF;LVD-F,Semantics;Visualization;Context;Cancer;Physics;Vectors;Media,content-based retrieval;indexing;information filtering;natural language processing;video retrieval,semantic keyword selection;automatic video annotation;descriptive keyword;digital media content;content-based indexing;content-based retrieval;lecture video;surrogate document;seed word;subject category;visual similarity;word sense disambiguation;term frequency inverse document frequency;TF-IDF;latent Dirichlet allocation;LDA method,,,,20,,30-Jan-14,,,IEEE,IEEE Conferences
Efficient Exploration of Algorithm in Scholarly Big Data Document,學術大數據文檔中算法的高效探索,S. P. Vanjari; K. P. Balsaraf,"Department of Information Technology, ZOER, Narhe, Pune; Department of Information Technology, ZOER, Narhe, Pune","2018 International Conference on Information , Communication, Engineering and Technology (ICICET)",15-Nov-18,2018,,,1,5,"Algorithms are used to develop, analyzing, and applying in the computer field and used for developing new application. It is used for finding solutions to any problems in different condition. It transforms the problems into algorithmic ones on which standard algorithms are applied. Day by day Scholarly Digital documents are increasing. AlgorithmSeer is a search engine used for searching algorithms. The main aim of it provides a large algorithm database. It is used to automatically encountering and take these algorithms in this big collection of documents that enable algorithm indexing, searching, discovery, and analysis. An original set to identify and pull out algorithm representations in a big collection of scholarly documents is proposed, of scale able techniques used by AlgorithmSeer. Along with this, particularly important and relevant textual content can be accessed the platform and highlight portions by anyone with different levels of knowledge. In support of lectures and self-learning, the highlighted documents can be shared with others. But different levels of learners cannot use the highlighted part of text at same understanding level. The problem of guessing new highlights of partially highlighted documents can be solved by us.",,978-1-5386-5510-8,10.1109/ICICET.2018.8533779,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8533779,Algorithms;Pseudo codes;Scholarly big data;Sentence Extractor;Steaming;TFIDF,Machine learning algorithms;Search engines;Portable document format;Data mining;Metadata;Software algorithms;Indexing,Big Data;document handling;Internet;learning (artificial intelligence);search engines,algorithm database;algorithm indexing;algorithm representations;AlgorithmSeer;search engine;searching algorithms;scholarly Big Data document;textual content;scholarly digital documents;self-learning,,,,10,,15-Nov-18,,,IEEE,IEEE Conferences
Keep It Simple with Time: A Reexamination of Probabilistic Topic Detection Models,與時俱進：概率主題檢測模型的重新檢驗,Q. He; K. Chang; E. Lim; A. Banerjee,"Pennsylvania State University, State College; Nanyang Technological University, Singapore; Singapore Management University, Singapore; University of Minnesota, Twin Cities, Minneapolis",IEEE Transactions on Pattern Analysis and Machine Intelligence,19-Aug-10,2010,32,10,1795,1808,"Topic detection (TD) is a fundamental research issue in the Topic Detection and Tracking (TDT) community with practical implications; TD helps analysts to separate the wheat from the chaff among the thousands of incoming news streams. In this paper, we propose a simple and effective topic detection model called the temporal Discriminative Probabilistic Model (DPM), which is shown to be theoretically equivalent to the classic vector space model with feature selection and temporally discriminative weights. We compare DPM to its various probabilistic cousins, ranging from mixture models like von-Mises Fisher (vMF) to mixed membership models like Latent Dirichlet Allocation (LDA). Benchmark results on the TDT3 data set show that sophisticated models, such as vMF and LDA, do not necessarily lead to better results; in the case of LDA, notably worst performance was obtained under variational inference, which is likely due to the significantly large number of LDA model parameters involved for document-level topic detection. On the contrary, using a relatively simple time-aware probabilistic model such as DPM suffices for both offline and online topic detection tasks, making DPM a theoretically elegant and effective model for practical topic detection.",1939-3539,,10.1109/TPAMI.2009.203,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5374412,Topic detection;probabilistic model;time-aware;bursty feature;online;DPM;TFIDF.,Linear discriminant analysis;Event detection;Hurricanes;Frequency;Mathematical model;Nominations and elections;Finance;Data mining;Character generation,document handling;information retrieval;probability,probabilistic topic detection models;topic detection and tracking;news streams;temporal discriminative probabilistic model;feature selection;latent dirichlet allocation;TDT3 data set;vMF,,45,,44,,8-Jan-10,,,IEEE,IEEE Journals
Vector space model for Arabic information retrieval ??application to ?Hadith??indexing,向量空間模型在阿拉伯語信息檢索中的應用,F. Harrag; A. Hamdi-Cherif; E. El-Qawasmeh,"Computer Science Dept, UFAS University, S矇tif, Algeria; Computer College, Qassim University, Buraydah, Saudi Arabia; Computer Science Dept, JUST University, Irbid, Jordan",2008 First International Conference on the Applications of Digital Information and Web Technologies (ICADIWT),31-Oct-08,2008,,,107,112,"The Arabic language is one of the most important languages because it is the sacred and liturgical language of Islam, one of the influential monotheistic religions of our times. In the post-9/11 aftermath, Islam suddenly dominated western actuality for the remaining years of the present decade. Al-Qurpsilaan - The Reading par Excellence - and ldquoHadithrdquo - Saying - represent the two fundamental scriptural sources of Islamic Legislation. Specifically, ldquoHadithrdquo, or Prophetic Traditions, are sayings and doings of the Prophet of Islam (Peace and Blessings be upon Him). Researchers need automatic search tools within large ldquoHadithrdquo databasesto access one of the original sources of Islam. For this purpose, we describe the development of AuthenTique, an updated automatic text mining search tool, based on the vector space model (VSM). The aim is to allow the provision of a list of ldquoHadithsrdquo classified according to their degrees of similarity based on a given userpsilas query.",,978-1-4244-2623-2,10.1109/ICADIWT.2008.4664328,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4664328,Text Mining;Information Retrieval;TFIDF Weighting;UML;Arabic Language Processing,,data mining;humanities;indexing;information retrieval;text analysis,vector space model;Arabic information retrieval;Hadith indexing;Al-Qurpsilaan;Islamic legislation;prophetic traditions;updated automatic text mining search tool,,4,,13,,31-Oct-08,,,IEEE,IEEE Conferences
Spam Mails Filtering Using Different Classifiers with Feature Selection and Reduction Technique,使用特徵選擇和歸約技術使用不同分類器過濾垃圾郵件,A. K. Sharma; R. Yadav,"Dept. of Comput. Sci. & Eng., ICFAI Univ., Jaipur, India; IBM India Pvt. Ltd., Pune, India",2015 Fifth International Conference on Communication Systems and Network Technologies,1-Oct-15,2015,,,1089,1093,"The continuous growth of email users has resulted in the increasing of unsolicited emails also known as Spam. Incurrent, server side and client side anti spam filters are introduced for detecting different features of spam emails. However, recently spammers introduced some effective tricks consisting of embedding spam contents into digital image, pdf and doc as attachment which can make ineffective to current techniques that is based on analysis digital text in the body and subject fields of email. Many of proposed working strategy provides an anti spam filtering approach that is based on data mining techniques which classify the spam and ham emails. The effectiveness of these approaches is evaluated on large corpus of simple text dataset as well as text embedded image dataset. But most of the filtering techniques are unable to handle frequent changing scenario of spam mails adopted by the spammers over the time. Therefore improved spam control algorithms or enhancing the efficiency of various existing data mining algorithms to its fullest extent are the utmost requirement. A comparative study is presented on various spam filtering techniques adopted on the basis of various attributes to find best among all to extract the best results.",,978-1-4799-1797-6,10.1109/CSNT.2015.11,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7280088,Component Analysis;Correlation Feature Selection;PCA;Bayesian Classifiers;SVM;J48;LMT;Stemming;TFIDF,Principal component analysis;Bayes methods;Support vector machines;Postal services;Unsolicited electronic mail;Data mining,data mining;feature selection;information filtering;text analysis;unsolicited e-mail,spam mails filtering;feature selection techniques;reduction techniques;email users;unsolicited emails;server side antispam filters;client side antispam filters;embedding spam contents;digital image;data mining techniques;ham emails;text embedded image dataset;spam control algorithms,,2,,15,,1-Oct-15,,,IEEE,IEEE Conferences
"TF-SIDF: Term frequency, sketched inverse document frequency",TF-SIDF：術語頻率，草繪的反向文檔頻率,M. Baena-Garc穩a; J. M. Carmona-Cejudo; G. Castillo; R. Morales-Bueno,"Dpto. Lenguajes y Ciencias de la Computation, Universidad de Malaga, Spain; Dpto. Lenguajes y Ciencias de la Computation, Universidad de Malaga, Spain; Department of Mathematics, University of Aveiro, Portugal; Dpto. Lenguajes y Ciencias de la Computation, Universidad de Malaga, Spain",2011 11th International Conference on Intelligent Systems Design and Applications,2-Jan-12,2011,,,1044,1049,"Exact calculation of the TF-IDF weighting function in massive streams of documents involves challenging memory space requirements. In this work, we propose TF-SIDF, a novel solution for extracting relevant words from streams of documents with a high number of terms. TF-SIDF relies on the Count-Min Sketch data structure, which allows to estimate the counts of all the terms in the stream. Results of the experiments conducted with two dataset show that this sketch-based algorithm achieves good approximations of the TF-IDF weighting values (as a rule, the top terms with highest TF-IDF values remaining the same), while substantial savings in memory usage are observed. It is also observed that the performance is highly correlated with the sketch size, and that wider sketch configurations are preferable given the same sketch size.",2164-7151,978-1-4577-1676-8,10.1109/ISDA.2011.6121796,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6121796,text mining;tfidf;count-min sketch,Approximation methods;Measurement;Radiation detectors;Correlation;Data structures;Intelligent systems;Graphics,data mining;data structures;storage management;text analysis,TF-SIDF;term frequency;sketched inverse document frequency;exact calculation;TF-IDF weighting function;massive streams;memory space requirements;count-min sketch data structure;sketch-based algorithm;TF-IDF weighting values;memory usage;sketch size;sketch configurations,,5,,11,,2-Jan-12,,,IEEE,IEEE Conferences
Online calculation of word-clouds for efficient label summarization,在線計算詞云以實現有效的標籤匯總,J. M. Carmona-Cejudo; M. Baena-Garc穩a; G. Castillo; R. Morales-Bueno,"Dpto. Lenguajes y Ciencias de la Computati籀n, Universidad de M獺laga, Spain; Dpto. Lenguajes y Ciencias de la Computati籀n, Universidad de M獺laga, Spain; Department of Mathematics, University of Aveiro, Portugal; Dpto. Lenguajes y Ciencias de la Computati籀n, Universidad de M獺laga, Spain",2011 11th International Conference on Intelligent Systems Design and Applications,2-Jan-12,2011,,,1056,1061,"Large amounts of information are available on the Internet in the form of natural language text that can be processed as a stream of documents. Users need solutions that summarize the vast volume of data. Word clouds are a popular graphical representation approach that allows them to obtain such a quick visual summary. Nevertheless, the exact solution to this problem has high memory requirements, and is not scalable as the collection size grows up. In this work, we provide a method for approximate online computation of word clouds to summarize the contents of each label or category of a given text stream, using only the most relevant terms of each document according to some weighting function. We experimentally show that our method, based on sketching techniques, obtains a good performance while using a restricted quantity of memory.",2164-7151,978-1-4577-1676-8,10.1109/ISDA.2011.6121798,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6121798,text mining;tfidf;count-min sketch,Tag clouds;Radiation detectors;Approximation methods;Data structures;Visualization;Memory management;Intelligent systems,functions;Internet;natural language processing;text analysis;word processing,Internet;natural language text stream;graphical representation approach;quick visual summary;approximate online computation;word cloud;weighting function;sketching technique,,,,13,,2-Jan-12,,,IEEE,IEEE Conferences
A P2P-Based Semantic Web Services Composition Architecture,基於P2P的語義Web服務組合架構,Z. Zhengdong; H. Yahong; L. Ronggui; W. Weiguo; L. Zengzhi,"Dept. of Comput., Xi'an JiaoTong Univ., Xi'an, China; Dept. of Comput., ZheJiang Univ. of Technol., Hangzhou, China; Dept. of Comput., Xi'an JiaoTong Univ., Xi'an, China; Dept. of Comput., Xi'an JiaoTong Univ., Xi'an, China; Dept. of Comput., Xi'an JiaoTong Univ., Xi'an, China",2009 IEEE International Conference on e-Business Engineering,1-Dec-09,2009,,,403,408,"In order to improve the scalability, reliability and stability of the semantic Web service composition system, and to achieve ontology-based semantic Web services composition efficiently, this paper presents a P2P-based Semantic Web services (P2PSWS) composition system architecture. This architecture combines the advantages of centralized and decentralized structures. It distributes the functions of UDDI to the local Web nodes, and groups Web nodes and public Web nodes. This paper designs a localized mechanism of semantic Web services in CAN-based P2P networks to ensure that each service is registered in a specific node of the public Web. The registration services of public Web nodes are divided by the area and shared by all nodes. The running result of finished prototype system shows that the P2PSWS structure helps to overcome the problem ""the failure of a single node"" on the traditional structure of public Web services and expands the capacity of a P2P system, and that the P2PSWS structure achieves an efficient ontology-based semantic Web services composition.",,978-0-7695-3842-6,10.1109/ICEBE.2009.63,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5342084,Semantic Web Service;Web Service Composition;P2P;CAN;TFIDF,Semantic Web;Service oriented architecture;Web services;Ontologies;Sections;Computer architecture;Scalability;Stability;Markup languages;OWL,peer-to-peer computing;semantic Web;software architecture;software reliability;Web services,P2P-based semantic Web services composition architecture;ontology-based semantic Web services composition;local Web nodes;groups Web nodes;public Web nodes;CAN-based P2P networks,,7,,16,,1-Dec-09,,,IEEE,IEEE Conferences
Improve text classification accuracy based on classifier fusion methods,基於分類器融合方法提高文本分類精度,A. Danesh; B. Moshiri; O. Fatemi,"Dept. of Elec. & Comp. Eng. University of Tehran, Iran; Control & Intelligent Processing Center of Excellence, University of Tehran, Iran; Dept. of Elec. & Comp. Eng., University of Tehran, Iran",2007 10th International Conference on Information Fusion,26-Dec-07,2007,,,1,6,"Naive-Bayes and k-NN classifiers are two machine learning approaches for text classification. Rocchio is the classic method for text classification in information retrieval. Based on these three approaches and using classifier fusion methods, we propose a novel approach in text classification. Our approach is a supervised method, meaning that the list of categories should be defined and a set of training data should be provided for training the system. In this approach, documents are represented as vectors where each component is associated with a particular word. We proposed voting methods and OWA operator and decision template method for combining classifiers. Experimental results show that these methods decrese the classification error 15 percent as measured on 2000 training data from 20 newsgroups dataset.",,978-0-662-45804-3,10.1109/ICIF.2007.4408196,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4408196,Text Classification;Na簿ve-Bayes;K-NN;Rocchio;TFIDF;OWA;Decision Template;Voting;Classifier Fusion,Text categorization;Machine learning;Training data;Voting;Open wireless architecture;Classification tree analysis;Linear discriminant analysis;Neural networks;Process control;Intelligent control,Bayes methods;classification;decision theory;information retrieval;learning (artificial intelligence);sensor fusion;text analysis,text classification;machine learning;k-NN classifier;naive-Bayes classifier;information retrieval;decision template method;voting method;OWA operator;Rocchio algorithm,,16,,14,,26-Dec-07,,,IEEE,IEEE Conferences
Similarity measures for title matching,標題匹配的相似性度量,N. Gali; R. Mariescu-Istodor; P. Fr瓣nti,"School of Computing, University of Eastern Finland, Joensuu, Finland; School of Computing, University of Eastern Finland, Joensuu, Finland; School of Computing, University of Eastern Finland, Joensuu, Finland",2016 23rd International Conference on Pattern Recognition (ICPR),24-Apr-17,2016,,,1548,1553,"In many web applications, users query a place name, a photo name, and other entity names using search words that include alternate spellings, abbreviations, and variants that are similar, but not identical to the title associated with the desired entity. Given two titles, an effective similarity measure should be able to determine whether the titles represent the same entity or not. In this paper, we evaluate 21 measures with the aim of detecting the most appropriate measure for matching the titles. Results show that Soft-TFIDF performs the best.",,978-1-5090-4847-2,10.1109/ICPR.2016.7899857,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7899857,similarity measures;title matching;web mining;information retrieval,Biomedical measurement;Computers;Frequency measurement;Ontologies;Weight measurement;Computer science;Information retrieval,data mining;information retrieval;pattern matching,title matching;similarity measures;Soft-TFIDF;Web mining;information retrieval,,9,,25,,24-Apr-17,,,IEEE,IEEE Conferences
Implementation of emotional features on satire detection,諷刺檢測中情感特徵的實現,P. P. Thu; N. New,"University of Computer Studies, Mandalay, Mandalay, Myanmar; University of Computer Studies, Mandalay, Mandalay, Myanmar","2017 18th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)",31-Aug-17,2017,,,149,154,"Recognition of satirical language in social multimedia outlets turn out to be a trending research area in computational linguistics. Many researchers have analyzed satirical language from various point of views: lexically, syntactically, and semantically. However, due to the ironic dimension of emotion embedded in satirical language, emotional study of satirical language has ever left behind. In this study, we propose the new emotion-based satire detection model using supervised and unsupervised weighting approaches (TFRF and TFIDF). We implement the model with Ensemble Bagging classifier compared with benchmark classifier: SVM. The model not only outperform the word-based baseline: BoW but also handle both short text and long text configurations. Our work in recognition of satirical language can aid in lessening the impact of implicit language in public opinion mining, sentiment analysis, fake news detection and cyberbullying.",,978-1-5090-5504-3,10.1109/SNPD.2017.8022715,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8022715,Satire Detection;Emotion Recognition;Supervised and Unsupervised Weighting Approaches,Computational modeling;Feature extraction;Emotion recognition;Support vector machines;Analytical models;Indexes;Computational linguistics,natural language processing;pattern classification;text analysis;unsupervised learning,emotional feature;satire detection;satirical language recognition;social multimedia outlets;computational linguistics;supervised weighting approach;unsupervised weighting approach;TFRF approach;TFIDF approach;ensemble bagging classifier;short text configuration;long text configuration;public opinion mining;sentiment analysis;fake news detection;cyber bullying,,2,,21,,31-Aug-17,,,IEEE,IEEE Conferences
Amrita-CEN-SentiDB: Twitter Dataset for Sentimental Analysis and Application of Classical Machine Learning and Deep Learning,Amrita-CEN-SentiDB：Twitter數據集，用於經典機器學習和深度學習的情感??分析和應用,K. S. Naveenkumar; R. Vinayakumar; K. P. Soman,"Amrita Vishwa Vidyapeetham,Center for Computational Engineering and Networking (CEN) Amrita School of Engineering,Coimbatore,Tamil Nadu,India; Amrita Vishwa Vidyapeetham,Center for Computational Engineering and Networking (CEN) Amrita School of Engineering,Coimbatore,Tamil Nadu,India; Amrita Vishwa Vidyapeetham,Center for Computational Engineering and Networking (CEN) Amrita School of Engineering,Coimbatore,Tamil Nadu,India",2019 International Conference on Intelligent Computing and Control Systems (ICCS),16-Apr-20,2019,,,1522,1527,"Social media is a platform in which the data is generated each and every day in an abundance manner. The data is so large that cannot be easily understood, so this has paved a path to a new field in the information technology which is natural language processing. In this paper, we use the text data for classification of tweets that determines the state of the person according of the sentiments which is positive, negative and neutral. Emotions are common between humans which has a way to express it that decides the person's feelings which has a high influence on the decision making tasks. Here we have proposed the text representation, Term Frequency Inverse Document Frequency (tfidf), Keras embedding along with the machine learning and deep learning algorithms for classification of the sentiments, out of which Logistics Regression machine learning based methods out performs well when the features is taken in the limited amount as the features increases Support Vector Machine (SVM) that belongs to machine learning algorithm out performs well making a benchmark accuracy for this dataset as the 75.8%. The dataset is made publically available for research purpose.",,978-1-5386-8113-8,10.1109/ICCS45141.2019.9065337,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9065337,Twitter;Sentiment;Sentiment Analysis;Text Representation;Machine learning;Deep learning,Feature extraction;Machine learning;Social network services;Support vector machines;Databases;Tagging;Task analysis,decision making;learning (artificial intelligence);neural nets;pattern classification;regression analysis;sentiment analysis;social networking (online);support vector machines;text analysis,Twitter dataset;sentimental analysis;machine learning;social media;information technology;natural language processing;text data;decision making tasks;text representation;term frequency inverse document frequency;deep learning algorithms;logistics regression;support vector machine;machine learning algorithm;Amrita-CEN-SentiDB;tfidf,,,,21,,16-Apr-20,,,IEEE,IEEE Conferences
A study on text classification based on stacked contractive auto-encoder,基於堆疊壓縮自動編碼器的文本分類研究,Y. Yu; J. Hui,"School of Information, Qilu University of Technology, JiNan, China; School of Information, Qilu University of Technology, JiNan, China",2017 First International Conference on Electronics Instrumentation & Information Systems (EIIS),22-Feb-18,2017,,,1,6,"In order to improve the classification effect of text classification and reduce the error rate of classification, this paper proposes the thought of text classification based on Stacked Contractive Auto-Encoder (SCAE) by stacking network layer by layer, the SCAE constitutes the depth of the neural network by unsupervised training and learning text to improve the robustness of feature extraction, the network uses the gradient descent algorithm to optimize parameters of the network. This paper adopts an improved TFIDF method calculating the weight of feature words. Though experiments, the CAE and SAE (Sparse Auto-Encoder) are compared, the support vector machine (SVM) is used to classify text. Experiment result shows that the classification performance of single layer CAE is better than that of single layer SAE, and the classification performance of SCAE is better than that of SSAE (Stacked Sparse Auto-Encoder).",,978-1-5386-0843-2,10.1109/EIIS.2017.8298701,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8298701,Auto-Encoder;Contractive Auto-Encoder;Sparse Auto-Encoder;Stacked Contractive Auto-Encoder;SVM;Text Classification,Feature extraction;Text categorization;Robustness;Neurons;Classification algorithms;Training;Encoding,feature extraction;neural nets;pattern classification;support vector machines;text analysis;unsupervised learning,stacked sparse auto-encoder;support vector machine;SVM;SAE;CAE;improved TFIDF method;learning text;unsupervised training;neural network;network layer;SCAE;stacked contractive auto-encoder;text classification,,,,12,,22-Feb-18,,,IEEE,IEEE Conferences
Lightly supervised learning from a damaged natural speech corpus,從受損的自然語音語料庫中進行輕微的監督學習,C. Fox; T. Hain,"Department of Computer Science, University of Sheffield, UK; Department of Computer Science, University of Sheffield, UK","2013 IEEE International Conference on Acoustics, Speech and Signal Processing",21-Oct-13,2013,,,8086,8090,"Large corpora of transcribed speech are rare and expensive to acquire, but valuable for ASR systems. Of current research interest are corpora of natural speech, i.e. far-field recordings of multiple speakers in noisy environments. In the big data era there are many speech transcriptions collected for purposes other than ASR, which omit features required by typical ASR systems such as timing information. If we could recover training data from such `found' corpora this would open up large new resources for ASR research. We present a case study for this type of data recovery - becoming known as `lightly supervised learning' - for a highly damaged corpus called Family Life. We use a novel comparison of a parallel decode and forced audio alignment to iteratively select and grow good data. Family Life also has unusual data mislabelling problems which can be addressed by an integrated tfidf approach. These methods reduce WER on the corpus from 83.0 to 57.2. We also discuss a probabilistic loose string alignment approach which removes untranscribed `icebreaker' speech.",2379-190X,978-1-4799-0356-6,10.1109/ICASSP.2013.6639240,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6639240,,Interviews;Hidden Markov models;Training;Speech;Timing;Error analysis;Acoustics,learning (artificial intelligence);natural language processing;speech recognition,transcribed speech;ASR systems;natural speech;speech transcriptions;training data;data recovery;lightly supervised learning;highly damaged corpus;Family Life;parallel decode;forced audio alignment;probabilistic loose string alignment approach;WER;integrated tfidf approach;data mislabelling problem,,,,17,,21-Oct-13,,,IEEE,IEEE Conferences
Building A Document Class Hierarchy for Obtaining More Proper Bibliographies from Web,建立文檔類層次結構以從Web獲取更多正確的書目,Daling Wang; Ge Yu; Minghan Hu; Yubin Bao; Meng Zhang,"School of Information Science and Engineering, Northeastern University Shenyang 110004, P.R.China; Sch. of Inf. Sci. & Eng., Northeastern Univ., Shenyang; Sch. of Inf. Sci. & Eng., Northeastern Univ., Shenyang; Sch. of Inf. Sci. & Eng., Northeastern Univ., Shenyang; Sch. of Inf. Sci. & Eng., Northeastern Univ., Shenyang",International Workshop on Challenges in Web Information Retrieval and Integration,12-Dec-05,2005,,,214,219,"In order for researchers in scientific and technological fields to find more proper information resources on Web, an auxiliary search structure is proposed, which is a class hierarchy of documents built based on the keywords of the documents. To cover the contents of the document properly, the keywords are extracted by means of mining maximal sequential frequent phrases. In this paper, the concept of maximal sequential frequent phrase is defined, and the corresponding mining algorithm is designed and implemented. The experiments show that keywords extraction using maximal sequential frequent phrase has better F-measure than that of using traditional TFIDF weight. Moreover, compared with previous works, our extended class hierarchy tree represents a relationship hierarchy either between keywords themselves or between keywords and documents, by which the queries on different professional levels can be supported",,0-7695-2414-1,10.1109/WIRI.2005.13,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1553016,,Bibliographies;Information resources;Search engines;Books;Information science;Data mining;Algorithm design and analysis;Internet;Proposals;Writing,data mining;Internet;search engines;text analysis,document class hierarchy;bibliographies;World Wide Web;information resources;auxiliary search structure;document keywords;maximal sequential frequent phrase mining;keyword extraction;TFIDF weight,,,,16,,12-Dec-05,,,IEEE,IEEE Conferences
Source Code Authorship Attribution Using Hybrid Approach of Program Dependence Graph and Deep Learning Model,程序依賴圖和深度學習模型混合方法的源代碼作者身份歸屬,F. Ullah; J. Wang; S. Jabbar; F. Al-Turjman; M. Alazab,"College of Computer Science, Sichuan University, Chengdu, China; School of Aeronautics and Astronautics, College of Computer Science, Sichuan University, Chengdu, China; Department of Computing and Mathematics, Manchester Metropolitan University, Manchester, U.K.; Artificial Intelligence Department, Near East University, Nicosia, Turkey; College of Engineering, IT & Environment, Charles Darwin University, Casuarina, NT, Australia",IEEE Access,7-Oct-19,2019,7,,141987,141999,"Source Code Authorship Attribution (SCAA) is to find the real author of source code in a corpus. Though, it is a privacy threat to open-source programmers, but, it may be significantly helpful to develop forensic based applications. Such as, ghostwriting detection, copyright dispute settlements, and other code analysis applications. The efficient features extraction is the key challenge for classifying real authors of specific source codes. In this paper, the Program Dependence Graph with Deep Learning (PDGDL) methodology is proposed to identify authors from different programming source codes. First, the PDG is implemented to extract control and data dependencies from source codes. Second, the preprocessing technique is applied to convert PDG features into small instances with frequency details. Third, the Term Frequency Inverse Document Frequency (TFIDF) technique is used to zoom the importance of each PDG feature in source code. Fourth, Synthetic Minority Over-sampling Technique (SMOTE) is applied to tackle the class imbalance problem. Finally, the deep learning algorithm is applied to extract coding styles' features for each programmer and to attribute the real authors. The deep learning algorithm is further fine-tuned with drop out layer, learning error rate, loss and activation function, and dense layers for better accuracy of results. The proposed work is analyzed on 1000 programmers' data, collected from Google Code Jam (GCJ). The dataset contains three different programming languages, i.e., C++, Java, C#. The results are appreciable in outperforming the existing techniques from the perspective of classification accuracy, precision, recall, and f-measure metrics.",2169-3536,,10.1109/ACCESS.2019.2943639,"National Basic Research Program of China (973 Program); National Natural Science Foundation of China; Technology Research Development Program of Sichuan, China; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8848478,Code authorship attribution;program dependence graph;deep learning;software forensics and security;software plagiarism,Feature extraction;Encoding;Programming;Malware;Deep learning;Forensics,authorisation;C# language;C++ language;feature extraction;graph theory;Java;learning (artificial intelligence);neural nets;pattern classification;program compilers;program diagnostics;public domain software;source code (software);text analysis,Program Dependence Graph;Deep Learning model;Source Code Authorship Attribution;open-source programmers;code analysis;feature extraction;PDG feature;Term Frequency Inverse Document Frequency technique;deep learning algorithm;Google Code Jam;source Code Authorship Attribution;programming source codes;TFIDF;synthetic minority over-sampling technique;SMOTE;C++ language;Java language;C# language,,2,,45,CCBY,25-Sep-19,,,IEEE,IEEE Journals
Using n-best recognition output for extractive summarization and keyword extraction in meeting speech,使用n最佳識別輸出進行會議語音的提取摘要和關鍵字提取,Y. Liu; S. Xie; F. Liu,"The University of Texas at Dallas, Richardson, USA; The University of Texas at Dallas, Richardson, USA; The University of Texas at Dallas, Richardson, USA","2010 IEEE International Conference on Acoustics, Speech and Signal Processing",28-Jun-10,2010,,,5310,5313,"There has been increasing interest recently in meeting understanding, such as summarization, browsing, action item detection, and topic segmentation. However, there is very limited effort on using rich recognition output (e.g., recognition confidence measure or more recognition candidates) for these downstream tasks. This paper presents an initial study using n-best recognition hypotheses for two tasks, extractive summarization and keyword extraction. We extend the approach used on 1-best output to n-best hypotheses: MMR (maximum marginal relevance) for summarization and TFIDF (term frequency, inverse document frequency) weighting for keyword extraction. Our experiments on the ICSI meeting corpus demonstrate promising improvement using n-best hypotheses over 1-best output. These results suggest worthy future studies using n-best or lattices as the interface between speech recognition and downstream tasks.",2379-190X,978-1-4244-4295-9,10.1109/ICASSP.2010.5494972,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5494972,summarization;keyword extraction;n-best hypotheses,Speech recognition;Automatic speech recognition;Data mining;Lattices;Frequency;Humans;Broadcasting;Degradation;Natural languages;Information management,feature extraction;speech processing;speech recognition,n-best recognition output;extractive summarization;keyword extraction;meeting speech;browsing;action item detection;topic segmentation;recognition confidence measure;recognition candidates;n-best recognition hypotheses;MMR;maximum marginal relevance;TFIDF weighting;term frequency inverse document frequency,,9,,22,,28-Jun-10,,,IEEE,IEEE Conferences
Retrieving and ranking short medical questions with two stages neural matching model,使用兩階段神經匹配模型檢索和排序簡短的醫學問題,X. Li; X. Fu; Z. Lu; R. Bai; U. Aickelin; P. Ge; G. Liu,"School of Computer Science, University of Nottingham, Ningbo, China; School of Computer Science, University of Nottingham, Ningbo, China; School of Computer Science, University of Nottingham, Ningbo, China; School of Computer Science, University of Nottingham, Ningbo, China; School of Computing and Information Systems, University of Melbourne, Melbourne, Austrialia; Technology Dept, Ping An Health Cloud, Ping An, Shanghai; Technology Dept, Ping An Health Cloud, Ping An, Shanghai",2019 IEEE Congress on Evolutionary Computation (CEC),8-Aug-19,2019,,,873,879,"Internet hospital is a rising business thanks to recent advances in mobile web technology and high demand of health care services. Online medical services become increasingly popular and active. According to US data in 2018, 80 percent of internet users have asked health-related questions online. Numerous data is generated in unprecedented speed and scale. Those representative questions and answers in medical fields are valuable raw data sources for medical data mining. Automated machine interpretation on those sheer amount of data gives an opportunity to assist doctors to answer frequently asked medical-related questions from the perspective of information retrieval and machine learning approaches. In this work, we propose a novel two-stage framework for the semantic matching of query-level medical questions, which takes advantages of sentence similarity-based search engine techniques and Siamese inspired recent recurrent neural network. The two-stage hierarchical design optimises the performance of automatic information retrieval of user queries. Compared against the classical TFIDF search technique as a single-stage, our novel soft search technique performs significantly better. Incorporating an advanced deep learning model as the second stage can improve the results further, which we believe is the new state-of-the-art in the current problem setting with the unique medical corpus from one of the largest online healthcare provider in market.",,978-1-7281-2153-6,10.1109/CEC.2019.8790326,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8790326,machine learning;information retrieval;medical questions answering,Semantics;Standards;Medical services;Recurrent neural networks;Search engines;Computer science,data mining;health care;information retrieval;Internet;learning (artificial intelligence);medical information systems;natural language processing;search engines;text analysis,health-related questions;medical data mining;automated machine interpretation;medical-related questions;machine learning approaches;semantic matching;query-level medical questions;sentence similarity-based search engine techniques;two-stage hierarchical design optimises;automatic information retrieval;user queries;soft search technique;mobile web technology;health care services;online medical services;US data;recurrent neural network;deep learning model;medical corpus;neural matching model;Internet hospital;medical questions;TFIDF search technique,,,,30,,8-Aug-19,,,IEEE,IEEE Conferences
Multi-schema matching based on clustering techniques,基於聚類技術的多模式匹配,Guohui Ding; Tianhe Sun; Yingnan Xu,"School of Computer, Shenyang Aerospace University, China; School of Electronic Information Engineering, Shenyang Aerospace University, China; School of Graduate, Shenyang Aerospace University, China",2013 10th International Conference on Fuzzy Systems and Knowledge Discovery (FSKD),19-May-14,2013,,,778,782,"Schema matching plays an important role in many database applications, such as ontology merging, data integration, data warehouse and dataspaces. The problem of schema matching is to find the semantic correspondence between attributes of schemas to be matched. In this paper, we propose multi-schema matching based on clustering techniques. Traditional matching techniques mainly address matching tasks between two attributes, namely pairwise-attribute correspondence. However, there exist lots of applications that require the semantic correspondence among multiple attributes. Thus, we will focus on matching multiple attributes, which is more difficult than pairwise-attribute correspondence. We employ the clustering techniques to solve the multi-schema matching problem. We use the well-known TFIDF weighting method to convert each attribute in schemas to a point in the vector space model. Then, these attributes can be partitioned into different clusters each of which has a specific semantics topic. Finally, the attributes partitioned into the same cluster are similar with higher confidence. We validate our approach with an experimental study, the results of which demonstrate that our approach is effective and has good performance.",,978-1-4673-5253-6,10.1109/FSKD.2013.6816299,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6816299,,Vectors;Semantics;Measurement;Clustering algorithms;Partitioning algorithms;Accuracy;Educational institutions,data integration;data warehouses;database management systems;merging;ontologies (artificial intelligence);pattern clustering;vectors,dataspaces;data warehouse;data integration;ontology merging;vector space model;TFIDF weighting method;pairwise-attribute correspondence;database applications;clustering techniques;multischema matching,,,,18,,19-May-14,,,IEEE,IEEE Conferences
Similarity Evaluation of English Translations of the Holy Quran,古蘭經英語譯本的相似性評價,M. Z. Murah,"Center for Artificial Intell. Technol., Univ. Kebangsaan Malaysia, Bangi, Malaysia",2013 Taibah University International Conference on Advances in Information Technology for the Holy Quran and Its Sciences,28-Sep-15,2013,,,228,233,"In this paper, similarity evaluation of English translations of the Holy Quran using four computational methods is performed. The computational methods are bag of words, term-frequency, tfidf and latent semantic indexing. We used twenty-one translation pairs from seven English translations (Hilali, Yusuf Ali, Sahih, Shakir, Arberry, Pickthall, Maududi) in our experiments. The similarity measures were evaluated pair wise. Based on our results, seven translations pair have high similarity measures, (Hilali, Yusuf Ali), (Hilali, Sahih), (Sahih, Shakir), (Hilali, Pickthall), (Pickthall, Shakir), (Hilali, Shakir), (Shakir, Arberry). We have nine translation pairs with low similarity measures, (Hilali, Maududi), (Maududi, Pick-thall), (Maududi, Yusuf Ali), (Hilali, Arberry), (Arberry, Yusuf Ali), (Maududi, Arberry), (Pickthall, Yusuf Ali), (Shahih, Yusuf Ali), (Pickthall, Sahih). These results from a computational perspective offer new insights into the similarity evaluation between the English translations based on computation methods. Also, we concluded the translations of (Hilali, Sahih, Shakir, Yusuf Ali, Pickthall) could be clustered into one group, and the translations of (Maududi, Arberry) into another group. These results could be used for classification of English translations and for comparing future translations.",,978-1-4799-2823-1,10.1109/NOORIC.2013.54,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7277251,similarity measures;Quran translations,Semantics;Indexing;Frequency measurement;Computational linguistics;Computational modeling;Matrix decomposition;Natural language processing,indexing;language translation;pattern clustering,similarity evaluation;English translations;Holy Quran;computational methods;bag of words;term-frequency;tfidf;latent semantic indexing;translation pairs;Hilali;YusufAli;Sahih;Shakir;Arberry;Pickthall;Maududi;pairwise evaluation,,,,17,,28-Sep-15,,,IEEE,IEEE Conferences
From keywords to social tags: Tagging for dialogues,從關鍵字到社交標籤：為對話添加標籤,Guannan Fang; Caixia Yuan; Xiaojie Wang; Jiang Li; Zhanjiang Song,"Center for Intelligence Science and Technology, Beijing University of Posts and Telecommunications, China; Center for Intelligence Science and Technology, Beijing University of Posts and Telecommunications, China; Center for Intelligence Science and Technology, Beijing University of Posts and Telecommunications, China; Nokia Research Center, Beijing, China; Nokia Research Center, Beijing, China",2011 7th International Conference on Natural Language Processing and Knowledge Engineering,26-Jan-12,2011,,,106,113,"This paper proposes an unsupervised method for generating informative tags for multi-party dialogue in an open domain. Our model first extracts keywords from text through a multi-weighting framework, which includes frequency weighting, sentence weighting, speaker weighting and position weighting. Then we get their bigrams through frequent pattern matching. In order to generate more flexible and socialized tags, we expand keywords and their bigrams by exploring tag associations mined from a famous bookmarking web del.icio.us. Finally we rank the three parts of tag candidates under a uniform metric. Unlike previous models used for tag recommendation task, our model needs neither seed tags for source texts nor a complete tag set. It can recommend new tags out of the historical tag set. We evaluate our methods on 10,265 Chinese dialogues. Experimental results show our method outperform previous models like TextRank, TFIDF rank and KNN.",,978-1-61284-729-0,10.1109/NLPKE.2011.6138177,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6138177,bigram;social tag;dialogue;multi-weighting;tag association,Linux;Delta modulation;Electronic publishing,interactive systems;social networking (online),keyword extraction;social tags;informative tag generation;multiparty dialogue;multiweighting framework;frequency weighting;sentence weighting;speaker weighting;position weighting;pattern matching;bigrams;Web del.icio.us;TextRank;TFIDF rank;KNN,,1,,24,,26-Jan-12,,,IEEE,IEEE Conferences
Children story classification based on structure of the story,基於故事結構的兒童故事分類,Harikrishna D M; K. S. Rao,"School of Information Technology, Indian Institute of Technology, Kharagpur, India; School of Information Technology, Indian Institute of Technology, Kharagpur, India","2015 International Conference on Advances in Computing, Communications and Informatics (ICACCI)",28-Sep-15,2015,,,1485,1490,"The main objective of this work is to classify Hindi and Telugu stories based on their structure into three genres: Fable, Folk-tale and Legend. In this work, each story is divided into three parts: (i) introduction, (ii) main and (iii) climax. The objective of this work is to explore how story genre information is embedded in different parts of the story. We are proposing a framework for story classification using keyword and Part-of-speech (POS) based features. Keyword based features like Term Frequency (TF) and Term Frequency Inverse Document Frequency (TFIDF) are used. Classification performance is analyzed for different story parts using various combinations of features with three classifiers: (i) Naive Bayes (NB), (ii) k-Nearest Neighbour (KNN) and (iii) Support Vector Machine (SVM). From the experimental studies, it has been observed that classification performance has not significantly improved by combining linguistic (POS) and keyword based features. Among classifiers, SVM outperformed the other classifiers. The main part of the story has the highest classification accuracy compared to introduction and climax parts of the story.",,978-1-4799-8792-4,10.1109/ICACCI.2015.7275822,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7275822,Story Classification;Text-to-Speech;Part-of-Speech;Vector Space Model;Naive Bayes;KNN;SVM;Structure of Story;Introduction;Main;Climax,Support vector machines;Niobium;Accuracy;Handheld computers;Text categorization;Informatics;Machine learning algorithms,Bayes methods;document handling;linguistics;natural language processing;pattern classification;speech synthesis;support vector machines,children story classification;story structure;classify;Hindi story classification;Telugu story classification;fable;folk-tale;legend;story genre information;part-of-speech;POS based feature;term frequency inverse document frequency;TFIDF;classification performance;naive Bayes classifier;NB classifier;k-nearest neighbour classifier;KNN classifier;support vector machine classifier;SVM classifier;linguistic;keyword based features;story speech synthesis system,,9,,17,,28-Sep-15,,,IEEE,IEEE Conferences
Combining content with user preferences for TED lecture recommendation,將內容與用戶喜好結合起來以進行TED演講推薦,N. Pappas; A. Popescu-Belis,"Idiap Research Institute, Rue Marconi 19, 1920 Martigny, Switzerland; Idiap Research Institute, Rue Marconi 19, 1920 Martigny, Switzerland",2013 11th International Workshop on Content-Based Multimedia Indexing (CBMI),8-Aug-13,2013,,,47,52,"This paper introduces a new dataset and compares several methods for the recommendation of non-fiction audiovisual material, namely lectures from the TED website. The TED dataset contains 1,149 talks and 69,023 profiles of users, who have made more than 100,000 ratings and 200,000 comments. This data set, which we make public, can be used for training and testing of generic and personalized recommendation tasks. We define content-based, collaborative, and combined recommendation methods for TED lectures and use cross-validation to select the best parameters of keyword-based (TFIDF) and semantic vector space-based methods (LSI, LDA, RP, and ESA). We compare these methods on a personalized recommendation task in two settings, a cold-start and a non-cold-start one. In the former, semantic-based vector spaces perform better than keyword-based ones. In the latter, where collaborative information can be exploited, content-based methods are outperformed by collaborative filtering ones, but the proposed combined method shows acceptable performances, and can be used in both settings.",1949-3991,978-1-4799-0956-8,10.1109/CBMI.2013.6576551,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6576551,,Semantics;Collaboration;Vectors;Large scale integration;Training;Computational modeling;Measurement,audio-visual systems;collaborative filtering;computer aided instruction;content-based retrieval;recommender systems,user preferences;TED lecture recommendation;nonfiction audio-visual material;TED Website;TED dataset;personalized recommendation tasks;generic recommendation tasks;content-based recommendation methods;collaborative recommendation methods;combined recommendation methods;cross-validation;keyword-based parameters;TFIDF;semantic vector space-based methods;noncold-start settings;semantic-based vector spaces;collaborative information;collaborative filtering,,8,,17,,8-Aug-13,,,IEEE,IEEE Conferences
A Dynamic Graph Model for Analyzing Streaming News Documents,用於分析流新聞文檔的動態圖模型,E. L. Hohman; D. J. Marchette,"Naval Surface Warfare Center, Dahlgren, VA 22448. Email: elizabeth.hohman@navy.mil; Naval Surface Warfare Center, Dahlgren, VA 22448. Email: david.marchette@navy.mil",2007 IEEE Symposium on Computational Intelligence and Data Mining,4-Jun-07,2007,,,462,469,"In this paper we consider the problem of analyzing streaming documents, in particular streaming news stories. The system is designed to extract statistics from the document, incorporate these into a graph-based model, and discard the document to reduce storage requirements. The model is defined in terms of a changing lexicon and sub-lexicons at each node in the graph, with the nodes of the graph representing topics. An approximation to the TFIDF term weighting is introduced. We illustrate the methodology on a dataset of news articles, and discuss the dynamic nature of the model",,1-4244-0705-2,10.1109/CIDM.2007.368911,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4221335,,Text processing;Frequency;Computational intelligence;Data mining;Statistics;Text categorization;Keyboards;Feeds;Electronic mail;Traffic control,document handling;graph theory,dynamic graph model;analyzing streaming news documents;lexicon;TFIDF term weighting,,,,14,,4-Jun-07,,,IEEE,IEEE Conferences
An Ensemble Learning for Detecting Situational Awareness Tweets during Environmental Hazards,在環境危害中檢測情境意識推文的整體學習,A. Alshehri; S. Alahamri,"Dept. of Computer Science and Engineering, University of South Florida Tampa, Florida, 33620; Dept. of Computer Science and Engineering, University of South Florida Tampa, Florida, 33620",2019 IEEE International Systems Conference (SysCon),16-Sep-19,2019,,,1,8,"The shift to social media platforms like Twitter during environmental hazards and emergencies has expanded recently. Yet, the classification of situational awareness tweet based on people post is a complicated process due to the high dimensionality of features. In this empirical study, A framework using machine learning and Natural Language Processing techniques was developed for two-stage binary classification of Twitter data. The First stage consists of four models: Random Forest, Support Vector Machine, Naive Bayes and Decision Trees. Whereas, the second stage includes an ensemble learning approach. Text features - TFIDF (term frequency, inverse document frequency), psychometric, and linguistic - were analyzed as predictors of binary classification to categorize each tweet as situational relevant or irrelevant automatically. A manually built and labeled dataset of 4,000 tweets were analyzed for situational awareness of environmental health hazards in Barbados from water, mosquito-borne diseases, and sewage during the period 2014 - 2018. Based on the experiment, our model was able to achieve over 85% accuracy on classifying tweets that contribute to situational awareness. Furthermore, the results indicate that applying ensemble learning in the second stage showed superior results compared to the combined features-based classification models.",2472-9647,978-1-5386-8396-5,10.1109/SYSCON.2019.8836814,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8836814,Ensemble learning;Barbados;Sewage;Environmental health;Text mining;Social media;Crisis;NLP,Twitter;Diseases;Natural language processing;Hazards;Linguistics;Oils,decision trees;diseases;environmental science computing;health care;learning (artificial intelligence);natural language processing;pattern classification;social networking (online);support vector machines;text analysis,environmental health hazards;environmental hazards;social media platforms;machine learning;two-stage binary classification;Support Vector Machine;term frequency inverse document frequency;tweets classification;natural language processing;Twitter data classification;ensemble learning;TFIDF;situational awareness tweet detection;psychometric;linguistic;random forest;naive Bayes;decision trees,,,,37,,16-Sep-19,,,IEEE,IEEE Conferences
A novel approach for ontology-based dimensionality reduction for web text document classification,基於本體的Web文本文檔分類降維的新方法,M. K. Elhadad; K. Badran; G. I. Salama,"Computer department, Military Technical College, Cairo, Egypt; Computer department, Military Technical College, Cairo, Egypt; Computer department, Military Technical College, Cairo, Egypt",2017 IEEE/ACIS 16th International Conference on Computer and Information Science (ICIS),29-Jun-17,2017,,,373,378,"Dimensionality reduction of feature vector size plays a vital role in enhancing the text processing capabilities; it aims in reducing the size of the feature vector used in the mining tasks (classification, clustering... etc.). This paper proposes an efficient approach to be used in reducing the size of the feature vector for web text document classification process. This approach is based on using WordNet ontology, utilizing the benefit of its hierarchal structure, to eliminate words from the generated feature vector that has no relation with any of WordNet lexical categories; this leads to the reduction of the feature vector size without losing information on the text. For mining tasks, the Vector Space Model (VSM) is used to represent text documents and the Term Frequency Inverse Document Frequency (TFIDF) is used as a term weighting method. The proposed ontology based approach was evaluated against the Principal component analysis (PCA) approach using several experiments. The experimental results reveal the effectiveness of our proposed approach against other traditional approaches to achieve a better classification accuracy, F-measure, precision, and recall.",,978-1-5090-5507-4,10.1109/ICIS.2017.7960021,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7960021,Dimensionality reduction;Principal component analysis;Feature Extraction;Feature Selection;WordNet;Ontology;web text documents classification;Semantic similarity;Vector Space Model;Term Frequency Inverse Document Frequency,Feature extraction;Ontologies;Classification algorithms;Semantics;Algorithm design and analysis;Principal component analysis;Databases,data mining;Internet;ontologies (artificial intelligence);pattern classification;principal component analysis;text analysis;vectors,PCA;principal component analysis;TFIDF;term frequency inverse document frequency;VSM;vector space model;WordNet lexical categories;WordNet ontology;mining tasks;feature vector;Web text document classification;ontology-based dimensionality reduction,,5,,33,,29-Jun-17,,,IEEE,IEEE Conferences
Matching Reviews to Database Objects Based on Labeled Latent Dirichlet Allocation Model,基於標記潛在狄利克雷分配模型的數據庫對象評論匹配,Y. Zhu; Q. Li; Y. Zhu,"Sch. of Comput. Sci. & Technol., Shandong Univ., Jinan, China; Sch. of Comput. Sci. & Technol., Shandong Univ., Jinan, China; NA",2013 10th Web Information System and Application Conference,27-Mar-14,2013,,,48,51,"We develop a method for matching unstructured reviews to database objects in data integration, where each object has a set of attributes. To this end, we propose a Labeled Latent Dirichlet Allocation model. We model reviews as if they were generated by a two-stage stochastic process. Each review is represented by a probability distribution over attributes, and each attribute is represented as a probability distribution over words for that attribute. We introduce the label for each attribute, and then the model integrates object information. We use an unsupervised manner to estimate the model parameters, and use this model to find, given a review, the most likely object to be the topic of the review. Experiments in multiple domains show that our method is superior to the TFIDF method as well as a recent RLM method for the review matching problem.",,978-1-4799-3219-1,10.1109/WISA.2013.18,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6778609,Latent Dirichlet Allocatio;Gibbs sampling;review matching;data integration,Resource management;Motion pictures;Databases;Probability distribution;Accuracy;Data integration;Information retrieval,data integration;database management systems;parameter estimation;statistical distributions;stochastic processes,RLM method;TFIDF method;model parameter estimation;probability distribution;two-stage stochastic process;data integration;labeled latent Dirichlet allocation model;database objects;unstructured review matching,,1,,20,,27-Mar-14,,,IEEE,IEEE Conferences
Mining Relevant Examples for Learning in ITS Student Models,在ITS學生模型中挖掘學習相關實例,R. Chaturvedi; C. I. Ezeife,"Sch. of Comput. Sci., Univ. of Windsor, Windsor, ON, Canada; Sch. of Comput. Sci., Univ. of Windsor, Windsor, ON, Canada",2014 IEEE International Conference on Computer and Information Technology,15-Dec-14,2014,,,743,750,"An Intelligent Tutoring System (ITS) provides direct customized instruction or feedback to students while they perform a task in a tutoring system without the intervention of a human. One of the main functions of an ITS system is to present its students with course materials that are most appropriate to their current knowledge of domain concepts, example being one of the course materials. ITS systems typically compare and analyze student model (SM) components for student's current knowledge of concepts (main topics, e.g. Scanf in C programming) that are required to understand the next example (e.g. Codes for scanf) suitable for learning a task (e.g. Write C code to read 2 integers from the keyboard). Existing systems such as NavEx and PADS perform an exhaustive matching of student knowledge level with all examples in the database. This research proposes a task-based technique for managing and classifying examples for more effective retrieval of relevant examples for learning a task. We propose a system called EASK for translating task and example solutions into concepts for similarity matching, which is more readily available, easily extendible and adaptable to other domains. Examples and tasks are represented as vectors of weights computed with term frequency measure TFIDF that signify the importance of a concept for an example. Examples most similar to a task are found by using a classification method called k-NN, which finds the closeness between different objects such as examples and tasks using cosine similarity measure and selecting the k objects (examples) with highest similarity scores. As a by-product, k-NN also predicts the class label (difficulty level) of the task. Our proposed model achieves this prediction with 89% accuracy.",,978-1-4799-6239-6,10.1109/CIT.2014.31,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6984744,adaptation;data mining;classification;example-based Learning;student model,Vectors;Computational modeling;Materials;Indexes;Analytical models;Adaptation models,data mining;educational courses;intelligent tutoring systems;pattern classification,relevant example mining;ITS student models;intelligent tutoring system;course materials;C programming;NavEx systems;PADS systems;task-based technique;EASK;similarity matching;TFIDF;k-NN classification method;cosine similarity measure,,1,,8,,15-Dec-14,,,IEEE,IEEE Conferences
The Effect of Combining Different Feature Selection Methods on Arabic Text Classification,組合不同特徵選擇方法對阿拉伯文字分類的影響,A. Al-Thubaity; N. Abanumay; S. Al-Jerayyed; A. Alrukban; Z. Mannaa,"Comput. Res. Inst., King Abdulaziz City for Sci. & Technol., Riyadh, Saudi Arabia; Comput. Res. Inst., King Abdulaziz City for Sci. & Technol., Riyadh, Saudi Arabia; Coll. of Comput. & Inf. Sci., Imam Univ. Riyadh, Riyadh, Saudi Arabia; Coll. of Comput. & Inf. Sci., Imam Univ. Riyadh, Riyadh, Saudi Arabia; Coll. of Comput. & Inf. Sci., King Saud Univ., Riyadh, Saudi Arabia","2013 14th ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing",16-Sep-13,2013,,,211,216,"Feature selection is one of several factors affecting text classification systems. Feature selection aims to choose a representative subset of all features to reduce the complexity of classification problems. Usually a single method is used for feature selection. For English, several attempts were reported examining the combination of different feature selection methods. To the best of our knowledge no such attempts were reported for Arabic text classification. In this study, we examined the effect of combining five feature selection methods, namely CHI, IG, GSS, NGL and RS, on Arabic text classification accuracy. Two approaches of combination were used, intersection (AND) and union (OR). The NB classification algorithm was used to classify a Saudi Press Agency dataset which comprised 6,300 texts divided evenly into six classes. Three feature representation schemas were used, namely Boolean, TFiDF and LTC. The experiments show slight improvement in classification accuracy for combining two and three feature selection methods. No improvement on classification accuracy was seen when four or all five feature selection methods were combined.",,978-0-7695-5005-3,10.1109/SNPD.2013.89,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6598468,Arabic text classification;feature selection;feature representation;classification algorithms;classification accuracy,Accuracy;Diversity reception;Text categorization;Classification algorithms;Niobium;Educational institutions;Computers,classification;natural language processing;text analysis,feature selection methods;Arabic text classification;Saudi Press Agency dataset;representative subset;CHI;IG;GSS;NGL;RS;intersection combination;union combination;Boolean;TFiDF;LTC,,6,,12,,16-Sep-13,,,IEEE,IEEE Conferences
Analysis of inverse class frequency in centroid-based text classification,基於質心的文本分類中逆類頻率的分析,V. Lertnattee; T. Theeramunkong,"Inf. Technol. Program, Sirindhorn Int. Inst. of Technol., Maung, Thailand; NA","IEEE International Symposium on Communications and Information Technology, 2004. ISCIT 2004.",11-Apr-05,2004,2,,1171,1176 vol.2,"Most previous works on text categorization applied term occurrence frequency and inverse document frequency for representing importance of terms. This work presents an analysis of inverse class frequency in centroid-based text categorization. There are two aims of this paper. The first one is to find appropriate functions of inverse class frequency. The other is to find the key factors for using inverse class frequency. The experimental results show that the key factors, which improve classification accuracy, are the numbers of few-class terms and most-class terms. When large numbers of few-class terms and most-class terms are obtained, the logarithmic function of inverse class frequency is the most effective when it is combined with term frequency. The square root of inverse class frequency incorporated into TFIDF, works well in the case when data sets include a small number of few-class terms and most-class terms. To increase the numbers of these effective terms, some methods are involved i.e. using higher gram models, small number of classes and large number of training sets.",,0-7803-8593-4,10.1109/ISCIT.2004.1413903,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1413903,,Frequency;Text categorization;Electronic mail;Information resources;Information technology;Bayesian methods;Neural networks;Support vector machines;Support vector machine classification;Prototypes,text analysis;pattern classification;statistical analysis,inverse class frequency;centroid-based text classification;text categorization;classification accuracy;few-class terms;most-class terms;term frequency;TFIDF,,8,,15,,11-Apr-05,,,IEEE,IEEE Conferences
Metric learning for text documents,文本文檔的公制學習,G. Lebanon,"Dept. of Stat., Purdue Univ., West Lafayette, IN, USA",IEEE Transactions on Pattern Analysis and Machine Intelligence,21-Feb-06,2006,28,4,497,508,"Many algorithms in machine learning rely on being given a good distance metric over the input space. Rather than using a default metric such as the Euclidean metric, it is desirable to obtain a metric based on the provided data. We consider the problem of learning a Riemannian metric associated with a given differentiable manifold and a set of points. Our approach to the problem involves choosing a metric from a parametric family that is based on maximizing the inverse volume of a given data set of points. From a statistical perspective, it is related to maximum likelihood under a model that assigns probabilities inversely proportional to the Riemannian volume element. We discuss in detail learning a metric on the multinomial simplex where the metric candidates are pull-back metrics of the Fisher information under a Lie group of transformations. When applied to text document classification the resulting geodesic distance resemble, but outperform, the tfidf cosine similarity measure.",1939-3539,,10.1109/TPAMI.2006.77,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1597108,Distance learning;text analysis;machine learning.,Kernel;Machine learning algorithms;Machine learning;Euclidean distance;Joining processes;Geometry;Probability;Level measurement;Text analysis;Neural networks,statistical analysis;learning (artificial intelligence);text analysis;Lie groups;transforms;differential geometry,metric learning;text documents;machine learning;Riemannian metric;differentiable manifold;inverse volume maximization;maximum likelihood;Riemannian volume element;multinomial simplex;pull-back metrics;Fisher information;Lie group;geodesic distance;tfidf cosine similarity measure,"Algorithms;Artificial Intelligence;Automatic Data Processing;Computer Graphics;Documentation;Image Enhancement;Image Interpretation, Computer-Assisted;Information Storage and Retrieval;Numerical Analysis, Computer-Assisted;Pattern Recognition, Automated;Signal Processing, Computer-Assisted;User-Computer Interface",56,,13,,21-Feb-06,,,IEEE,IEEE Journals
Combination of Unsupervised Keyphrase Extraction Algorithms,無監督關鍵詞提取算法的組合,Z. Zhu; M. Li; L. Chen; Z. Yang; S. Chen,"Inst. of Intell. Machines, Hefei, China; Inst. of Intell. Machines, Hefei, China; Inst. of Intell. Machines, Hefei, China; Inst. of Intell. Machines, Hefei, China; Inst. of Intell. Machines, Hefei, China",2013 International Conference on Asian Language Processing,24-Oct-13,2013,,,33,36,"Key phrase extraction plays a significant role in many language processing tasks such as text summarization, text categorization and information retrieval. However, none study combines several approaches to improve the performance of key phrase extraction. This paper first implements three representative unsupervised algorithms TfIdf, Text Rank and Expand Rank, and then proposes a generalized framework using serial, parallel and voting methods on combining these algorithms for comprehensive analysis of key phrase extraction. Experimental results, carried out on an evaluation dataset including 1040 abstracts from Chinese thesis, demonstrate the remarkable performance of some combination approaches.",,978-0-7695-5063-3,10.1109/IALP.2013.14,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6645997,information extraction;keyphrase extraction;unsupervised learning;combination method,Data mining;Filtering algorithms;Algorithm design and analysis;Merging;Time-frequency analysis;Standards;Computational linguistics,information retrieval;natural language processing;text analysis;unsupervised learning,unsupervised keyphrase extraction algorithms;language processing tasks;text summarization;text categorization;information retrieval;keyphrase extraction performance improvement;TfIdf algorithm;TextRank algorithm;ExpandRank algorithm;generalized framework;serial method;parallel method;voting method;comprehensive keyphrase extraction analysis;Chinese thesis;combination method,,1,,14,,24-Oct-13,,,IEEE,IEEE Conferences
Towards matching food metadata in emergency decision-making using ontology and MapReduce,使用本體和MapReduce在緊急決策中實現匹配食物元數據,Li Zhu; Wei Hu,"School of Economics and Management, Nanjing Univ. of Information Science & Technology, 210044, China; State Key Laboratory for Novel Software Technology, Nanjing Univ., 210046, China","2012 International Conference on Information Management, Innovation Management and Industrial Engineering",25-Oct-12,2012,2,,498,501,"Data integration technologies improve the accuracy of decision-making in the occurrence of public emergency. Set in the emergency food supply, we propose in this paper a new method to match food metadata with ontology and MapReduce. In specific, by extending the ?ARGOVOC??ontology from the Food and Agriculture Organization of United Nations (FAO), ontological descriptions about food metadata are established. Based upon the classification of emergency functionalities, food metadata in the same category are matched in a two-stage TFIDF way, which is further implemented using the MapReduce framework for efficient parallel computation. Evaluations on the subsidiary agricultural product metadata, provided by the Suguo supermarket, show the feasibility of our approach.",2155-1472,978-1-4673-1931-7,10.1109/ICIII.2012.6339886,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6339886,food ontology;MapReduce;TF-IDF;emergency decision-making;ontology-based data integration,Dairy products,data integration;emergency services;meta data;ontologies (artificial intelligence);parallel processing;pattern classification;pattern matching;statistical analysis,food metadata matching;emergency decision-making;MapReduce;data integration technology;public emergency;emergency food supply;ARGOVOC ontology;Food and Agriculture Organization;United Nations;ontological description;emergency functionality classification;two-stage TFIDF way;parallel computation;Suguo supermarket;term frequency-inverse document frequency,,,,8,,25-Oct-12,,,IEEE,IEEE Conferences
A Study on Classification Methods Applied to Sentiment Analysis,分類方法在情感分析中的應用,V. Mazzonello; S. Gaglio; A. Augello; G. Pilato,"DICGIM, Univ. di Palermo, Palermo, Italy; DICGIM, Univ. di Palermo, Palermo, Italy; Ist. di Calcolo e Reti ad Alte Prestazioni, Palermo, Italy; Ist. di Calcolo e Reti ad Alte Prestazioni, Palermo, Italy",2013 IEEE Seventh International Conference on Semantic Computing,2-Jan-14,2013,,,426,431,"Sentiment analysis is a new area of research in data mining that concerns the detection of opinions and/or sentiments in texts. This work focuses on the application and the comparison of three classification techniques over a text corpus composed of reviews of commercial products in order to detect opinions about them. The chosen domain is about ""perfumes"", and user opinions composing the corpus are written in Italian language. The proposed approach is completely data-driven: a Term Frequency / Inverse Document Frequency (TFIDF) terms selection procedure has been applied in order to make computation more efficient, to improve the classification results and to manage some issues related to the specific classification procedure adopted.",,978-0-7695-5119-7,10.1109/ICSC.2013.82,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693557,Sentiment Classification;Naive Bayes classifier;Class Association Rules;Random Indexing;TF-IDF,Semantics;Accuracy;Training;Feature extraction;Context;Association rules;Vectors,classification;data mining;natural language processing;text analysis,classification methods;sentiment analysis;data mining;opinion detection;classification techniques;text corpus;Italian language;term frequency/inverse document frequency terms selection procedure;TFIDF terms selection procedure;classification procedure,,4,,15,,2-Jan-14,,,IEEE,IEEE Conferences
Polarity Detection in a Cross-Lingual Sentiment Analysis using spaCy,使用spaCy在跨語言情感分析中的極性檢測,M. Sharma,"Delhi Technological University,Department of Electrical Engineering,New Delhi,India","2020 8th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)",15-Sep-20,2020,,,490,496,"This paper presents a comparison of sentiment analyses performed on a dataset of French tweets and it's machine translated version (in English) using Google Translate. In recent years, a fairly new Python library called spaCy has gained significant traction in performing sentiment analyses in languages other than English due to its multilingual support. There still haven't been major publications on evaluating its usage for the said purpose. In this research, TFIDF features are extracted from three different N-grams (Unigrams, Bigrams and Trigrams) in the corpus after preprocessing to remove irrelevant details. These are then trained and tested using three machine learning algorithms - Logistic Regression, Na簿ve Bayes Algorithm and Stochastic Gradient Descent. A comparative study then put forth will help future researchers in the following three areas - the capability of performing sentiment analyses in languages other than English, reliability of machine translation tools in performing cross-lingual sentiment analyses and the evaluation of Python's library, spaCy for performing multilingual sentiment analyses.",,978-1-7281-7016-9,10.1109/ICRITO48877.2020.9197829,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9197829,Sentiment Analysis;Opinion Mining;CrossLingual Sentiment Analysis;Polarity Detection;Machine Translation;NLP;Twitter Sentiment Analysis,Sentiment analysis;Feature extraction;Twitter;Tools;Google;Libraries,Internet;language translation;learning (artificial intelligence);pattern classification;sentiment analysis;social networking (online),TFIDF features extraction;machine learning algorithms;multilingual sentiment analyses;machine translation tools;Python library;Google Translate;French tweets;spaCy;cross-lingual sentiment analysis;polarity detection,,,,20,,15-Sep-20,,,IEEE,IEEE Conferences
A Wikipedia Two-Way Link Vector Model for Measuring Semantic Relatedness,Wikipedia雙向鏈接矢量模型，用於測量語義相關性,X. Zhu; Q. Guo; B. Zhang,"Guangxi Key Lab. of Multi-source Inf. Min. & Security, Guangxi Normal Univ., Guilin, China; Guangxi Key Lab. of Multi-source Inf. Min. & Security, Guangxi Normal Univ., Guilin, China; Guangxi Key Lab. of Multi-source Inf. Min. & Security, Guangxi Normal Univ., Guilin, China","2018 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)",6-Dec-18,2018,,,323,330,"The measurement of the semantic relatedness between concepts is an important fundamental research topic in natural language processing. This paper proposes a Wikipedia two-way link vector model to extend the existing Wikipedia one-way out-link vector model. This vector model contains the weighted out-links and weighted in-links of concepts in Wikipedia and uses a TFIDF-based bidirectional weight method to uniformly calculate the strength of the mutual association between a given concept with its out-link or in-link concept. The bidirectional weight is equal to the sum of the weight for the link from the given concept to its link concept and the weight for the link from its link concept to the given concept. Moreover, we also propose a disambiguation strategy based on senses' social awareness that directly sorts the out-links within a disambiguation page in the order in which they occur in the disambiguation page and adopts an adjustable threshold to determine how many senses will be selected. The experimental results demonstrate that our model surpasses the existing popular ESA and WCVM methods in the current Wikipedia versions and that our two-way link vector model significantly improves the performance of the existing one-way link vector model.",,978-1-5386-9380-3,10.1109/SmartWorld.2018.00088,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8560066,"natural language processing, semantic relatedness, link vector, disambiguation, Wikipedia",,natural language processing;text analysis;Web sites,two-way link vector model;one-way out-link vector model;TFIDF-based bidirectional weight method;in-link concept;disambiguation page;semantic relatedness;Wikipedia versions;sense social awareness;natural language processing,,,,24,,6-Dec-18,,,IEEE,IEEE Conferences
Exceptions in language as learned by the multi-factor sparse plus low-rank language model,多因素稀疏加低秩語言模型學習到的語言異常,B. Hutchinson; M. Ostendorf; M. Fazel,"Electrical Engineering Department, University of Washington, USA; Electrical Engineering Department, University of Washington, USA; Electrical Engineering Department, University of Washington, USA","2013 IEEE International Conference on Acoustics, Speech and Signal Processing",21-Oct-13,2013,,,8580,8584,"Word usage is influenced by diverse factors, including topic, genre and various speaker/author characteristics. To characterize these aspects of language, we introduce the ?Multi-Factor Sparse Plus Low Rank??exponential language model, which allows supervised joint training of arbitrary overlapping factor-specific model components. This flexible architecture has the advantage of being highly interpretable. The elements of sparse parameter matrices can be viewed as factor-dependent corrections (e.g. topic- or speaker-dependent phenomena). In topic modeling experiments on conversational telephone speech, we obtain modest perplexity reductions over an n-gram baseline and demonstrate topic-dependent keyword extraction that leads to a 13% (absolute) improvement in precision over TFIDF. We also show how keywords can be jointly learned for speakers, roles and topics in a study of Supreme Court oral arguments.",2379-190X,978-1-4799-0356-6,10.1109/ICASSP.2013.6639340,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6639340,Language modeling;sparse plus low rank decomposition;topic models;keyword extraction,Adaptation models;Computational modeling;Training;Sparse matrices;Joints;Data models;Speech,computational linguistics;learning (artificial intelligence);matrix algebra;natural language processing;speech processing,multifactor sparse plus low-rank exponential language model;speaker-author characteristics;supervised joint training;arbitrary overlapping factor-specific model components;flexible architecture;sparse parameter matrices;factor-dependent corrections;topic modeling;conversational telephone speech;modest perplexity reductions;n-gram baseline;topic-dependent keyword extraction;TFIDF;supreme court oral arguments;word usage;supervised learning;sequential language behavior,,1,,16,,21-Oct-13,,,IEEE,IEEE Conferences
Hypergraph Partition with Harmonic Average Top-N and PCA for Topic Detection,具有諧波平均Top-N和PCA的超圖分區用於主題檢測,X. Liu; F. Ma; H. Lin; H. Shen,"Sch. of Comput. Sci. & Technol., Dalian Univ. of Technol., Dalian, China; Sch. of Software, Dalian Univ. of Technol., Dalian, China; Sch. of Comput. Sci. & Technol., Dalian Univ. of Technol., Dalian, China; Sch. of Software, Dalian Univ. of Technol., Dalian, China","2010 3rd International Symposium on Parallel Architectures, Algorithms and Programming",17-Feb-11,2010,,,269,276,"An algorithm named SMHP is proposed, which aims at improving the efficiency of Topic Detection. In SMHP, a T-MI-TFIDF model is designed by introducing mutual information (MI) and enhancing the weight of terms in the title. Then VSM is constructed according to terms' weight, and the dimension is reduced by combining H-TOPN and PCA. Then topics are grouped based on SMHP. Experiment results show the proposed methods are more suitable for clustering topics. SMHP with novel approaches can effectively solve the relationship of multiple stories problem and improve the accuracy of cluster results.",2168-3042,978-1-4244-9482-8,10.1109/PAAP.2010.38,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5715093,,Clustering algorithms;Partitioning algorithms;Principal component analysis;Noise;Mutual information;Harmonic analysis;Algorithm design and analysis,graph theory;information retrieval;pattern clustering;principal component analysis;text analysis,hypergraph partition;harmonic average Top-N;PCA;topic detection;SMHP algorithm;T-MI-TFIDF model;mutual information;VSM;H-TOPN;clustering topics;multiple stories problem,,,,25,,17-Feb-11,,,IEEE,IEEE Conferences
Keywords extraction for automatic indexing of e-learning resources,電子學習資源自動索引的關鍵詞提取,M. Hendez; H. Achour,"High Institute of Management, University of Tunis, Tunisia; High Institute of Management, University of Tunis, Tunisia",2014 World Symposium on Computer Applications & Research (WSCAR),7-Oct-14,2014,,,1,5,"With the growing use of various educational web applications such as e-Learning platforms, learning portals, learning object repositories, ... as well as the increasing setting on line of learning resources, it becomes essential to index these resources in order to facilitate their searching and retrieving. In this paper, we address the problem of automatic indexing of online educational resources and we propose an approach to help the indexing operation. This approach consists in automatically extracting a set of relevant terms describing the educational content of a resource. The proposed approach is based on the TF-IDF algorithm, the usage of a domain lexicon and exploits the structure of educational documents.",,978-1-4799-2806-4,10.1109/WSCAR.2014.6916796,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6916796,learning resources;e-Learning;information retrieval;automatic indexation;key words extraction,Standardization;Programming profession;Manuals;Conferences,computer aided instruction;indexing;text analysis,keywords extraction;e-learning resources;automatic indexing;online educational resources;educational content;TFIDF algorithm;domain lexicon;educational documents;term frequency inverse document frequency,,4,,11,,7-Oct-14,,,IEEE,IEEE Conferences
Sentiment classification for Chinese reviews based on key substring features,基於關鍵子串特徵的中文評論情感分類,Z. Zhai; H. Xu; J. Li; P. Jia,"State Key Laboratory on Intelligent Technology and Systems Tsinghua National Laboratory for Information Science and Technology, CS&T Department, Tsinghua University, Beijing 100084, China P.R.; State Key Laboratory on Intelligent Technology and Systems Tsinghua National Laboratory for Information Science and Technology, CS&T Department, Tsinghua University, Beijing 100084, China P.R.; State Key Laboratory on Intelligent Technology and Systems Tsinghua National Laboratory for Information Science and Technology, CS&T Department, Tsinghua University, Beijing 100084, China P.R.; State Key Laboratory on Intelligent Technology and Systems Tsinghua National Laboratory for Information Science and Technology, CS&T Department, Tsinghua University, Beijing 100084, China P.R.",2009 International Conference on Natural Language Processing and Knowledge Engineering,6-Nov-09,2009,,,1,8,"One of the most widely-studied sub-problems of opinion mining is sentiment classification, which classifies evaluative texts as positive or negative to help people automatically identify the viewpoints underlying the online user-generated information. Most of the existing methods for sentiment classification ignore word sequence and unlabeled test documents' structural information. This paper proposes a transductive learning based algorithm considering both of these two types of information. The proposed algorithm is implemented by firstly selecting key substrings in the suffix tree constructed from the strings in training and unlabeled test documents and then converting each original text document to a bag of numbers of the key substrings. Finally, SVM is employed to classify the converted documents. Experiments on the open dataset (16,000 Chinese reviews) demonstrate promising performance of the proposed algorithm, the accuracy being over 93.15%, which is much better than the performance of the existing sentiment classification methods, such as n-gram features based classification algorithms. Experimental results also show that ldquotfidf-crdquo performs much better than other term weighting approaches in sentiment classification for large text corpus. In particular, the reasons behind the proposed algorithm's outstanding performance are further studied and analyzed in this paper. Moreover, the proposed algorithm can avoid the messy and rather artificial problem of defining word boundaries in Chinese language.",,978-1-4244-4538-7,10.1109/NLPKE.2009.5313782,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5313782,Sentiment Classification;Substring;Transductive Learning;Opinion Mining,Testing;Data mining;Support vector machines;Support vector machine classification;Classification algorithms;Machine learning;Laboratories;Algorithm design and analysis;Learning systems;Intelligent systems,data mining;learning (artificial intelligence);natural language processing;pattern classification;text analysis;trees (mathematics),sentiment classification;Chinese reviews;key substring features;opinion mining;evaluative text classification;transductive learning based algorithm;suffix tree;text document;tfidf-c;word boundaries;Chinese language,,5,,23,,6-Nov-09,,,IEEE,IEEE Conferences
MixPR-An Approach of Combining Content and Links of Web Page,MixPR-組合網頁內容和鏈接的方法,Y. Guo,"Xi'an University of Finance & Economics, Xi'an 710061, P.R.China",Fourth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD 2007),18-Dec-07,2007,2,,456,460,"Pagerank was used in systems based on hyperlink structure such as Google. TFIDF was widely used in IR systems based on the vector space model (VSM). It was significative to combine the advantages of two systems. In this paper, we set up a new model by using the content of Web pages and the links among pages. We set up the transition probability matrix, which composed of link information and the relevant value of pages with the given query. The relevant value was denoted by TFIDF. We got the MixPR (mixed pagerank) by solving the equation with the coefficient of matrix. In this model, part of the pages, which would be used to compute the TFIDF, had been downloaded from the Internet firstly, and the link information which started from those pages was stored in local server, too. The importance of the page was determined by content and the links. Experimental results showed that the new model worked well, and the precision approached to the result of the TFIDF did.",,978-0-7695-2874-8,10.1109/FSKD.2007.407,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4406120,,Web pages;Search engines;Databases;Finance;Equations;Internet;Web server;Delay;Content based retrieval;Web search,information retrieval;Internet;search engines,Web page;Pagerank;hyperlink structure;Google;vector space model;transition probability matrix,,,,10,,18-Dec-07,,,IEEE,IEEE Conferences
Document indexing in text categorization,文本分類中的文檔索引,Qi-Rui Zhang; Ling Zhang; Shou-Bin Dong; Jing-Hua Tan,"Guangdong Key Lab. of Comput. Network, South China Univ. of Technol., Guangzhou, China; Guangdong Key Lab. of Comput. Network, South China Univ. of Technol., Guangzhou, China; Guangdong Key Lab. of Comput. Network, South China Univ. of Technol., Guangzhou, China; NA",2005 International Conference on Machine Learning and Cybernetics,7-Nov-05,2005,6,,3792,3796 Vol. 6,"Aiming at the characteristic of text categorization, this paper proposes an improved method of computing term weights, tfidfie, based on the traditional tfidf function that is generally used in most classifiers. In comparison with the tfidf function, the tfidfie function adds an information entropy factor, H, which represents the distribution of documents in the training set in which the term occurs. The experiments show tfidfie outperforms tfidf. In addition, this paper analyses the difference of using information entropy factor H between document categorization and feature selection, also finds that both two phases are all necessary for text categorization, meanwhile it can reach the best performance of classification with up to 70% of the unique terms being removed.",2160-1348,0-7803-9091-1,10.1109/ICMLC.2005.1527600,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1527600,Text categorization;document indexing;feature selection,Indexing;Text categorization;Information retrieval;Machine learning;Intelligent networks;Computer networks;Information entropy;Classification tree analysis;Frequency;Laboratories,information retrieval;text analysis;indexing;vocabulary;classification,document indexing;text categorization;term weight computing;tfidfie function;information entropy factor;feature selection,,7,,10,,7-Nov-05,,,IEEE,IEEE Conferences
How to measure the semantic similarities between scientific papers and patents in order to discover uncommercialized research fronts: A case study of solar cells,如何測量科學論文與專利之間的語義相似性，以發現非商業化的研究前沿：以太陽能電池為例,N. Shibata; Y. Kajikawa; I. Sakata,"Innovation Policy Research Center, School of Engineering, The University of Tokyo, Tokyo 113-8656, Japan; Innovation Policy Research Center, School of Engineering, The University of Tokyo, Tokyo 113-8656, Japan; Innovation Policy Research Center, School of Engineering, The University of Tokyo, Tokyo 113-8656, Japan",PICMET 2010 TECHNOLOGY MANAGEMENT FOR GLOBAL ECONOMIC GROWTH,14-Oct-10,2010,,,1,6,"In this paper, we perform a comparative study to measure the semantic similarity between academic papers and patents. Research fronts which do not correspond any patents can be uncommercialized and opportunities for industry. Therefore it is significant to investigate the relationship between the scientific outcomes and the pieces of industrial technology. We compare structures of citation network of scientific publications with those of patents by citation analysis, measure the similarity between sets of academic papers and ones of patents by natural language processing, and discuss the validity of the results with experts. After the documents (papers/patents) in each layer are categorized by a citation-based method, we compare three semantic similarity measurements between a set of academic papers and a set of patents: Jaccard coefficient, cosine similarity of tfidf vector, and cosine similarity of log-tfidf vector. A case study is performed in solar cells to develop a method investigating the corresponding relationship between papers and patents. As a result, the cosine similarity of tfidf is the best way to discover the corresponding relationship. This proposed approach enables us to obtain, at least, the candidates of unexplored research fronts, where academic researches exist but patents do not.",2159-5100,978-1-4244-8203-0,,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5602080,,Patents;Photovoltaic cells;Semantics;Industries;Technological innovation;Polymers;Indexes,citation analysis;natural language processing;patents;solar cells,scientific papers;patents;uncommercialized research fronts;solar cells;semantic similarity measurement;academic papers;industrial technology;citation analysis;natural language processing;Jaccard coefficient;cosine similarity,,1,,19,,14-Oct-10,,,IEEE,IEEE Conferences
SVM Method for Classification of Primary School Teacher Education Journal Articles,支持向量機方法的小學教師教育期刊論文分類,U. Pujianto; I. A. E. Zaeni; N. O. Irawan,"State University of Malang,Department of Electrical Engineering,Malang,Indonesia; State University of Malang,Department of Electrical Engineering,Malang,Indonesia; State University of Malang,Department of Electrical Engineering,Malang,Indonesia","2019 International Conference on Electrical, Electronics and Information Engineering (ICEEIE)",6-Feb-20,2019,6,,324,329,"Increasing search for a journal article should be supported by appropriate journal articles search results. Searching for appropriate journal articles can be done by grouping journal articles or information presented based on certain categories. The categorization problem that is often faced is the unbalanced data categorization. So that the settlement of the problem of categorizing unbalanced journal articles in each group will be solved by over-sampling and text classification methods. The purpose of this study is to compare the text classification for the journal articles of Primary School Teacher Education (PGSD) with the Support Vector Machine (SVM) classification method by conducting over-sampling techniques or methods with Synthetic Minority Over-Sampling Technique (SMOTE) and classification of PGSD journal articles using the SVM method only. This research includes text preprocessing processes such as tokenizing and case folding which produce a set of terms or words. The results of words will be weighted using TFIDF. After obtaining the TFIDF value, SMOTE will be conducted to overcome the data imbalance. The data that has been through SMOTE will be classified by the SVM method. The comparison of performance for each method is measured by 3 test outputs, which are accuracy, recall, and precision. From the test results, it was proved that the SVM using SMOTE after the TFIDF value obtained is better for classifying than using the SVM method only. The test value for the SVM method using SMOTE has a precision value of 97.3%, recall of 97.23% and accuracy of 97.22%, while the SVM method has a precision value of 72.55%, recall of 50.71% and accuracy of 80.56%.",,978-1-7281-4160-2,10.1109/ICEEIE47180.2019.8981455,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8981455,text classsification;SMOTE;SVM,,educational administrative data processing;pattern classification;sampling methods;support vector machines;text analysis,SVM method;Primary School Teacher Education journal articles;unbalanced data categorization;unbalanced journal articles;text classification;support vector machine classification method;synthetic minority over-sampling technique;SMOTE;PGSD journal articles;text preprocessing,,,,19,,6-Feb-20,,,IEEE,IEEE Conferences
Term Weighting Approaches for Text Categorization Improving,改進文本分類的術語加權方法,L. A. Matsunaga; N. F. F. Ebecken,"Fed. District Legislative Assembly; COPPE, Fed. Univ. of Rio de Janeiro, Rio de Janeiro",2008 Eighth International Conference on Intelligent Systems Design and Applications,8-Dec-08,2008,1,,409,414,"The objective of the text categorization problem examined in this paper corresponds to automatically distribute the legislative bills to the committees at the Federal District Legislative Assembly in Brasilia, Brazil. For this study the replacement of the idf part in TFIDF by a new term selection measure - absl logit- and by bi-normal separation produced the best general classification results, using support vector machines models (SVM), when compared with TFIDF and with the use of common term selection measures - chi-square, information gain, gain ratio and odds ratio - to replace the idf part in TFIDF.",2164-7151,978-0-7695-3382-7,10.1109/ISDA.2008.21,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4696241,term weighting;text categorization;text,Text categorization;Dictionaries;Gain measurement;Support vector machines;Support vector machine classification;Vocabulary;Intelligent systems;Assembly systems;Text mining;Frequency,category theory;support vector machines;text analysis,term weighting;text categorization;support vector machines models;term selection measures,,,,13,,8-Dec-08,,,IEEE,IEEE Conferences
An improved topic relevance algorithm for focused crawling,一種改進的主題相關算法，用於集中爬網,H. Hao; C. Mu; X. Yin; S. Li; Z. Wang,"Department of Computer Science, School of Computer and Communication Engineering, University of Science and Technology Beijing, 100083, China; Department of Computer Science, School of Computer and Communication Engineering, University of Science and Technology Beijing, 100083, China; Department of Computer Science, School of Computer and Communication Engineering, University of Science and Technology Beijing, 100083, China; Department of Computer Science, School of Computer and Communication Engineering, University of Science and Technology Beijing, 100083, China; Department of Computer Science, School of Computer and Communication Engineering, University of Science and Technology Beijing, 100083, China","2011 IEEE International Conference on Systems, Man, and Cybernetics",21-Nov-11,2011,,,850,855,"Topic relevance of pages and hyperlinks is the key issue in focused crawling. In this paper, an improved topic relevance algorithm for focused crawling is proposed. First, we implement a prototype system of the focused crawler - a topic-specific news gathering system which is prepared for comparative experiments on different similarity measures with the anchor text. Second, experiments on Chinese text corpus show that using LSI (Latent Semantic Indexing) outperforms using TF-IDF (term frequency- inverse document frequency) for hyperlink topic relevance prediction and pages topic relevance calculation. Third, in real crawling experiments on the prototype system, the crawler using TF-IDF has high performance with the accumulated topic relevance increasing quickly at the beginning of crawling, however the crawler using LSI can find more related pages and tunnel through. Fourth, combining their advantages of LSI and TF-IDF, we propose TFIDF+LSI algorithm to guide the crawling. Last, the crawler using TFIDF+LSI performs the same crawl task and demonstrates the combination advantage of TF-IDF and LSI. The experiment suggests that the crawler's performance using TFIDF+LSI is greatly superior to that using either TF-IDF or LSI respectively.",1062-922X,978-1-4577-0653-0,10.1109/ICSMC.2011.6083759,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6083759,topical crawler;link prediction;topic relevance;Latent Semantic Indexing;Web information retrieval,Large scale integration;Crawlers;Vectors;Semantics;Correlation;Algorithm design and analysis;Prototypes,indexing;information retrieval;Internet,topic relevance algorithm;focused crawling;topic-specific news gathering system;Chinese text corpus;latent semantic indexing;term frequency-inverse document frequency,,7,,16,,21-Nov-11,,,IEEE,IEEE Conferences
Text Retrieval Based on Semantic Relationship,基於語義關係的文本檢索,G. Huang; X. Zhang,"Electron. & Inf. Eng. Coll., Henan Univ. of Sci. & Technol., Luoyang, China; Electron. & Inf. Eng. Coll., Henan Univ. of Sci. & Technol., Luoyang, China",2010 International Conference on E-Product E-Service and E-Entertainment,10-Dec-10,2010,,,1,4,"Expansion of query keywords based on semantic relationship is an effective approach to improve the performance of text retrieval. In this paper, a novel approach for text retrieval is presented. The principle of the approach is to construct a integrated semantic tree, and select candidate keywords from the tree. On the tree, all nodes are weighted based on synonymy, hypernymy, and Mutual Information. The weights of nodes will be used to supplement tfidf values in computing the similarity between query and documents. Experimental results demonstrate about 14.6% precision and 13.7% prec@20 improvement over the traditional tfidf-based method.",,978-1-4244-7161-4,10.1109/ICEEE.2010.5661531,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5661531,,Semantics;Mutual information;Information filters;Correlation;Context,information retrieval;semantic networks;text analysis,text retrieval;semantic relationship;query keywords;semantic tree,,3,,8,,10-Dec-10,,,IEEE,IEEE Conferences
Multilingual author profiling using word embedding averages and SVMs,使用單詞嵌入平均值和SVM進行多語言作者分析,R. Bayot; T. Gon癟alves,"Department of Informatics, School of Sciences and Technology, University of ?vora, Portugal; Department of Informatics, School of Sciences and Technology, University of ?vora, Portugal","2016 10th International Conference on Software, Knowledge, Information Management & Applications (SKIMA)",4-May-17,2016,,,382,386,"This paper describes an experiment done to investigate author profiling of tweets in English and Spanish, particularly for cross genre evaluation. Profiling consists of age and gender classification. The training sets were taken from tweets while genres for evaluation come from blogs, hotel reviews, other tweets collected in a different time, as well as other social media. Comparisons were done between tfidf as a baseline and average of word vectors, using a Support Vector Machine algorithm. Results show that using average of word vectors outperforms tfidf in most cross genre problems for age and gender.",,978-1-5090-3298-3,10.1109/SKIMA.2016.7916251,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7916251,word2vec;word embeddings;SVM;author profiling,Blogs;Social network services;Training;Support vector machines;Dictionaries;Software;Information management,age issues;gender issues;natural language processing;pattern classification;social networking (online);support vector machines,multilingual author profiling;word embedding averages;SVMs;tweets;English language;Spanish language;cross genre evaluation;age classification;gender classification;social media;word vectors;support vector machine algorithm,,6,,22,,4-May-17,,,IEEE,IEEE Conferences
Comparison of two schemes for automatic keyword extraction from MEDLINE for functional gene clustering,兩種從MEDLINE自動提取功能基因聚類方案的比較,Ying Liu; B. J. Ciliax; K. Borges; V. Dasigi; A. Ram; S. B. Navathe; R. Dingledine,"Coll. of Comput., Georgia Inst. of Technol., Atlanta, GA, USA; NA; NA; NA; NA; NA; NA","Proceedings. 2004 IEEE Computational Systems Bioinformatics Conference, 2004. CSB 2004.",8-Oct-04,2004,,,394,404,"One of the key challenges of microarray studies is to derive biological insights from the unprecedented quantities of data on gene-expression patterns. Clustering genes by functional keyword association can provide direct information about the nature of the functional links among genes within the derived clusters. However, the quality of the keyword lists extracted from biomedical literature for each gene significantly affects the clustering results. We extracted keywords from MEDLINE that describe the most prominent functions of the genes, and used the resulting weights of the keywords as feature vectors for gene clustering. By analyzing the resulting cluster quality, we compared two keyword weighting schemes: normalized z-score and term frequency-inverse document frequency (TFIDF). The best combination of background comparison set, stop list and stemming algorithm was selected based on precision and recall metrics. In a test set of four known gene groups, a hierarchical algorithm correctly assigned 25 of 26 genes to the appropriate clusters based on keywords extracted by the TDFIDF weighting scheme, but only 23 of 26 with the z-score method. To evaluate the effectiveness of the weighting schemes for keyword extraction for gene clusters from microarray profiles, 44 yeast genes that are differentially expressed during the cell cycle were used as a second test set. Using established measures of cluster quality, the results produced from TFIDF-weighted keywords had higher purity, lower entropy, and higher mutual information than those produced from normalized z-score weighted keywords. The optimized algorithms should be useful for sorting genes from microarray lists into functionally discrete clusters.",,0-7695-2194-0,10.1109/CSB.2004.1332452,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1332452,,Clustering algorithms;Abstracts;Data mining;Educational institutions;Frequency;Testing;Biomedical measurements;Nervous system;Venus;Fungi,genetics;cellular biophysics;biology computing;entropy;optimisation;pattern clustering;information analysis,automatic keyword extraction;MEDLINE;functional gene clustering;microarray;gene-expression patterns;functional keyword association;biomedical literature;feature vectors;normalized z-score;term frequency-inverse document frequency;background comparison set;stop list;stemming algorithm;weighting schemes;yeast genes;cell cycle;optimized algorithms;high purity;low entropy;high mutual information,"Artificial Intelligence;Cluster Analysis;Information Storage and Retrieval;MEDLINE;Multigene Family;Natural Language Processing;Oligonucleotide Array Sequence Analysis;Structure-Activity Relationship;Vocabulary, Controlled",7,,25,,8-Oct-04,,,IEEE,IEEE Conferences
Improving Sentiment Analysis in Twitter Using Sentiment Specific Word Embeddings,使用特定於情感的詞嵌入來改善Twitter中的情感分析,R. Othman; Y. Abdelsadek; K. Chelghoum; I. Kacem; R. Faiz,"Laboratoire de Recherche Op矇rationnelle, de D矇cision et de Contr繫le de processus, LARODEC, ISG Tunis, Universit矇 de Tunis,Tunis,Tunisia,1007; Laboratoire de Conception, Optimisation et Mod矇lisation des Syst癡mes, LCOMS EA 7306, Universit矇 de Lorraine,Metz,France,57000; Laboratoire de Conception, Optimisation et Mod矇lisation des Syst癡mes, LCOMS EA 7306, Universit矇 de Lorraine,Metz,France,57000; Laboratoire de Conception, Optimisation et Mod矇lisation des Syst癡mes, LCOMS EA 7306, Universit矇 de Lorraine,Metz,France,57000; LARODEC, IHEC Carthage, Universit矇 de Carthage,Tunis,Tunisia",2019 10th IEEE International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications (IDAACS),5-Dec-19,2019,2,,854,858,"Most existing continuous word representation learning algorithms usually only capture the syntactic information in the texts while ignoring the sentiment relations between words. These represenations are not sufficiently effective for sentiment analysis as, in many cases, words with similar syntactic context, having neighboring word vectors can bear opposite sentiment polarity. In this paper, we present a weighted average word embeddings method which incorporates sentiment information in the continuous representation of words based on an adapted version of the delta TFIDF measure. Majority voting was then applied to determine the final polarity involving three machine learning classifiers notably, Support Vector Machine, Maximum Entropy and Na簿ve Bayes. Our experiments show promising results and a significant improvement over unweighted embeddings as well as traditional Term Frequency-Inverse Document Frequency (TFIDF).",,978-1-7281-4069-8,10.1109/IDAACS.2019.8924403,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8924403,Twitter;Sentiment analysis;weighted word embeddings;Word2vec,Sentiment analysis;Training;Task analysis;Syntactics;Weight measurement;Twitter;Support vector machines,Bayes methods;learning (artificial intelligence);maximum entropy methods;pattern classification;sentiment analysis;social networking (online);support vector machines,Support Vector Machine;unweighted embeddings;sentiment analysis;sentiment specific word embeddings;continuous word representation;syntactic information;sentiment relations;similar syntactic context;word vectors;opposite sentiment polarity;weighted average word embeddings method;sentiment information;continuous representation,,2,,21,,5-Dec-19,,,IEEE,IEEE Conferences
Comparing Dimension Reduction Techniques for Arabic Text Classification Using BPNN Algorithm,使用BPNN算法比較阿拉伯文本分類的降維技術,F. Harrag; E. El-Qawasmah; A. M. S. Al-Salman,"Comput. Sci. Dept, Farhat ABBAS Univ., Setif, Algeria; Software Eng. Dept., Jordan Univ. of Sci. & Technol., Irbid, Jordan; Coll. of Comput. & Inf. Sci., King Saud Univ., Riyadh, Saudi Arabia",2010 First International Conference on Integrated Intelligent Computing,16-Sep-10,2010,,,6,11,"Dimensionality reduction is an essential task for many large-scale information processing problems such as classifying document sets, searching over Web data sets, etc. It can be used to improve both the efficiency and the effectiveness of classifiers. In this paper, a comparative study is conducted of five Dimension Reduction Techniques in the context of the Arabic text classification problem using an in house Arabic dataset. We evaluated and compared Stemming, Light-Stemming, Document Frequency (DF), TFIDF and Latent Semantic Indexing (LSI)methods to reduce the feature space into an input space of much lower dimension for the neural network classifier. The results showed that the proposed model was able to achieve high categorization effectiveness as measured by Macro-Average F1 measure. Experiments on Arabic datasets indicate that the DF, TFIDF and LSI techniques are favorable in terms of its effectiveness and efficiency when compared with the two other methods.",,978-1-4244-7963-4,10.1109/ICIIC.2010.23,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5572644,Dimensionality Reduction;Back-Propagation Neural Network;Arabic Text Categorization,Artificial neural networks;Classification algorithms;Text categorization;Large scale integration;Training;Support vector machine classification;Matrix decomposition,backpropagation;neural nets;pattern classification;text analysis,comparing dimension reduction techniques;arabic text classification;BPNN algorithm;Web data sets;Arabic text classification;Arabic dataset;neural network,,7,,19,,16-Sep-10,,,IEEE,IEEE Conferences
Sentiment Analysis with NLP on Twitter Data,使用NLP對Twitter數據進行情感分析,M. R. Hasan; M. Maliha; M. Arifuzzaman,"East West University,Department of Electronics and Communications Engineering,Dhaka,1212; East West University,Department of Electronics and Communications Engineering,Dhaka,1212; Bangladesh University of Engineering and Technology,Dhaka,1000","2019 International Conference on Computer, Communication, Chemical, Materials and Electronic Engineering (IC4ME2)",16-Mar-20,2019,,,1,4,"Every social networking sites like facebook, twitter, instagram etc become one of the key sources of information. It is found that by extracting and analyzing data from social networking sites, a business entity can be benefited in their product marketing. Twitter is one of the most popular sites where people used to express their feelings and reviews for a particular product. In our work, we use twitter data to analyze public views towards a product. Firstly, we have developed a natural language processing (NLP) based pre-processed data framework to filter tweets. Secondly, we incorporate Bag of Words (BoW) and Term Frequency-Inverse Document Frequency (TF-IDF) model concept to analyze sentiment. This is an initiative to use BoW and TFIDF are used together to precisely classify positive and negative tweets. We have found that by exploiting TF-IDF vectorizer, the accuracy of sentiment analysis can be substantially improved and simulation results show the efficiency of our proposed system. We achieved 85.25% accuracy in sentiment analysis using NLP technique.",,978-1-7281-3060-6,10.1109/IC4ME247184.2019.9036670,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9036670,Natural language processing (NLP);Twitter;data mining;Sentiment analysis,Sentiment analysis;Twitter;Load modeling;Data mining;Analytical models;Companies,sentiment analysis;social networking (online),TF-IDF vectorizer;sentiment analysis;NLP technique;twitter data;social networking sites;business entity;product marketing;natural language processing based pre-processed data framework;BoW;Term Frequency-Inverse Document Frequency model concept;Bag of Words,,2,,18,,16-Mar-20,,,IEEE,IEEE Conferences
Automatic extraction of the unlisted terms in the field of information technology based on the dynamic circulation corpus,自動提取未列出的條款,Qiangjun Wang; Isabella Park; Pu Zhang,"Coll. of Humanity, Hebei Univ., China; NA; NA","International Conference on Natural Language Processing and Knowledge Engineering, 2003. Proceedings. 2003",22-Mar-04,2003,,,452,458,"We discuss automatic extraction of the unlisted terms in the field of information technology based on the large-scale DCC (dynamic circulation corpus), under the theory of dynamic updating of language and knowledge. It proposes the concept of concatenation index to decide whether a character string is a word/phrase or not. It also presents a new approach named ""concatenation index + TFIDF"" for extracting unlisted terms in large scale corpus of a certain field. The experiment selects the texts, around 17 million Chinese characters, in the field of IT (Information Technology) as the object corpus; and the texts, around 600 million Chinese characters, in the field of common usage as the contrast corpus. As a result, the tentative work flow has been established, and the approach turned out to be efficient.",,0-7803-7902-0,10.1109/NLPKE.2003.1275949,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1275949,,Data mining;Information technology;Terminology;Large-scale systems;Educational institutions;Tiles;Web sites;ISO;Measurement units;Dictionaries,natural languages;character recognition;text analysis;information technology,automatic term extraction;information technology;dynamic circulation corpus;dynamic updation theory;concatenation index;character string,,,,7,,22-Mar-04,,,IEEE,IEEE Conferences
Micro-blog commercial word extraction based on improved TF-IDF algorithm,基於改進TF-IDF算法的微博商業詞提取,X. Huang; Q. Wu,"School of Computer Science and Technology, Hangzhou Dianzi University, (310018) Zhejiang, China; School of Computer Science and Technology, Hangzhou Dianzi University, (310018) Zhejiang, China",2013 IEEE International Conference of IEEE Region 10 (TENCON 2013),23-Jan-14,2013,,,1,5,"Nowadays found some micro-blog commercial extraction algorithm only considering the relationship between the key words and the number of it appearing in texts, and ignoring the key words' distribution in a certain category, which leads the decreased accuracy problems of micro-blog commercial word extraction. To solve this problem, the application of TF-IDF algorithm in words weight calculation was researched in this paper. Combining the relevant knowledge of information theory and analyzing the distribution of keywords within a class, the article proposed improving TF-IDF algorithm and applying it in term weight calculation. To test the feasibility of the improved algorithm, this paper initially classified the massive micro-blog information into certain types, and then used improved TFIDF algorithm to calculate term weight among the categories, and, this calculation was realized under the Hadoop Distributed framework. The experiment results demonstrated that in the application of micro-blog commercial word extraction, the improved TF-IDF algorithm is effective and feasible. Compared with traditional algorithms, the improved algorithm greatly improved accuracy. In addition, the data processing speed has greatly improved under Hadoop framework.",2159-3450,978-1-4799-2827-9,10.1109/TENCON.2013.6718884,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6718884,Micro-blog;Commercial Word Extract;TF-IDF;Hadoop;Mass Data,Classification algorithms;Data mining;Games;Internet;Accuracy;Entertainment industry;Blogs,distributed processing;information retrieval;pattern classification;Web sites,microblog commercial word extraction;improved TF-IDF algorithm;term frequency-inverse document frequency algorithm;keywords distribution;words weight calculation;information theory;term weight calculation;information classification;Hadoop distributed framework,,6,,14,,23-Jan-14,,,IEEE,IEEE Conferences
Research and application of information retrieval techniques in Intelligent Question Answering System,信息檢索技術在智能問答系統中的研究與應用,Liang Yunjuan; Zhang Lijun; Ma Lijuan; Miao Qinglin,"School of Information Engineering, Henan Institute of Science and Technology, Xinxiang, China; School of Information Engineering, Henan Institute of Science and Technology, Xinxiang, China; School of Information Engineering, Henan Institute of Science and Technology, Xinxiang, China; School of Mechanical and electronic Engineering, Henan Institute of Science and Technology, Xinxiang, China",2011 3rd International Conference on Computer Research and Development,5-May-11,2011,2,,188,190,"Question and answer system, which is a full-text retrieval system based on dynamic knowledge library, is an important segment of remote education platform. Information retrieval technique is a key technology to make the success of Intelligent Question Answering System. The paper gave research and analysis on the inverted index technology and adopted the improved TFIDF weighting formula in order to improve the accuracy of retrieval explained; introduced a distributed multi-threading technology, cache technology in the retrieval system. Finally found the best program about the system, making it become intelligent interaction of the Question and Answering platform.",,978-1-61284-840-2,10.1109/ICCRD.2011.5764111,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5764111,Intelligent Answer System;Information Searching Technology;Inverted index,Artificial intelligence;Information retrieval;Query processing;Indexing;Education,libraries;multi-threading;question answering (information retrieval),information retrieval technique;intelligent question answering system;dynamic knowledge library;inverted index technology;distributed multi-threading technology;cache technology,,1,,8,,5-May-11,,,IEEE,IEEE Conferences
Using fuzzy logic to estimate user interests in multiscreen viewing situation,使用模糊邏輯估計多屏觀看情況下的用戶興趣,Y. Maki; M. Motegi; Y. Takashima; T. Kobayashi; T. Yamada,"NTT Service Evolution Laboratories, Nippon Telegraph and Telephone Corporation, Yokosuka, Japan; NTT Service Evolution Laboratories, Nippon Telegraph and Telephone Corporation, Yokosuka, Japan; NTT Service Evolution Laboratories, Nippon Telegraph and Telephone Corporation, Yokosuka, Japan; NTT Service Evolution Laboratories, Nippon Telegraph and Telephone Corporation, Yokosuka, Japan; NTT Service Evolution Laboratories, Nippon Telegraph and Telephone Corporation, Yokosuka, Japan",2013 IEEE Third International Conference on Consumer Electronics 聶 Berlin (ICCE-Berlin),2-Jan-14,2013,,,1,2,"This paper describes a method to extract user interest keywords for user profiling applicable to various recommendation systems from browsed web pages during multiscreen viewing, i.e. watching TV while browsing web pages related to the TV program on smartphones or Tablet PCs. Our method extracts keywords from browsed web pages and computes interest weights, which is based on the user's natural behaviors of ?browsed?? ?bookmarked; like social bookmarking??or ?no reaction; user did not browse it although it was shown?? Ranking the keywords in order of interest weights allows us to estimate the interest keywords. Experiments show that our method has better potential in filtering out non-useful keywords and thus is superior to the basic TFIDF approach.",2166-6822,978-1-4799-1412-8,10.1109/ICCE-Berlin.2013.6697992,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6697992,Multiscreen;User profiling;Fuzzy logic;Information Retrieval,Web pages;TV;Feature extraction;Fuzzy logic;Vectors;Smart phones;Tablet computers,fuzzy logic;information retrieval;mobile television;online front-ends;smart phones,fuzzy logic;multiscreen viewing situation;user interest keyword;TV program;smartphones;Tablet PC;browsed Web pages;social bookmarking;non-useful keyword,,,,5,,2-Jan-14,,,IEEE,IEEE Conferences
Classification of children stories in hindi using keywords and POS density,使用關鍵字和POS密度對印地語中的兒童故事進行分類,D. M. Harikrishna; K. S. Rao,"Indian Institute of Technology Kharagpur, India; Indian Institute of Technology Kharagpur, India","2015 International Conference on Computer, Communication and Control (IC4)",11-Jan-16,2015,,,1,5,"The main objective of this work is to classify Hindi stories into three genres: fable, folk-tale and legend. In this paper, we are proposing a framework for story classification using keyword and Part-of-speech (POS) based features. Keyword based features like Term Frequency (TF) and Term Frequency Inverse Document Frequency (TFIDF) are used. Effect of POS tags like Noun, Pronoun, Adjective etc., are analyzed for different story genres. Classification performance is analyzed using different combinations of features with three classifiers; Naive Bayes (NB), k-Nearest Neighbour (KNN) and Support Vector Machine (SVM). From the experimental studies, it is observed that combining linguistic and keyword based features do not improve significantly the classifier performance. Among the classifiers, SVM models outperformed the other models.",,978-1-4799-8164-9,10.1109/IC4.2015.7375666,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7375666,Hindi Story Classification;Text-to-Speech;Document Classification;Part-of-Speech;Vector Space Model;Naive Bayes;KNN;SVM,Support vector machines;Niobium;Pragmatics;Conferences;Computers;Text categorization;Tagging,Bayes methods;computational linguistics;document handling;natural language processing;pattern classification;support vector machines,Hindi children story classification;fable genre;folk-tale genre;legend genre;keyword based features;part-of-speech based features;term frequency inverse document frequency;POS tags;naive Bayes classifier;k-nearest neighbour classifier;support vector machine;linguistic based features,,5,,14,,11-Jan-16,,,IEEE,IEEE Conferences
Chinese text categorization based on deep belief networks,基於深度信念網絡的中文文本分類,J. Song; S. Qin; P. Zhang,"The Faculty of Science and Technology Communication, University of China, Beijing, China; New Media Institute, Communication University of China, Beijing, China; The Faculty of Science and Technology, Communication University of China, Beijing, China",2016 IEEE/ACIS 15th International Conference on Computer and Information Science (ICIS),25-Aug-16,2016,,,1,5,"With the rapid development of Internet, text categorization becomes a mission-critical technology that organizes and processes large amounts of data in document. Deep belief networks have powerful abilities of learning and can extract highly distinguishable features from the high-dimensional original feature space. So a new Chinese text categorization algorithm based on deep learning structure and semi-supervised deep belief networks is presented in this paper. We extract original feature with TFIDF-ICF, construct the text classification model based on DBN, and select the number of hidden layers and hidden units. Our experimental results indicated that the performance of text categorization algorithm based on deep belief networks is better than support vector machine.",,978-1-5090-0806-3,10.1109/ICIS.2016.7550914,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7550914,text categorization;restricted boltzmann machine;deep belief networks,Text categorization;Classification algorithms;Support vector machines;Feature extraction;Training;Machine learning;Neural networks,belief networks;feature extraction;Internet;learning (artificial intelligence);support vector machines;text analysis,Chinese text categorization;Internet;mission-critical technology;deep learning structure;semi-supervised deep belief networks;feature extraction;support vector machine,,4,,17,,25-Aug-16,,,IEEE,IEEE Conferences
A comparative study of topic identification on newspaper and e-mail,報紙和電子郵件主題識別的比較研究,B. Bigi; A. Brun; J. -. Haton; K. Smaili; I. Zitouni,LORIA/INRIA-Lorraine; NA; NA; NA; NA,Proceedings Eighth Symposium on String Processing and Information Retrieval,27-Jun-05,2001,,,238,241,"This work presents several statistical methods for topic identification on two kinds of textual data: newspaper articles and e-mails. Five methods are tested on these two corpora: topic unigrams, cache model, TFIDF classijier, topic peqdexity, and weighted model. Our work aims to study these methods by confronting them to very diferent data. This study is very fruitful for our research. Statistical topic identiJication methods depend not only on a corpus, but also on its type. One of the methods achieves a topic identiJcation of 80% on a general newspaper corpus but does not exceed 30% on e-mail corpus. Another method gives the best result on e-mails, but has not the same behavior on a newspaper corpus. We also show in this paper that almost all our methods achieve good results in retrieving the first two manually annotated labels.",,0-7695-1192-9,10.1109/SPIRE.2001.989770,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=989770,,Electronic mail;Statistical analysis;Text categorization;Speech recognition;Routing;Vocabulary;Testing;Information retrieval;Natural languages,,,,16,,9,,27-Jun-05,,,IEEE,IEEE Conferences
Keyphrase extraction based on semantic relatedness,基於語義相關性的關鍵詞提取,F. Xie; X. Wu; X. Hu,"Department of Computer Science, Hefei University of Technology, Hefei 230009, China; Department of Computer Science, University of Vermont, Burlington, VT 50405, USA; Department of Computer Science, Hefei Normal University, Hefei 230061, China",9th IEEE International Conference on Cognitive Informatics (ICCI'10),11-Oct-10,2010,,,308,312,"Keyphrase extraction is a fundamental research task in natural language processing and text mining. A limitation of previous keyphrase extraction methods based on semantic analysis is that the acquisition of the semantic features within phrases is restricted by the constructed thesaurus and language. An approach to the acquisition of the semantic features within phrases from a single document is proposed in this paper, which is used to extract document keyphrases. Semantic relatedness degrees between phrases are computed using word co-occurrence information in the document, and the document is represented as a relatedness graph. Keyphrases are extracted based on the semantic relatedness features acquired from the graph. Our experiments demonstrate that the proposed keyphrase extraction method always outperforms the baseline methods TFIDF and Kea. Furthermore, our approach is not domain-specific and the method generalizes well when it is trained on one domain (journal articles) and tested on another (news web pages).",,978-1-4244-8042-5,10.1109/COGINF.2010.5599721,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5599721,keyphrase extraction;semantic relatedness;word co-occurrence,Feature extraction;Semantics;Thesauri;Data mining;Web pages;Probability,data mining;natural language processing;text analysis;word processing,natural language processing;text mining;keyphrase extraction methods;semantic analysis;semantic features acquisition;semantic relatedness,,3,,19,,11-Oct-10,,,IEEE,IEEE Conferences
Research on Medical Document Categorization,醫學文獻分類研究,Q. Zhang; Y. Xue; H. Zhou; J. Tan,"Coll. of Med. Inf. Eng., Guangdong Pharm. Univ., Guangzhou; Coll. of Med. Inf. Eng., Guangdong Pharm. Univ., Guangzhou; Coll. of Med. Inf. Eng., Guangdong Pharm. Univ., Guangzhou; NA",2008 International Seminar on Future BioMedical Information Engineering,19-Jun-09,2008,,,437,440,"Medical document categorization is the process of automatically assigning one or more predefined category labels to medical documents. Document indexing plays a very important role in the process of classification. This paper proposes an improved method of computing term weights which is called tfidfie (term frequency, inverted document frequency and inverted entropy). In comparison with the tfidf (term frequency and inverted document frequency) function, the tfidfie function adds an information entropy factor, H, which represents the distribution of documents in the training set in which the term occurs. Then, we discuss the effects of training set in medical document categorization. An imbalanced training set decreases the performance of classifier. Considering the characteristics of medical documents, the medical classifiers are constructed by the methods of Naive Bayes and Rocchio respectively. The experiment results show that tfidfie improves the classification performance and Naive Bayes outperforms Rocchio.",2157-9601,978-0-7695-3561-6,10.1109/FBIE.2008.83,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5076776,medical information;document categorization;information entropy;document indexing;Na簿ve Bayes;Rocchio,Frequency;Indexing;Text categorization;Biomedical engineering;Information entropy;Seminars;Educational institutions;Pharmaceuticals;Research and development;Telecommunications,classification;medical information systems;text analysis,medical document categorization;document indexing;inverted document frequency;inverted entropy;term frequency;information entropy factor;Naive Bayes,,1,,15,,19-Jun-09,,,IEEE,IEEE Conferences
Sentiment classification on Turkish hotel reviews,土耳其酒店評論的情緒分類,B. B. O?ul; G. Ercan,"Bilgisayar M羹hendisli?i B繹l羹m羹, Hacettepe ?niversitesi, Ankara, T羹rkiye; Bilgisayar M羹hendisli?i B繹l羹m羹, Hacettepe ?niversitesi, Ankara, T羹rkiye",2016 24th Signal Processing and Communication Application Conference (SIU),23-Jun-16,2016,,,497,500,"Sentiment analysis refers to classify the emotion of a text whether positive or negative. The studies conducted on sentiment analysis are generally based on English and other languages while there are limited studies on Turkish. In this study, after constructing a dataset using a well-known hotel reservation site booking.com, we compare the performances of different machine learning approaches. We also apply dictionary-based method, SentiTFIDF, which differs from the traditional methods due to their logarithmic differential term frequency and term presence distribution usage. The results are evaluated using the area under of a Receiver Operating Characteristic (ROC) curve (AUC). The results show that, using document term matrix as input gives better classification results than TFIDF matrix. We also observe that the best results are obtained using Random Forest classifier with an AUC value of %89 on both positive and negative comments.",,978-1-5090-1679-2,10.1109/SIU.2016.7495786,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7495786,Sentiment analysis;machine learning;text features;tf-idf;term document matrix;random forest,Sentiment analysis;Receivers;Computer science;Data mining;Algorithm design and analysis;Blogs;Niobium,matrix algebra;natural language processing;pattern classification;text analysis,sentiment classification analysis;Turkish hotel reviews;hotel reservation site booking.com;machine learning approaches;SentiTFIDF;dictionary-based method;random forest classifier;document term matrix;term presence distribution usage;logarithmic differential term frequency,,,,,,23-Jun-16,,,IEEE,IEEE Conferences
An Empirical Study of Feature Selection for Text Categorization based on Term Weightage,基於術語權重的文本分類特徵選擇的實證研究,Bong Chih How; K. Narayanan,Universiti Malaysia Sarawak; NA,IEEE/WIC/ACM International Conference on Web Intelligence (WI'04),4-Apr-05,2004,,,599,602,"This paper proposes a local feature selection (FS) measure namely, Categorical Descriptor Term (CTD) for text categorization. It is derived based on classic term weighting scheme, TFIDF. The method explicitly chooses feature set for each category by only selecting set of terms from relevant category. Although past literatures have suggested that the use of features from irrelevant categories can improve the measure of text categorization, we believe that by incorporating only relevant feature can be highly effective. The experimental comparison is carried out between CTD and five well-known feature selection measures: Information Gain, Chi-Square, Correlation Coefficient, Odd Ratio and GSS Coefficient. The results also show that our proposed method can perform comparatively well with other FS measures, especially on collection with highly overlapped topics.",,0-7695-2100-2,10.1109/WI.2004.10060,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1410876,,Text categorization;Gain measurement;Frequency;Dictionaries;Computer science;Information technology;Performance evaluation;Natural languages;Indexing;Information retrieval,,,,9,,12,,4-Apr-05,,,IEEE,IEEE Conferences
An Insight into the Relevance of Word Ordering for Text Data Analysis,文本數據分析中單詞排序的相關性的見解,R. R. K. Menon; R. Akhil dev; S. G. Bhattathiri,"Amrita Vishwa Vidyapeetham,Department of Computer Science and Applications,Amritapuri,India; Amrita Vishwa Vidyapeetham,Department of Computer Science and Applications,Amritapuri,India; Amrita Vishwa Vidyapeetham,Department of Computer Science and Applications,Amritapuri,India",2020 Fourth International Conference on Computing Methodologies and Communication (ICCMC),23-Apr-20,2020,,,207,213,"Sentence ordering and word ordering is always remaining as a critical task for natural language processing applications. It is expected that introduction of word order information will lead to improvements in document related tasks like keyword extraction, context identification, topic analysis, intent identification, summary generation, document classification, sentiment analysis, clustering etc. In this paper, we are maintaining the structure of the document data by using various deep learning techniques. Most of the techniques can be compared on the basis of vector similarity. The proposed research work helps to improve the accuracy on the basis of the order of word occurrence. We also compare different types of word ordering techniques to maintain the structure of the document. The obtained results indicate that Doc2Vec model outperforms Tfidf model in terms of word order similarity.",,978-1-7281-4889-2,10.1109/ICCMC48092.2020.ICCMC-00040,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9076469,,,data analysis;learning (artificial intelligence);text analysis;vectors,document data;deep learning;word order similarity;text data analysis;word ordering;natural language processing;sentence ordering;vector similarity;Doc2Vec,,,,12,,23-Apr-20,,,IEEE,IEEE Conferences
Categorical term descriptor: a proposed term weighting scheme for feature selection,分類術語描述符：為特徵選擇提出的術語加權方案,Bong Chin How; N. Kulathuramaiyer; Wong Ting Kiong,"Fac. of Comput. Sci. & Inf. Technol., Universiti Malaysia, Sarawak, Malaysia; Fac. of Comput. Sci. & Inf. Technol., Universiti Malaysia, Sarawak, Malaysia; NA",The 2005 IEEE/WIC/ACM International Conference on Web Intelligence (WI'05),17-Oct-05,2005,,,313,316,"This paper proposes a term weighting scheme, categorical term descriptor (CTD), for feature selection in automated text categorization. CTD is an adaptation of the term frequency inverse document frequency (TFIDF). We compared the performance of the proposed method against classical methods such as correlation coefficient, chi-square and information gain using the multinomial naive Bayes and the support vector machine (SVKD) classifiers on the Reuters(10) and Reuters (115) variants of Reuters-21578 dataset. Despite its simplicity, CTD has proven to be promising for both local and global feature selection. CTD works best for the Reuter(10) as a stable local FS method.",,0-7695-2415-X,10.1109/WI.2005.46,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1517863,,Computer Society,text analysis;Bayes methods;support vector machines;pattern classification,categorical term descriptor;feature selection;term weighting scheme;automated text categorization;term frequency inverse document frequency;correlation coefficient;multinomial naive Bayes;support vector machine classifier;chi-square method,,,,14,,17-Oct-05,,,IEEE,IEEE Conferences
An evidential reasoning based LSA approach to document classification for knowledge acquisition,基於證據推理的LSA知識獲取文檔分類方法,R. Mohamed; J. Watada,"Graduate school of information, production and systems, Waseda University, Kitakyushu, Fukuoka, Japan; Graduate school of information, production and systems, Waseda University, Kitakyushu, Fukuoka, Japan",2010 IEEE International Conference on Industrial Engineering and Engineering Management,23-Dec-10,2010,,,1092,1096,"Web is one of major information sources. Failure in proper management of knowledge leads to incorrect results returned by search engines. Therefore, the web should have an effective information retrieval system to improve the correctness of retrieval results. This study provides a method to assign a new document to the fittest category out of predefined categories, where latent semantic analysis (LSA) is used to evaluate each term in documents, the similarity between terms and documents as well as the one between terms and categories. The objective of our method is to fuse evidential reasoning method with LSA which can assign a new document to a predefined category. The method provides better results in performance of classification comparing to the fusion of an evidential reasoning approach with term frequency inverse document frequency (TFIDF).",2157-362X,978-1-4244-8503-1,10.1109/IEEM.2010.5674188,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5674188,Evidential reasoning;knowledge management;categorization;latent semantic analysis (LSA),Cognition;Erbium;Training data;Matrix decomposition;Entropy;Semantics;Text mining,document handling;inference mechanisms;knowledge acquisition;pattern classification,evidential reasoning;latent semantic analysis;document classification;knowledge acquisition;term frequency inverse document frequency,,4,,13,,23-Dec-10,,,IEEE,IEEE Conferences
A Model for Legal Judgment Prediction Based on Multi-model Fusion,基於多模型融合的法律判決預測模型,D. Huang; W. Lin,"Fuzhou University,College of Physics & Information Engineering,Fuzhou,P.R. China; Fuzhou University,College of Physics & Information Engineering,Fuzhou,P.R. China",2019 3rd International Conference on Electronic Information Technology and Computer Engineering (EITCE),18-May-20,2019,,,892,895,"In the work of legal judgment prediction, the most common tasks are crime prediction and related law prediction. These works can be regarded as a multi-label text classification task. In order to further improve the accuracy of prediction work, this paper proposes a multi-task deep neural network classification model, named M-AttBLSTM-CNN, which based on integrating TextCNN with Att-BLSTM model to achieve high-precision prediction for crime prediction and related law prediction. Automatically extracting more rich features is the biggest feature of this model, focusing on local features while taking the full-text information into account at the same time. Firstly, according to the characteristics of the two sub-models, We combining the two sub-models in parallel to obtain more feature information. Secondly, the bidirectional LSTM and attention mechanism are also introduced in the model of this paper, which effectively alleviates the model over-fitting problem and further optimizes the model feature selection. Finally, the experiments are carried out on a judicial documents data set, which enjoys a large number of corpora up to 626,600. From experiments, the proposed model has better performance than the state-of-art text classification models including SVM-TFIDF, hierarchical attention network(HAN) and deep pyramid convolutional neural network (DPCNN).",,978-1-7281-3584-7,10.1109/EITCE47263.2019.9094946,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9094946,Legal Judgement Prediction;multi-model fusion;attention mechanism,Predictive models;Feature extraction;Law;Task analysis;Text categorization;Convolution;Machine learning,convolutional neural nets;feature extraction;law administration;learning (artificial intelligence);pattern classification;recurrent neural nets;sensor fusion;text analysis,legal judgment prediction;multimodel fusion;crime prediction;multilabel text classification task;multitask deep neural network classification model;feature selection;law prediction;M-AttBLSTM-CNN;Att-BLSTM;TextCNN;feature extraction,,,,10,,18-May-20,,,IEEE,IEEE Conferences
A Study of Chinese Document Representation and Classification with Word2vec,Word2vec的中文文檔表示與分類研究,L. Zhu; G. Wang; X. Zou,"Sch. of Comput. & Inf. Sci., Southwest Univ., Chongqing, China; Sch. of Comput. & Inf. Sci., Southwest Univ., Chongqing, China; Sch. of Comput. & Inf. Sci., Southwest Univ., Chongqing, China",2016 9th International Symposium on Computational Intelligence and Design (ISCID),26-Jan-17,2016,1,,298,302,"Word2vec is a neural network language model which can convert words and phrases into a high-quality distributed vector (called word embedding) with semantic word relationships, so it offers a unique perspective to the text classification and other natural language processing (NLP) tasks. In this paper, we propose to combine improved tfidf algorithm and word embedding as a way to represent documents and conduct text classification experiments on the Sogou Chinese classification corpus. Our results show that the combination of word embedding and improved tf-idf algorithm can outperform either individually.",2473-3547,978-1-5090-3558-8,10.1109/ISCID.2016.1075,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7830349,tf-idf;word2vec;text classification,Computational modeling;Support vector machines;Mathematical model;Neural networks;Semantics;Training;Conferences,natural language processing;neural nets;pattern classification;text analysis,Chinese document representation;Chinese document classification;Word2vec;neural network language model;high-quality distributed vector;semantic word relationships;natural language processing tasks;NLP;text classification;Sogou Chinese classification corpus;word embedding;tf-idf algorithm,,4,,28,,26-Jan-17,,,IEEE,IEEE Conferences
Relation Analysis between Speech Balloon Shapes and their Serif Descriptions in Comic,漫畫中語音氣球形狀與其襯線描述之間的關係分析,H. Tanaka; R. Yamanishi; J. Fukumoto,"Grad. Sch. of Inf. Sci. & Eng., Ritsumeikan Univ., Kusatsu, Japan; Fac. of Inf. Sci. & Eng., Ritsumeikan Univ., Kusatsu, Japan; Fac. of Inf. Sci. & Eng., Ritsumeikan Univ., Kusatsu, Japan",2015 IIAI 4th International Congress on Advanced Applied Informatics,7-Jan-16,2015,,,229,233,"Acoustic information of speech disappears in text communication. In Comic, readers can recognize nuance of character voice from speech balloon shape, which expresses characters' nuance, emotion and intention. We have developed speech balloon database from various genres of Comic magazines and analyzed speech balloon data used in character conversation expressions. We classified speech balloon types and analyzed serif descriptions using tfidf method. As an elemental study to communicate acoustic information using speech balloon shape in text communication, this paper basically studies relationships between serif description of balloon and speech balloon shape. We have extracted some typical linguistic expressions for each speech balloon type. We discussed some typical words, symbols, and expressions were strongly related with some speech balloon types.",,978-1-4799-9958-3,10.1109/IIAI-AAI.2015.235,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7373906,comic;speech balloon;serif;tf-idf,Speech;Shape;Databases;Speech recognition;Electronic mail;Explosions;Information science,data analysis;emotion recognition;text analysis,text communication;character voice;speech balloon shape;character nuance;character emotion;character intention;speech balloon database;Comic magazines;speech balloon data analysis;character conversation expressions;speech balloon type classification;serif descriptions;tf-idf method;acoustic information communication;linguistic expression extraction,,,,10,,7-Jan-16,,,IEEE,IEEE Conferences
The Determination of Cluster Number at k-Mean Using Elbow Method and Purity Evaluation on Headline News,用肘法確定k均值的簇數和頭條新聞的純度評估,D. Marutho; S. Hendra Handaka; E. Wijaya; Muljono,"Computer Science Faculty of Dian, Nuswantoro University, Semarang, Indonesia; Computer Science Faculty of Dian, Nuswantoro University, Semarang, Indonesia; Computer Science Faculty of Dian, Nuswantoro University, Semarang, Indonesia; Computer Science Faculty of Dian, Nuswantoro University, Semarang, Indonesia",2018 International Seminar on Application for Technology of Information and Communication,29-Nov-18,2018,,,533,538,"Information is one of the most important thing in our lives, while humans is naturally impatient when searching for information from the internet. Users want to get the right answer instantaneously with minimal effort. News headlines can be used to categorize news types, as appropriate. The appropriate type of news can make it easier for us to choose the particular topic we want. Similarity in a title can be used to clustering news based on news title. From those reason this dataset research contain the title of online news site. TFIDF used as Document Preprocessing method, K-Means as clustering method, and elbow method used to optimize number of cluster. Purity method applied to evaluate news title clustering as internal evaluation. SSE (Sum Square Error) of each cluster are calculate and compared to optimize number of cluster in the elbow method, the result of those comparison evaluate using internal evaluation called purity, purity value is conformity between cluster and ideal cluster. From the calculation of elbow method, the most optimal number of cluster are 8 cluster, there is 0.228 point between 7cluster and 8 cluster SSE value so the elbow form are made. Purity evaluation method generates value 0.514 in the number of cluster are 8, this is the highest value and the one closest to one rather than the other number of cluster which mean the most ideal. The conclusion is the elbow method can be used to optimize number of cluster on K-Mean clustering method.",,978-1-5386-7486-4,10.1109/ISEMANTIC.2018.8549751,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8549751,Clustering;K-Means;ElbowM ethod;Purity;Tf-idf,Elbow;Clustering algorithms;Principal component analysis;Entropy;Seminars;Clustering methods;Genetic algorithms,information retrieval;Internet;pattern clustering;text analysis,sum square error;cluster SSE value;document preprocessing method;K-mean clustering method;internal evaluation;purity method;online news site;news title;clustering news;news headlines;cluster number;purity evaluation method;optimal number;elbow method,,9,,17,,29-Nov-18,,,IEEE,IEEE Conferences
Detecting Duplicate Biological Entities Using Markov Random Field-Based Edit Distance,使用基於馬爾可夫隨機場的編輯距離檢測重複的生物實體,M. Song; A. Rudniy,"Inf. Syst., New Jersey Inst. of Technol., Newark, NJ; Comput. Sci., New Jersey Inst. of Technol., Newark, NJ",2008 IEEE International Conference on Bioinformatics and Biomedicine,21-Nov-08,2008,,,457,460,"Duplicate entities detection in biological data became a demanded research task. In this paper, we propose a novel context-sensitive Markov random field-based edit distance. We apply the Markov random field theory to Needleman-Wunsch distance and combine MRFED with TFIDF, a token-based distance algorithm (SoftMRFED). We evaluate SoftMRFED and other distance algorithms (Levenstein, SoftTFIDF, and MongeElkan) at biological entity matching and synonym matching. The experiment results show SoftMRFED significantly outperforms other distance algorithms and its performance is superior to token-based distance algorithms in two matching tasks.",,978-0-7695-3452-7,10.1109/BIBM.2008.34,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4684939,Duplicate entities detection;Edit Distance;Markov Random Field Theory,Databases;Bioinformatics;Information systems;Markov random fields;Computer science;Speech processing;Image processing;Computer vision;Cost function;Explosives,biology computing;Markov processes,biological entities;Markov random field-based edit distance;Needleman-Wunsch distance;token-based distance algorithm;biological entity matching;synonym matching,,3,,16,,21-Nov-08,,,IEEE,IEEE Conferences
An Extensive Empirical Study of Feature Selection for Text Categorization,文本分類特徵選擇的廣泛實證研究,L. Qiu; R. Zhao; G. Zhou; S. Yi,"State Key Lab. of Software Dev. Environ., Beihang Univ., Beihang; State Key Lab. of Software Dev. Environ., Beihang Univ., Beihang; State Key Lab. of Software Dev. Environ., Beihang Univ., Beihang; State Key Lab. of Software Dev. Environ., Beihang Univ., Beihang",Seventh IEEE/ACIS International Conference on Computer and Information Science (icis 2008),23-May-08,2008,,,312,315,"We present a novel feature selection (FS) approach for text categorization. It first constructs a local feature set for each category by selecting a set of features based on three different schemes: DF, TF and TFIDF, and then constructs a global feature set utilizing well-known CHI method based on the local feature set. The experimental comparison is carried out between our method and CHI method. Results from the experiments are summarized. The results show that our proposed method based on DF scheme can perform comparatively well with CHI methods.",,978-0-7695-3131-1,10.1109/ICIS.2008.49,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4529838,feature selection;Text Categorization,Text categorization;Space technology;Information science;Programming;Information analysis;Computational efficiency;Performance gain;Character generation;Frequency measurement;Gain measurement,learning (artificial intelligence);pattern classification;text analysis,feature selection;text categorization;CHI methods;local feature set,,6,,14,,23-May-08,,,IEEE,IEEE Conferences
Automated microsoft office macro malware detection using machine learning,使用機器學習自動檢測Microsoft Office宏惡意軟件,R. Bearden; D. C. Lo,"Department of Computer Science Kennesaw State University Marietta, GA, USA; Department of Computer Science Kennesaw State University Marietta, GA, USA",2017 IEEE International Conference on Big Data (Big Data),15-Jan-18,2017,,,4448,4452,"Macro malware in Microsoft (MS) Office files has long persisted as a cybersecurity threat. Though it ebbed after its initial rampages around the turn of the century, it has reemerged as threat. Attackers are taking a persuasive approach and using document engineering, aided by improved data mining methods, to make MS Office file malware appear legitimate. Recent attacks have targeted specific corporations with malicious documents containing unusually relevant information. This development undermines the ability of users to distinguish between malicious and legitimate MS Office files and intensifies the need for automating macro malware detection. This study proposes a method of classifying MS Office files containing macros as malicious or benign using the K-Nearest Neighbors machine learning algorithm, feature selection, and TFIDF where p-code opcode n-grams (translated VBA macro code) compose the file features. This study achieves a 96.3% file classification accuracy on a sample set of 40 malicious and 118 benign MS Office files containing macros, and it demonstrates the effectiveness of this approach as a potential defense against macro malware. Finally, it discusses the challenges automated macro malware detection faces and possible solutions.",,978-1-5386-2715-0,10.1109/BigData.2017.8258483,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8258483,macro;malware;Microsoft Office;machine learning;p-code,Malware;Feature extraction;Security;Machine learning algorithms;Testing;Classification algorithms,data mining;feature selection;invasive software;macros;nearest neighbour methods;pattern classification;word processing,automated microsoft office macro malware detection;Microsoft Office files;cybersecurity threat;improved data mining methods;MS Office file;malicious documents;legitimate MS Office files;automating macro malware detection;K-Nearest Neighbors machine learning algorithm;VBA macro code;document engineering,,1,,16,,15-Jan-18,,,IEEE,IEEE Conferences
Automatic text classification using modified centroid classifier,使用修改後的質心分類器進行自動文本分類,M. Elmarhumy; M. A. Fattah; F. Ren,"Faculty of Engineering University of Tokushima 2-1 Minamijosanjima Tokushima, Japan 770-8506; FIEHelwan University, Cairo, Egypt; Beijing University of Posts & Telecommunications Beijing, 100088, China",2009 International Conference on Natural Language Processing and Knowledge Engineering,6-Nov-09,2009,,,1,4,"This work proposes an approach to address the problem of inductive bias or model misfit incurred by the centroid classifier assumption to enhance the automatic text classification task. This approach is a trainable classifier, which takes into account tfidf as a text feature. The main idea of the proposed approach is to take advantage of the most similar training errors to the classification model to successively update it based on a certain threshold. The proposed approach is simple to implement and flexible. The proposed approach performance is measured at several threshold values on the Reuters -21578 text categorization test collection. The experimental results show that the proposed approach can improve the performance of centroid classifier.",,978-1-4244-4538-7,10.1109/NLPKE.2009.5313757,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5313757,Text classification;text categorization;centroid classifier;Data mining,Text categorization;Error correction;Classification tree analysis;Machine learning;Testing;Data mining;Internet;Organizing;Supervised learning;Bayesian methods,data mining;pattern classification;text analysis,automatic text classification;modified centroid classifier;text feature;text categorization;data mining,,2,,12,,6-Nov-09,,,IEEE,IEEE Conferences
Information Retrieval System in Bangla Document Ranking using Latent Semantic Indexing,使用潛在語義索引的孟加拉語文檔排名中的信息檢索系統,M. N. Hoque; R. Islam; M. S. Karim,"Science and Technology University,Dept. of Computer Science & Engineering,Gopalganj,Bangladesh,8100; Science and Technology University,Dept. of Computer Science & Engineering,Gopalganj,Bangladesh,8100; Science and Technology University,Dept. of Computer Science & Engineering,Gopalganj,Bangladesh,8100","2019 1st International Conference on Advances in Science, Engineering and Robotics Technology (ICASERT)",19-Dec-19,2019,,,1,5,"Nowadays, like the English and other languages, Bangla also plays a significant role to strengthen the web repository. The storing rate of Bangla information is augmented day-by-day. Because of the numerous documents in the World Wide Web, it is very difficult for a user to retrieve the desired information. Furthermore, finding the useful documents tends to be more time spending as well as an annoying job. These demands emerge to develop an Information Retrieval (IR) system to document ranking for Bangla language. In this paper, we have built such a retrieval system where users can find their needed documents which correspond to their own query strings throughout the ranking index. Although a lot of works have been done for English and other languages to rank the documents, unfortunately, we have found a very negligible amount of contributions in Bangla Language. Many methods such as - Boolean model, Maximal Marginal Relevance (MMR), Portfolio Theory (PR), Quantum Probability Ranking Principle (QPRP), Query Directed Clustering (QDC), Vector-based TFIDF and so on, have been proposed to implement the document ranking system. Here, we have applied a new approach, called Latent Semantic Indexing (LSI) to do the same task for Bangla documents. LSI uses the mathematical method called Singular Value Decomposition (SVD). After that, we have applied the cosine similarity to rank all the documents. We believe that the performance result of our proposed system has reached the trustworthy level.",,978-1-7281-3445-1,10.1109/ICASERT.2019.8934837,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8934837,IR;Bangla document ranking;LSI;SVD;Cosine similarity,Large scale integration;Matrix decomposition;Eigenvalues and eigenfunctions;Semantics;Indexing;Singular value decomposition;Information retrieval,indexing;Internet;natural language processing;query processing;singular value decomposition;string matching;text analysis,English language;Web repository;World Wide Web;information retrieval system;Bangla language;latent semantic indexing;Bangla document ranking system;query strings;singular value decomposition,,,,15,,19-Dec-19,,,IEEE,IEEE Conferences
Chatbot for Healthcare System Using Artificial Intelligence,使用人工智能的醫療系統聊天機器人,L. Athota; V. K. Shukla; N. Pandey; A. Rana,"Amity University,Bachelor of Science Information Technology,Dubai,UAE; Amity University,Department of Engineering and Architecture,Dubai,UAE; Amity Institute of Information Technology, Amity University,Noida,UP,India; Amity University Uttar Pradesh,AIIT,Noida,India","2020 8th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)",15-Sep-20,2020,,,619,622,"Healthcare is very important to lead a good life. However, it is very difficult to obtain the consultation with the doctor for every health problem. The idea is to create a medical chatbot using Artificial Intelligence that can diagnose the disease and provide basic details about the disease before consulting a doctor. This will help to reduce healthcare costs and improve accessibility to medical knowledge through medical chatbot. The chatbots are computer programs that use natural language to interact with users. The chatbot stores the data in the database to identify the sentence keywords and to make a query decision and answer the question. Ranking and sentence similarity calculation is performed using n-gram, TFIDF and cosine similarity. The score will be obtained for each sentence from the given input sentence and more similar sentences will be obtained for the query given. The third party, the expert program, handles the question presented to the bot that is not understood or is not present in the database.",,978-1-7281-7016-9,10.1109/ICRITO48877.2020.9197833,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9197833,Chatbot;Healthcare;Artificial Intelligence;Virtual Assistance;TFID;N-gram,Medical services;Databases;Expert systems;Feature extraction;Medical diagnostic imaging,health care;medical computing;query processing;software agents;text analysis,healthcare system;artificial intelligence;medical chatbot;healthcare costs;medical knowledge;computer programs;sentence keywords;sentence similarity calculation;ranking calculation,,,,9,,15-Sep-20,,,IEEE,IEEE Conferences
Sundanese Twitter Dataset for Emotion Classification,用於情感分類的Sundanese Twitter數據集,O. V. Putra; F. M. Wasmanson; T. Harmini; S. N. Utama,"Universitas Darussalam Gontor,Department of Informatics,Ponorogo,Indonesia; Universitas Darussalam Gontor,Department of Informatics,Ponorogo,Indonesia; Universitas Darussalam Gontor,Department of Informatics,Ponorogo,Indonesia; Universitas Darussalam Gontor,Department of Informatics,Ponorogo,Indonesia","2020 International Conference on Computer Engineering, Network, and Intelligent Multimedia (CENIM)",24-Dec-20,2020,,,391,395,"Sundanese is the second-largest tribe in Indonesia which possesses many dialects. This condition has gained attention for many researchers to analyze emotion especially on social media. However, with barely available Sundanese dataset, this condition makes understanding sundanese emotion is a challenging task. In this research, we proposed a dataset for emotion classification of Sundanese text. The preprocessing includes case folding, stopwords removal, stemming, tokenizing, and text representation. Prior to classification, for the feature generation, we utilize term frequency-inverse document frequency (TFIDF). We evaluated our dataset using k-Fold Cross Validation. Our experiments with the proposed method exhibit an effective result for machine learning classification. Furthermore, as far as we know, this is the first Sundanese emotion dataset available for public.",,978-1-7281-8283-4,10.1109/CENIM51130.2020.9297929,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9297929,emotion classification;dataset;sundanese;support vector machine;text mining,Blogs;Social networking (online);Support vector machines;Feature extraction;Radio frequency;Task analysis;Informatics,,,,,,12,,24-Dec-20,,,IEEE,IEEE Conferences
The effects of domain knowledge relations on domain text classification,領域知識關係對領域文本分類的影響,Han Lu; Yu Zhengtao; Deng Jinhui; Zhang Cheng; Mao Cunli; Guo Jianyi,"The School of Information Engineering and Automation, Kunming University of Science and Technology, 650051, China; The School of Information Engineering and Automation, Kunming University of Science and Technology, 650051, China; The School of Information Engineering and Automation, Kunming University of Science and Technology, 650051, China; The School of Information Engineering and Automation, Kunming University of Science and Technology, 650051, China; The Institute of Intelligent Information Processing, Computer Technology Application Key Laboratory of Yunnan Province, Kunming 650051, China; The School of Information Engineering and Automation, Kunming University of Science and Technology, 650051, China",2008 27th Chinese Control Conference,22-Aug-08,2008,,,460,463,"The text classification usually uses the statistical method to select characteristic. When it is carried out in different domains, the special interior knowledge relationships between domains will not be considered. In this paper, a new text classification model is proposed, which is based on the domain knowledge relations. This model adopts the support vector machine study algorithm, combine statistic samples and domain terminology to make up classification feature space, and calculate the similarity between domain conceptions, so that classification characteristic is entrusted with certain weight, realizing domain text classification. The new model has been made use of to carry out a text classification experiment about YunNan travel domain and non-travel domain. The result shows that domain knowledge has great effects on domain text classification and the accuracy of classification has been improved by 4 percentage compared with the improved TFIDF method.",2161-2927,978-7-900719-70-6,10.1109/CHICC.2008.4605079,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4605079,Domain Text Classification;Feature Selection;Domain Knowledge Relations;Weight Calculation,Text categorization;Electronic mail;Classification algorithms;Support vector machines;Terminology;Indexes;Gain,pattern classification;statistical analysis;support vector machines;text analysis,domain knowledge relations;domain text classification;statistical method;support vector machine study algorithm;statistic samples;YunNan travel domain,,,,8,,22-Aug-08,,,IEEE,IEEE Conferences
Keywords Extraction from Chinese Document Based on Complex Network Theory,基於復雜網絡理論的中文文檔關鍵詞提取,J. Nan; B. Xiao; Z. Lin; Q. Xu,"Inst. of Sensing Technol. & Bus., Beijing Univ. of Posts & Telecommun. Beijing, Beijing, China; Inst. of Sensing Technol. & Bus., Beijing Univ. of Posts & Telecommun. Beijing, Beijing, China; Inst. of Sensing Technol. & Bus., Beijing Univ. of Posts & Telecommun. Beijing, Beijing, China; Inst. of Sensing Technol. & Bus., Beijing Univ. of Posts & Telecommun. Beijing, Beijing, China",2014 Seventh International Symposium on Computational Intelligence and Design,9-Apr-15,2014,2,,383,386,"Keywords extraction is the process of choosing several words from a document to express its main idea. Keywords help people understand an article quickly and clearly. In recent years, more and more researchers pay attention to its research since its important role in text clustering, text classification, automatic abstracting, and text retrieval. This paper proposes an algorithm called EC-DC to extract keywords based on centrality measures of complex network. A document is mapped to a network with its words mapped to vertices and relations between words mapped to edges. Then, the importance of words is evaluated using eccentricity centrality and degree centrality. The most important K words are extracted as keywords. Experimental results show that the EC-DC algorithm has an improvement of about 9% in precision, recall and F-score compared to classical TFIDF algorithm.",,978-1-4799-7005-6,10.1109/ISCID.2014.183,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7082012,complex network;eccentricity centrality;degree centrality;document network;keywords extraction,Complex networks;Approximation algorithms;Semantics;Feature extraction;Business;Data mining;Internet,complex networks;feature extraction;text analysis,keywords extraction;Chinese document;complex network theory;text clustering;text classification;automatic abstracting;text retrieval;complex network centrality measures;eccentricity centrality;degree centrality;EC-DC algorithm,,2,,13,,9-Apr-15,,,IEEE,IEEE Conferences
Feature selection in Web applications by ROC inflections and powerset pruning,通過ROC變形和Powerset修剪在Web應用程序中選擇功能,F. M. Coetzee; E. Glover; S. Lawrence; C. L. Giles,"NEC Res. Inst., Princeton, NJ, USA; NA; NA; NA",Proceedings 2001 Symposium on Applications and the Internet,7-Aug-02,2001,,,5,14,"A basic problem of information processing is selecting enough features to ensure that events are accurately represented for classification problems, while simultaneously minimizing storage and processing of irrelevant or marginally important features. To address this problem, feature selection procedures perform a search through the feature power set to find the smallest subset meeting performance requirements. Major restrictions of existing procedures are that they typically explicitly or implicitly assume a fixed operating point, and make limited use of the statistical structure of the feature power set. We present a method that combines the Neyman-Pearson design procedure on finite data, with the directed set structure of the Receiver Operating Curves on the feature subsets, to determine the maximal size of the feature subsets that can be ranked in a given problem. The search can then be restricted to the smaller subsets, resulting in significant reductions in computational complexity. Optimizing the overall Receiver Operating Curve also allows for end users to select different operating points and cost functions to optimize. The algorithm also produces a natural method of Boolean representation of the minimal feature combinations that best describe the data near a given operating point. These representations are especially appropriate when describing data using common text-related features useful on the Web, such as thresholded TFIDF data. We show how to use these results to perform automatic Boolean query modification generation for distributed databases, such as niche metasearch engines.",,0-7695-0942-8,10.1109/SAINT.2001.905163,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=905163,,Information processing;Cost function;Metasearch;Engines;Indexing;National electric code;Distributed databases;Spatial databases;Computational complexity;Processor scheduling,Internet;information resources;computational complexity;information retrieval;distributed databases;search engines,feature selection;World Wide Web applications;ROC inflections;powerset pruning;information processing;classification;performance requirements;design procedure;Receiver Operating Curves;computational complexity;Boolean representation;text-related features;Boolean query modification generation;distributed databases;metasearch engines;Internet,,3,,23,,7-Aug-02,,,IEEE,IEEE Conferences
A Web Text Filter Based on Rough Set Weighted Bayesian,基於粗糙集加權貝葉斯的Web文本過濾器,Y. Wu; K. She; W. Zhu; X. Yue; H. Luo,"Sch. of Comput. Sci. & Eng., Univ. of Electron. Sci. & Technol. of China, Chengdu, China; Sch. of Comput. Sci. & Eng., Univ. of Electron. Sci. & Technol. of China, Chengdu, China; Sch. of Comput. Sci. & Eng., Univ. of Electron. Sci. & Technol. of China, Chengdu, China; Sch. of Comput. Sci. & Eng., Univ. of Electron. Sci. & Technol. of China, Chengdu, China; Sch. of Comput. Sci. & Eng., Univ. of Electron. Sci. & Technol. of China, Chengdu, China","2009 Eighth IEEE International Conference on Dependable, Autonomic and Secure Computing",15-Jan-10,2009,,,241,245,"With the deep penetration of the Internet, uncontrolled flood of information has become one of the most serious problems to Internet users. Harmful contents about pornography, violence and other illegal messages, etc have posed serious influence to the whole society, especially to the young people. In this paper, a novel Web text filter based on rough set and Bayesian theory is proposed to analysis text content of Web pages to filter harmful pages. Some of current feature selection methods such as inverse document frequency (IDF) does not take the classification information into account. To avoid this shortcoming rough set is used to reduce original feature terms. Meanwhile, a novel coefficient weighted method based on rough set is proposed and introduced into Bayesian formula, which will greatly improve filtering performance. In the final experiment, this paper compared the novel method with other weighted methods applied in Bayesian formula, such as Tf, IDF and TFIDF. The results demonstrate that this novel filter works efficiently.",,978-1-4244-5421-1,10.1109/DASC.2009.38,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5380357,web text filter;Rough set;Baysian theory,Information filtering;Information filters;Bayesian methods;Web pages;Filtering theory;Internet;Set theory;Uniform resource locators;Probability;Feature extraction,Bayes methods;information filtering;Internet;rough set theory;text analysis,Web text filter;rough set weighted Bayesian theory;Internet;Web pages;text content anaysis;feature selection methods;inverse document frequency;coefficient weighted method,,,,17,,15-Jan-10,,,IEEE,IEEE Conferences
Discourse analysis of public debates: A corpus-based approach,公眾辯論的話語分析：基於語料庫的方法,Hayeong Jeong; Tsuyoshi Hatori; Kiyoshi Kobayashi,"Department of Urban Management, Graduate School of Engineering, Kyoto University, 615-8540, Japan; Department of Civil Engineering, Tokyo Institute of Technology, 152-8552, Japan; Department of Urban Management, Graduate School of Engineering, Kyoto University, 615-8540, Japan","2007 IEEE International Conference on Systems, Man and Cybernetics",2-Jan-08,2007,,,1782,1793,"The aim of this study is to develop a computational method of discourse analysis based on corpus semantics. The objective is to achieve an accurate understanding of the debate content through the topic extraction and semantic similarity from the public debate minute corpus by using a multi-method which includes TFIDF, T-VSM, and MDS. The main issue of public debate and the inconsistency level between participants' utterance could be described by using the method. The methodology presented in this study is applied to a case example. Finally, the applicability of the proposed methodology to practical debates is discussed.",1062-922X,978-1-4244-0990-7,10.1109/ICSMC.2007.4413973,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4413973,,Cognition;Government;Context;Engineering management;Information analysis;Helium;Cultural differences;Uncertainty;Decision making;Acoustical engineering,content-based retrieval;text analysis,discourse analysis;public debates;corpus semantics;debate content;topic-based vector space model;multidimensional scaling;term frequency inverse;document frequency implementation,,5,,15,,2-Jan-08,,,IEEE,IEEE Conferences
TA-BLSTM: Tag Attention-based Bidirectional Long Short-Term Memory for Service Recommendation in Mashup Creation,TA-BLSTM：基於標記註意的雙向長期短期存儲器，用於在混搭創建中進行服務推薦,M. Shi; Y. Tang; J. Liu,"Department of Computer & Electrical Engineering and Computer Science, Florida Atlantic University, FL, 33431, USA; Department of Computer & Electrical Engineering and Computer Science, Florida Atlantic University, FL, 33431, USA; School of Computer Science and Engineering, Hunan University of Science and Technology, Xiangtan, 411201, China",2019 International Joint Conference on Neural Networks (IJCNN),30-Sep-19,2019,,,1,8,"The service-oriented architecture makes it possible for developers to create value-added Mashup applications by composing multiple available Web services. Due to the overwhelming number of Web services online, it is often hard and time-consuming for developers to find their desired ones from the entire service repository. In the past, various approaches aim at recommending Web services for automatic Mashup creation have been proposed, i.e., TFIDF, collaborative filtering and topic model-based methods, which rely on the original service descriptions given by service providers. However, most traditional methods fail to capture the function-related features of services since words contained in service descriptions usually correspond to different intent aspects (e.g., functional and non-functional related). To tackle this problem, we propose a tag attention-based recurrent neural networks model for Web service recommendation. The model consists of two Siamese bidirectional Long Short-Term Memory (LSTM) networks, which jointly learn two embeddings representing the functional features of Web services and the functional requirements of Mashups. In addition, by considering the tags of services as functional context information, the model can learn to assign attention scores to different words in service descriptions according to their intent importance, thus words used to reveal the functional properties of Web service will be given special attention. We compare our approach with the state-of-the-art methods (e.g., RTM, Word2vec, etc.) on a real-world dataset crawled from ProgrammableWeb, and the experimental results demonstrate the effectiveness of the proposed model.",2161-4407,978-1-7281-1985-4,10.1109/IJCNN.2019.8852438,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8852438,Tags;Web Services;Mashup;Recommendation;Long Short-Term Memory;Neural Network,Mashups;Quality of service;Computer architecture;Recurrent neural networks;Semantics,learning (artificial intelligence);recommender systems;recurrent neural nets;service-oriented architecture;Web services,service-oriented architecture;automatic Mashup creation;Web services;tag attention-based bidirectional long short-term memory;value-added mashup applications;tag attention-based recurrent neural network model;Siamese bidirectional long short-term memory networks;ProgrammableWeb;functional context information;Web service recommendation,,1,,27,,30-Sep-19,,,IEEE,IEEE Conferences
Tightly-coupled convolutional neural network with spatial-temporal memory for text classification,具有時空記憶的緊密耦合卷積神經網絡用於文本分類,S. Wang; Z. Deng,"State Key Laboratory of Intelligent Technology and Systems, Tsinghua National Laboratory for Information Science and Technology, Department of Computer Science, Tsinghua University Beijing 100084, China; State Key Laboratory of Intelligent Technology and Systems, Tsinghua National Laboratory for Information Science and Technology, Department of Computer Science, Tsinghua University Beijing 100084, China",2017 International Joint Conference on Neural Networks (IJCNN),3-Jul-17,2017,,,2370,2376,"Although several traditional models like bag of words (BOW), n-grams, and their variants of TFIDF exhibit high performance in the field of text classification, neural network methods such as LSTM, GRU and convolutional neural network (CNN) are recently attracting increasing attention. Considering that CNN has surprising capabilities of extracting hierarchical features, combination of LSTM/GRU with CNN seems to be quite reasonable for semantic representation and sequence analysis. On the other hand, it is also a promising subject to enable CNN to have memory embeddings and/or recurrent pathway. In this paper, we propose a novel tightly-coupled convolutional neural network with spatial-temporal memory (TCNN-SM). It comprises feature-representation and memory functional columns. Feature-representation functional column in our TCNN-SM actually performs hierarchical feature extraction as regular CNN does while memory functional column retains memories of different granularity and fulfills selective memory for historical information. In order to validate effectiveness and efficiency of the proposed TCNN-SM, we conduct extensive experiments on AG's News public dataset. The experimental results show that our new TCNN-SM achieves 7.99% test error, which has the best performance among other existing deep learning methods and is very close to state of the art results yielded using classical n-grams algorithm.",2161-4407,978-1-5090-6182-2,10.1109/IJCNN.2017.7966143,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7966143,,Feature extraction;Data mining;Recurrent neural networks;Semantics;Machine learning;Training,convolution;feature extraction;learning (artificial intelligence);natural language processing;neural nets;pattern classification;semantic networks;text analysis,spatial-temporal memory;SM;text classification;semantic representation;sequence analysis;tightly coupled convolutional neural network;TCNN;feature representation;memory functional columns;hierarchical feature extraction;deep learning;n-grams algorithm,,1,,34,,3-Jul-17,,,IEEE,IEEE Conferences
Significant term extraction by Higher Order SVD,通過高階SVD提取重要術語,S. Manna; Z. Petres; T. Gedeon,"Department of Computer Science, The Australian National University, ACT 0200, Australia; Department of Computer Science, The Australian National University, ACT 0200, Australia; Department of Computer Science, The Australian National University, ACT 0200, Australia",2009 7th International Symposium on Applied Machine Intelligence and Informatics,19-May-09,2009,,,63,68,"In this paper, we present a novel method for term importance, called tensor term indexing (TTI). This extracts significant terms from a document as well as a coherent collection of document set. The basic idea of this approach is to represent the whole document collection in a term-sentence-document tensor and employs higher-order singular value decomposition (HOSVD) for important term extraction. TTI uses the lower rank approximation technique to reduce noise by eliminating anecdotal terms, to mitigate synonymy by merging the dimensions associated with terms that have similar meanings, and to mitigates polysemy, since components of polysemous words that point in the ldquorightrdquo direction are added to the components of words that share a similar meaning. Our evaluation shows that that TTI model can extract significant terms relevant to a topic from a small number of documents which term frequency and inverse document frequency (tfidf) cannot.",,978-1-4244-3801-3,10.1109/SAMI.2009.4956610,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4956610,,Frequency;Indexing;Data mining;Information retrieval;Tensile stress;Computer science;Automation;Databases;Singular value decomposition;Law,approximation theory;document handling;indexing;information retrieval;singular value decomposition,significant term extraction;higher order singular value decomposition;tensor term indexing;term sentence document tensor;rank approximation technique;term frequency;inverse document frequency,,2,,24,,19-May-09,,,IEEE,IEEE Conferences
PerKey: A Persian News Corpus for Keyphrase Extraction and Generation,PerKey：用於提取和生成關鍵字的波斯新聞語料庫,E. Doostmohammadi; M. H. Bokaei; H. Sameti,"Computational Linguistics Group, Sharif University of Technology, Tehran, Iran; Information Technology Department, ICT Research Institute, Tehran, Iran; Computer Engineering Department, Sharif University of Technology, Tehran, Iran",2018 9th International Symposium on Telecommunications (IST),7-Mar-19,2018,,,460,465,"Keyphrases provide an extremely dense summary of a text. Such information can be used in many Natural Language Processing tasks, such as information retrieval and text summarization. Since previous studies on Persian keyword or keyphrase extraction have not published their data, the field suffers from the lack of a human extracted keyphrase dataset. In this paper, we introduce PerKey1, a corpus of 553k news articles from six Persian news websites and agencies with relatively high quality author extracted keyphrases, which is then filtered and cleaned to achieve higher quality keyphrases. The resulted data was put into human assessment to ensure the quality of the keyphrases. We also measured the performance of different supervised and unsupervised techniques, e.g. TFIDF, MultipartiteRank, KEA, etc. on the dataset using precision, recall, and F1-score.",,978-1-5386-8274-6,10.1109/ISTEL.2018.8661095,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8661095,Keyphrase Extraction;Keyword Extraction;Persian news corpus;supervised Keyphrase Extraction;unsupervised Keyphrase Extraction,Data mining;Natural language processing;Task analysis;Training;Feature extraction;Information retrieval;Cleaning,information retrieval;natural language processing;text analysis,PerKey;Persian news corpus;keyphrase extraction;extremely dense summary;Natural Language Processing tasks;information retrieval;Persian keyword;human extracted keyphrase dataset;relatively high quality author;Persian news Web sites;news articles;high-quality keyphrases;F1-score,,1,,24,,7-Mar-19,,,IEEE,IEEE Conferences
Feature subset selection for Arabic document categorization using BPSO-KNN,使用BPSO-KNN進行阿拉伯文檔分類的特徵子集選擇,H. K. Chantar; D. W. Corne,"School of Mathematical and Computer Sciences, Heriot-Watt University, EDINBURGH, UK; School of Mathematical and Computer Sciences, Heriot-Watt University, EDINBURGH, UK",2011 Third World Congress on Nature and Biologically Inspired Computing,1-Dec-11,2011,,,546,551,"Document categorization is an important topic that is central to many applications that demand reasoning about and organisation of text documents, web pages, and so forth. Document classification is commonly achieved by choosing appropriate features (terms) and building a term-frequency inerse-document frequency (TFIDF) feature vector. In this process, feature selection is a key factor in the accuracy and effectiveness of resulting classifications. For a given task, the right choice of features means accurate classification with suitable levels of computational efficiency. Meanwhile, most document classification work is based on English language documents. In this paper we make three main contributions: (i) we demonstrate successful document classification in the context of Arabic documents (although previous work has demonstrated text classification in Arabic, the datasets used, and the experimental setup, have not been revealed); (ii) we offer our datasets to enable other researchers to compare directly with our results; (iii) we demonstrate a combination of Binary PSO and K nearest neighbour that performs well in selecting good sets of features for this task.",,978-1-4577-1124-4,10.1109/NaBIC.2011.6089647,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6089647,feature selection;text mining;Arabic language processing,Accuracy;Training;Support vector machines;Text categorization;Vectors;Particle swarm optimization;Art,feature extraction;text analysis,feature subset selection;Arabic document categorization;text documents;Web pages;Document classification;term frequency inerse document frequency;feature vector;English language documents,,17,,25,,1-Dec-11,,,IEEE,IEEE Conferences
Machine Learning Methods for Medical Text Categorization,用於醫學文本分類的機器學習方法,Q. Zhang; J. Tan; H. Zhou; W. Tao; K. He,"Coll. of Med. Inf. Eng., Guangdong Pharm. Univ., Guangzhou, China; NA; Coll. of Med. Inf. Eng., Guangdong Pharm. Univ., Guangzhou, China; Coll. of Med. Inf. Eng., Guangdong Pharm. Univ., Guangzhou, China; NA","2009 Pacific-Asia Conference on Circuits, Communications and Systems",4-Sep-09,2009,,,494,497,"This paper reports a comparative study for medical text categorizations on four machine learning methods: k nearest neighbor (kNN), support vector machines (SVM), naive Bayes (NB) and clonal selection algorithm based on antibody density (CSABAD). CSABAD is an improved immune algorithm proposed by us. According to the clonal selection principle and density control mechanism, only those cells that have higher affinity and lower density are selected to proliferate. In addition, we propose an improved approach, called term frequency, inverted document frequency and inverted entropy (TFIDFIE), to compute term weights in document indexing. It considers the distribution of documents in the training set in which the term occurs. Our experiments show that SVM and CSABAD outperform significantly kNN and naive Bayes, and TFIDFIE is more effective than TFIDF on OHSCAL data set.",,978-0-7695-3614-9,10.1109/PACCS.2009.156,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5232395,medical text categorization;machine learning;immune algorithm;document indexing,Learning systems;Text categorization;Support vector machines;Machine learning algorithms;Frequency;Nearest neighbor searches;Niobium;Immune system;Entropy;Indexing,document handling;indexing;learning (artificial intelligence);medical computing;support vector machines;text analysis,medical text categorization;machine learning methods;k nearest neighbor;support vector machines;naive Bayes;clonal selection algorithm;antibody density;improved immune algorithm;density control mechanism;term frequency;inverted document frequency;inverted entropy;document indexing,,4,,14,,4-Sep-09,,,IEEE,IEEE Conferences
Experiments in text-based mining and analysis of biological information from MEDLINE on functionally-related genes,基於文本的挖掘和MEDLINE功能相關基因生物學信息分析實驗,N. Moon; R. Singh,"Dept. of Comput. Sci., San Francisco State Univ., CA, USA; Dept. of Comput. Sci., San Francisco State Univ., CA, USA",18th International Conference on Systems Engineering (ICSEng'05),27-Dec-05,2005,,,326,331,"Technological advancements such as microarrays have enabled biologists to generate unprecedented quantities of data about biological entities. This has lead to the development of a large number of algorithms for processing and analysis of biological data. Challenges however remain; for instance, genes that function cooperatively need not have similar expression patterns. This suggests the use of non-numerical sources of information to explore the underlying biology. We experimentally study various factors that are inherent in algorithmic methodologies for text analysis. The proposed method accesses MEDLINE dynamically to account for the latest research, with the available literature corresponding to the genes analyzed to develop lists of keywords. Natural language processing (NLP) techniques such as stop-word filtering and stemming are then applied to the lists, and keyword frequencies weighted using the term frequency-inverse document frequency (TFIDF) scheme. The results are input to a hierarchical clustering algorithm to derive groupings of genes by functionality. The process is repeated using z-score weighting and latent semantic analysis (LSA) to determine which yields the most accurate clustering. The study presented examines the importance of these steps and their influence on the overall efficacy of the system. We believe that the analysis conducted as part of this research is invaluable to development and fine-timing of text mining methodologies for biological literature.",,0-7695-2359-5,10.1109/ICSENG.2005.41,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1562873,,Data mining;Information analysis;Frequency;Data analysis;Algorithm design and analysis;Information resources;Text analysis;Natural language processing;Filtering;Clustering algorithms,biology computing;medical information systems;data analysis;natural languages;text analysis;pattern clustering;genetics;word processing;data mining;scientific information systems,text-based mining;biological information analysis;MEDLINE;functionally-related genes;technological advancement;microarray;biological entity;biological data processing algorithm;biological data analysis;gene expression pattern;biology;text analysis;gene analysis;natural language processing;stop-word filtering;stemming;keyword frequency;term frequency-inverse document frequency;hierarchical clustering;gene groupings;z-score weighting;latent semantic analysis;LSA;text mining;biological literature,,,,17,,27-Dec-05,,,IEEE,IEEE Conferences
A scoring method of XML fragments considering query-oriented statistics,考慮面向查詢的統計信息的XML片段評分方法,A. Keyaki; K. Hatano; J. Miyazaki,"Faculty of Culture and Information Science, Doshisha University, 1-3 Tatara-Miyakodani, Kyotanabe, Kyoto 610-0394, Japan; Faculty of Culture and Information Science, Doshisha University, 1-3 Tatara-Miyakodani, Kyotanabe, Kyoto 610-0394, Japan; Graduate School of Information Science, Nara Institute of Science and Technology, 8916-5 Takayama, Ikoma, 630-0192, Japan",2009 Second International Conference on the Applications of Digital Information and Web Technologies,2-Oct-09,2009,,,456,461,"In this paper, we propose a scoring method for searching XML fragments related with user's information need. In conventional XML fragment retrieval systems, the term-weighting schemes based on traditional information retrieval techniques are usually used directly for scoring retrieved XML fragments. However, we believe that retrieved XML fragments should be scored considering not only traditional retrieved-document-oriented statistics like the tfidf scoring but also query-oriented ones such as constituent rate of query keywords and statistics of the query results, so that it remains possible that such techniques will help the conventional XML fragment retrieval systems to improve their relevances. Our experimental results show that our method considering query conditions is more effective for searching XML fragments correctly than conventional approaches.",,978-1-4244-4456-4,10.1109/ICADIWT.2009.5273901,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5273901,,XML;Statistics;Search engines;Information retrieval;Web search;Information science;Data mining;Proposals,query processing;search engines;statistical analysis;XML,scoring method;XML fragment searching;query-oriented statistics;XML fragment retrieval system,,,,14,,2-Oct-09,,,IEEE,IEEE Conferences
Feature Selection For Text Categorisation Using Self-organising Map,使用自組織映射的文本分類功能選擇,P. Manomaisupat,"Department of Computing University of Surrey, Guildford, Surrey GU2 7XH. E-mail: csplpm@surrey.ac.uk",2005 International Conference on Neural Networks and Brain,10-Apr-06,2005,3,,1875,1880,"The categorisation of documents in large diverse collections poses a keen problem. The choice of a vector that may represent a document collection, and categories of documents within, is still an art form. We describe a study where four different types of term occurrence and document frequency metrices have been used with varying levels of success measured by classification accuracy statistics and average quantization error; TFIDF and its variant, term relevance, have been used together with a metric based on contrastive linguistics and another uses a finely-classified terminology data base. A novel method of term representation has been used - each element of the vector corresponds to the absence/presence of a set terms colocated within the element on the basis of frequency. In addition, we have defined a new baseline for comparison - a randomly selected set of terms for constructing a representative vector from within the collection. Categorisation was performed using the classic self-organising maps. We confirm that there is an optimum size of the input vector-c.100-200 terms- exists for each of the term-occurrence/document frequency metrices, and there appears to be a saturation point beyond that optimal limit",,0-7803-9422-4,10.1109/ICNNB.2005.1614991,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1614991,,Text categorization;Filtering;Routing;Frequency measurement;Quantization;Art;Error analysis;Terminology;Computer science;Thesauri,information filtering;pattern classification;self-organising feature maps;support vector machines;text analysis,feature selection;text categorisation;self-organising map;document categorisation;classification accuracy statistics;average quantization error,,1,,11,,10-Apr-06,,,IEEE,IEEE Conferences
Machine learning tool and meta-heuristic based on genetic algorithms for plagiarism detection over mail service,基於遺傳算法的機器學習工具和基於啟發式的郵件啟發式檢測,H. A. Bouarara; A. Rahmani; R. M. Hamou; A. Amine,"GeCode Laboratory, Department of Computer Science, Tahar Moulay University of Saida Algeria; GeCode Laboratory, Department of Computer Science, Tahar Moulay University of Saida Algeria; GeCode Laboratory, Department of Computer Science, Tahar Moulay University of Saida Algeria; GeCode Laboratory, Department of Computer Science, Tahar Moulay University of Saida Algeria",2014 IEEE/ACIS 13th International Conference on Computer and Information Science (ICIS),29-Sep-14,2014,,,157,162,"One of the most modern problems that computer science try to resolve is the plagiarism, in this article we present a new approach for automatic plagiarism detection in world of mail service. Our system is based on the n-gram character for the representation of the texts and tfidf as weighting to calculate the importance of term in the corpus, we use also a combination between the machine learning methods as a way to detect if a document is plagiarized or not, we use pan 09 corpus for the construction and evaluation of the prediction model then we simulate a meta-heuristic method based on genetic algorithms with a variations of parameters to know if it can improve the results. The main objective of our work is to protect intellectual property and improve the efficiency of plagiarism detection system.",,978-1-4799-4860-4,10.1109/ICIS.2014.6912125,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6912125,Plagiarism Detective;Machine Learning;Email Service;Meta-heuristics,Plagiarism;Electronic mail;Servers;Entropy;Genetic algorithms;Detectors;Classification algorithms,copyright;electronic mail;genetic algorithms;learning (artificial intelligence);text analysis,plagiarized document detection;text representation;automatic plagiarism detection;Email Service;genetic algorithms;meta-heuristic;machine learning tool,,16,,20,,29-Sep-14,,,IEEE,IEEE Conferences
Sentiment Analysis and Classification for Software as a Service Reviews,軟件即服務評論的情感分析和分類,A. M. Alkalbani; A. M. Ghamry; F. K. Hussain; O. K. Hussain,"Sch. of Software, Univ. of Technol. Sydney, Sydney, NSW, Australia; Sch. of Bus., Univ. of New South Wales Canberra (UNSW Canberra), Canberra, ACT, Australia; Sch. of Software, Univ. of Technol. Sydney, Sydney, NSW, Australia; Sch. of Bus., Univ. of New South Wales Canberra (UNSW Canberra), Canberra, ACT, Australia",2016 IEEE 30th International Conference on Advanced Information Networking and Applications (AINA),23-May-16,2016,,,53,58,"With the rapid growth of cloud services, there has been a significant increase in the number of online consumer reviews and opinions on these services on different social media platforms. These reviews are a source of valuable information in regard to cloud market position and cloud consumer satisfaction. This study explores cloud consumers' reviews that reflect the user's experience with Software as a Service (SaaS) applications. The reviews were collected from different web portals, and around 4000 online reviews were analysed using sentiment analysis to identify the polarity of each review, that is, whether the sentiment being expressed is positive, negative, or neutral. Also, this research develops a model for predicting the sentiment of Software as a Service consumers' reviews using a supervised learning machine called a support vector machine (SVM). The sentiment results show that 62% of the reviews are positive which indicates that consumers are most likely satisfied with SaaS services. The results show that the prediction accuracy of the SVM-based Binary Occurrence approach (3-fold crossvalidation testing) is 92.30%, indicating it performs better in determining sentiment compared with other approaches (Term Occurrences, TFIDF). This work also provides valuable insight into online SaaS reviews and offers the research community the first SaaS polarity dataset.",1550-445X,978-1-5090-1858-1,10.1109/AINA.2016.148,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7474069,SaaS reviews;sentiment analysis;sentiment classification;supervised machine learning;SaaS polarity dataset,Cloud computing;Sentiment analysis;Software as a service;Support vector machines;Data mining;Portals,classification;cloud computing;consumer behaviour;customer satisfaction;learning (artificial intelligence);portals;sentiment analysis;social networking (online);support vector machines,sentiment analysis;sentiment classification;software as a service;cloud services;online consumer reviews;social media;cloud market position;cloud consumer satisfaction;SaaS;Web portals;supervised learning machine;support vector machine;SVM;binary occurrence approach,,6,,28,,23-May-16,,,IEEE,IEEE Conferences
An empirical analysis of Combined Dissimilarity Spaces,組合相異空間的經驗分析,L. V. N. Lapenda; R. H. W. Pinheiro; G. D. C. Cavalcanti,"Centro de Inform獺tica (CIn), Universidade Federal de Pernambuco (UFPE), Brazil; Centro de Ci礙ncias e Tecnologia (CCT), Universidade Federal do Cariri (UFCA), Brazil; Centro de Inform獺tica (CIn), Universidade Federal de Pernambuco (UFPE), Brazil",2018 International Joint Conference on Neural Networks (IJCNN),14-Oct-18,2018,,,1,8,"Text categorization can be applied in many areas, such as Business Intelligence, sentiment analysis, social network monitoring, and security. Considering textual analysis techniques' wide applications, it is important to improve these techniques to obtain more precise and reliable results. Combined Dissimilarity Spaces (CoDiS) model implements a system for text categorization with multiple classifiers trained on different dissimilarity spaces, aiming to overcome Bag-of-Words' limitations. This study evaluates CoDiS performance when applying some parametric variations, such as the classifier, the data input format, and the dissimilarity measure. Macro F1 and Micro F1 are used to evaluate the performance, and the results show a significant difference among different configurations tested on CoDiS. Based on the statistical tests' results, it is possible to conclude that the best scenario is to apply TFIDF to represent the datasets, Cosine as the dissimilarity measure, and SVM as the classifier. This scenario also outperformed literature multiple classifier systems: Bagging and Random Subspace.",2161-4407,978-1-5090-6014-6,10.1109/IJCNN.2018.8489287,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8489287,,Training;Support vector machines;Prototypes;Feature extraction;Text categorization;Bagging;Testing,pattern classification;statistical testing;support vector machines;text analysis,CoDiS performance;dissimilarity measure;Macro F1;statistical tests;literature multiple classifier systems;text categorization;Business Intelligence;sentiment analysis;social network monitoring;textual analysis techniques;multiple classifiers;dissimilarity spaces;Bag-of-Words limitations;Combined Dissimilarity Spaces model,,,,19,,14-Oct-18,,,IEEE,IEEE Conferences
Study on the construction of domain text classification model with the help of domain knowledge,借助領域知識構建領域文本分類模型的研究,Zheng-Tao Yu; Lu Han; Cun-Li Mao; Jian-Yi Guo; Xiang-Yan Meng; Zhi-Kun Zhang,"The School of Information Engineering and Automation, Kunming University of Science and Technology, 650051, China; The School of Information Engineering and Automation, Kunming University of Science and Technology, 650051, China; The Institute of Intelligent Information Processing, Computer Technology Application Key Laboratory of Yunnan Province, Kunming, 650051, China; The School of Information Engineering and Automation, Kunming University of Science and Technology, 650051, China; The School of Information Engineering and Automation, Kunming University of Science and Technology, 650051, China; The School of Information Engineering and Automation, Kunming University of Science and Technology, 650051, China",2008 International Conference on Machine Learning and Cybernetics,5-Sep-08,2008,5,,2612,2617,"Traditional text classification model uses statistical methods to obtain features. But in the aspect of discrimination domain and non-domain text category, domain knowledge relations havenpsilat been taken account of in these methods. A domain text classification model was presented in this paper. This model used the support vector machine learning algorithm, gained domain classification feature words through statistic and union domain words, structured domain classification feature space. With the help of domain knowledge relations, computed relevance between domain concepts, got domain classification feature weight. Finally domain text classification was realized. An experiment in the Yunnan tourism domain was carried on to confirm that domain knowledge relations have a good influence on the domain text classification. The classification accuracy rate has been increased 0.04 than improved TFIDF method.",2160-1348,978-1-4244-2095-7,10.1109/ICMLC.2008.4620849,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4620849,Text classification;Feature selection;Domain knowledge Relations,Text categorization;Accuracy;Frequency domain analysis;Support vector machine classification;Rivers;Classification algorithms;Support vector machines,pattern classification;statistical analysis;support vector machines;text analysis,domain text classification model;domain knowledge;statistical methods;support vector machine learning algorithm;union domain words;structured domain classification feature space;Yunnan tourism domain,,,,8,,5-Sep-08,,,IEEE,IEEE Conferences
SentenceRank ??A graph based approach to summarize text,SentenceRank一種基於圖的方法來匯總文本,A. Ramesh; K. G. Srinivasa; N. Pramod,"Department of CSE, MSRIT, Bangalore; Department of CSE, MSRIT, Bangalore; Application Developer, ThoughtWorks",The Fifth International Conference on the Applications of Digital Information and Web Technologies (ICADIWT 2014),15-May-14,2014,,,177,182,"We introduce a graph and an intersection based technique which uses statistical and semantic analysis for computing relative importance of textual units in large data sets in order to summarize text. Current implementations consider only the mathematical/statistical approach to summarize text. (like frequency, TFIDF, etc.) But there are many cases where two completely different textual units might be semantically related. We hope to overcome this problem by exploiting the resources of WordNet and by the use of semantic graphs which represents the semantic dissimilarity between any pair of sentences. Ranking is usually performed on statistical information. The algorithm constructs semantic graphs using implicit links which are based on the semantic relatedness between text nodes and consequently ranks nodes using a ranking algorithm.",,978-1-4799-2259-8,10.1109/ICADIWT.2014.6814680,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6814680,,Semantics;Hurricanes;Silicon;Wind;Vectors;Algorithm design and analysis;Storms,graph theory;mathematical analysis;statistical analysis;text analysis,SentenceRank;graph based approach;text summarization;intersection based technique;statistical analysis;semantic analysis;textual units;mathematical approach;WordNet resources;semantic graphs;semantic dissimilarity;statistical information;semantic relatedness;text nodes;ranking algorithm,,7,,15,,15-May-14,,,IEEE,IEEE Conferences
Visualization and Integration of Databases Using Self-Organizing Map,使用自組織映射的數據庫可視化和集成,F. Bourennani; K. Q. Pu; Y. Zhu,"Univ. of Ontario Inst. of Technol., Oshawa, ON; Univ. of Ontario Inst. of Technol., Oshawa, ON; Univ. of Ontario Inst. of Technol., Oshawa, ON","2009 First International Confernce on Advances in Databases, Knowledge, and Data Applications",12-Jun-09,2009,,,155,160,"With the growing computer networks, accessible data is becoming increasingly distributed. Understanding and integrating remote and unfamiliar data sources are important data management issues. In this paper, we propose to utilize self-organizing maps (SOM) clustering to aid with the visualization of similar columns, and integration of relational database tables and attributes based on the content. In order to accommodate heterogeneous data types found in relational databases, we extended the TFIDF measure to handle, in addition to text, numerical attribute types for coincident meaning extraction. We present a SOM clustering based visualization algorithm allowing the user to browse the heterogeneously typed database attributes and discover semantically similar clusters. Additionally, we propose a new algorithm Common Item Based Classifier (CIBC) to smoothen the homogeneity of the clusters obtained by SOM. The discovered semantic clusters can significantly aid in manual or automated constructions of data integrity constraints in data cleaning or schema mappings in data integration.",,978-1-4244-3467-1,10.1109/DBKDA.2009.30,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5071828,SOM;Common Item Based Classifier (CIBC);Data Integration;Information Retrieval (IR),Visual databases;Data visualization;Distributed databases;Clustering algorithms;Relational databases;Self organizing feature maps;Data mining;Information retrieval;Application software;Computer network management,data integrity;data mining;data visualisation;distributed databases;pattern classification;pattern clustering;query processing;relational databases;self-organising feature maps,data visualization algorithm;self-organizing map clustering;relational database table;heterogeneous data type;distributed database browsing;common item based classifier algorithm;data integrity constraint;numerical data mining,,4,,15,,12-Jun-09,,,IEEE,IEEE Conferences
Automatic extraction of malicious behaviors,自動提取惡意行為,K. Dam; T. Touili,"IRIF, University Paris Diderot and CNRS; LIPN, CNRS and University Paris 13",2016 11th International Conference on Malicious and Unwanted Software (MALWARE),30-Mar-17,2016,,,1,10,"The number of new malwares is increasing everyday. Thus malware detection is nowadays a big challenge. The existing techniques for malware detection require a huge effort of engineering to manually extract the malicious behaviors. To avoid this tedious task, we propose in this paper an approach to automatically extract the malicious behaviors. We model a program using an API call graph, and we represent the malicious behaviors using a malicious API graph. We then reduce the malicious behavior extraction problem to the problem of retrieving from the benign and malicious API call graphs the set of subgraphs that are relevant for malicious behaviors. We solve this issue by applying and adapting well-known efficient Information Retrieval techniques based on the TFIDF scheme. We use our automatically extracted malicious behavior specification for malware detection using a kind of product between graphs. We obtained interesting experimental results, as we get 99.04% of detection rate. Moreover, we were able to detect several malwares that well-known and widely used antiviruses such as Panda, Avira, Kaspersky, Avast, Qihoo- 360, McAfee, AVG, BitDefender, ESET-NOD32, F-Secure, and Symantec could not detect.",,978-1-5090-4542-6,10.1109/MALWARE.2016.7888729,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7888729,,Malware;Binary codes;Information retrieval;Image edge detection;Databases;Data mining;Robustness,application program interfaces;graph theory;invasive software,automatic extraction;malware detection;API;malicious behavior extraction;malicious API call graphs;information retrieval techniques,,2,,37,,30-Mar-17,,,IEEE,IEEE Conferences
Semantic Subspace Learning with conditional significance vectors,具有條件重要性向量的語義子空間學習,N. Tripathi; S. Wermter; C. Hung; M. Oakes,"Department of Computing, Engineering and Technology, University of Sunderland, St Peters Way, SR6 0DD, United Kingdom; Institute for Knowledge Technology, Department of Computer Science, University of Hamburg, Vogt Koelln, Str. 30, 22527, Germany; Department of Information Management, Chung Yuan Christian University, Chung-Li, Taiwan 32023 R.O.C.; Department of Computing, Engineering and Technology, University of Sunderland, St Peters Way, SR6 0DD, United Kingdom",The 2010 International Joint Conference on Neural Networks (IJCNN),14-Oct-10,2010,,,1,8,Subspace detection and processing is receiving more attention nowadays as a method to speed up search and reduce processing overload. Subspace Learning algorithms try to detect low dimensional subspaces in the data which minimize the intra-class separation while maximizing the inter-class separation. In this paper we present a novel technique using the maximum significance value to detect a semantic subspace. We further modify the document vector using conditional significance to represent the subspace. This enhances the distinction between classes within the subspace. We compare our method against TFIDF with PCA and show that it consistently outperforms the baseline with a large margin when tested with a wide variety of learning algorithms. Our results show that the combination of subspace detection and conditional significance vectors improves subspace learning.,2161-4407,978-1-4244-6918-5,10.1109/IJCNN.2010.5596640,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5596640,,Classification algorithms;Semantics;Training;Support vector machine classification;Principal component analysis;Prediction algorithms;Testing,learning (artificial intelligence);vectors,semantic subspace learning;conditional significance vector;subspace detection;subspace processing;maximum significance value;document vector,,3,,24,,14-Oct-10,,,IEEE,IEEE Conferences
"Semi-automatic, data-driven construction of multimedia ontologies",半自動，數據驅動的多媒體本體構建,A. Jaimes; J. R. Smith,"Dept. of Electr. Eng., Columbia Univ., New York, NY, USA; NA",2003 International Conference on Multimedia and Expo. ICME '03. Proceedings (Cat. No.03TH8698),18-Aug-03,2003,1,,I,781,"In this paper we investigate semi-automatic construction of multimedia ontologies using a data-driven approach. We start with a collection of videos for which we wish to build an ontology (an explicit specification of a domain). Each video is pre-processed: scene cut detection, automatic speech recognition (ASR), and metadata extraction are performed. In addition we automatically index the videos based on visual content by extracting syntactic (e.g., color, texture, etc.) and semantic features (e.g., face, landscape, etc.). We then combine standard tools for ontology engineering and tools in content-based retrieval to semi-automatically build ontologies. In the first stage we process the text information available with the videos (ASR, metadata, and annotations, if any). Stop words (e.g., a, on, the) are eliminated and statistics (e.g., frequency, TFIDF, and entropy) are computed for all terms. Based on this data we manually select concepts and relationships to include in the ontology. Then we use content-based retrieval tools to assign multimedia entities (e.g., shots, videos, collections of videos) to concepts, properties, or relationships in the ontology, and to select multimedia entities as concepts, relationships, or properties in the ontology. We explore this methodology to construct multimedia ontologies from 24 hours of educational films from the 1940s-1960s used in the TREC video retrieval benchmark and discuss the problems encountered and future directions.",,0-7803-7965-9,10.1109/ICME.2003.1221034,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1221034,,Ontologies;Videos;Automatic speech recognition;Content based retrieval;Layout;Data mining;Face detection;Statistics;Frequency;Entropy,multimedia systems;video signal processing;speech recognition;meta data;feature extraction;indexing;image retrieval;content-based retrieval;statistics,multimedia ontologies;data-driven approach;scene cut detection;automatic speech recognition;metadata extraction;features extraction;content-based retrieval;text information;statistics;TREC video retrieval benchmark;video indexing;visual content,,31,,15,,18-Aug-03,,,IEEE,IEEE Conferences
CRNN: A Joint Neural Network for Redundancy Detection,CRNN：用於冗餘檢測的聯合神經網絡,X. Fu; E. Ch'ng; U. Aickelin; S. See,"Univ. of Nottingham, Ningbo, China; Univ. of Nottingham, Ningbo, China; Univ. of Nottingham, Ningbo, China; Nvidia Technol. Center, Nvidia, Japan",2017 IEEE International Conference on Smart Computing (SMARTCOMP),15-Jun-17,2017,,,1,8,"This paper proposes a novel framework for detecting redundancy in supervised sentence categorisation. Unlike traditional singleton neural network, our model incorporates character- aware convolutional neural network (Char-CNN) with character-aware recurrent neural network (Char-RNN) to form a convolutional recurrent neural network (CRNN). Our model benefits from Char-CNN in that only salient features are selected and fed into the integrated Char-RNN. Char-RNN effectively learns long sequence semantics via sophisticated update mechanism. We compare our framework against the state-of-the- art text classification algorithms on four popular benchmarking corpus. For instance, our model achieves competing precision rate, recall ratio, and F1 score on the Google-news data-set. For twenty- news-groups data stream, our algorithm obtains the optimum on precision rate, recall ratio, and F1 score. For Brown Corpus, our framework obtains the best F1 score and almost equivalent precision rate and recall ratio over the top competitor. For the question classification collection, CRNN produces the optimal recall rate and F1 score and comparable precision rate. We also analyse three different RNN hidden recurrent cells' impact on performance and their runtime efficiency. We observe that MGU achieves the optimal runtime and comparable performance against GRU and LSTM. For TFIDF based algorithms, we experiment with word2vec, GloVe, and sent2vec embeddings and report their performance differences.",,978-1-5090-6517-2,10.1109/SMARTCOMP.2017.7946996,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7946996,,Logic gates;Training;Redundancy;Recurrent neural networks;Benchmark testing;Computational modeling,convolution;feature selection;pattern classification;recurrent neural nets;text analysis,CRNN;redundancy detection;supervised sentence categorisation;character-aware convolutional neural network;char-CNN;character-aware recurrent neural network;char-RNN;convolutional recurrent neural network;salient features selection;sequence semantics;precision rate;recall ratio;F1 score;Google-news data-set;news-groups data stream;Brown Corpus;sentence classification,,8,,32,,15-Jun-17,,,IEEE,IEEE Conferences
"Mining Student Feedback to Improve the Quality of Higher Education through Multi Label Classification, Sentiment Analysis, and Trend Topic",通過多標籤分類，情感分析和趨勢主題挖掘學生反饋以提高高等教育質量,C. Alencia Hariyani; A. Nizar Hidayanto; N. Fitriah; Z. Abidin; T. Wati,"Universitas Indonesia,Fakultas Ilmu Komputer; Universitas Indonesia,Fakultas Ilmu Komputer; Universitas Indonesia,Fakultas Ilmu Komputer; Universitas Indonesia,Fakultas Ilmu Komputer; UPN ?Veteran??Jakarta,Fakultas Ilmu Komputer,Jakarta,Indonesia","2019 4th International Conference on Information Technology, Information Systems and Electrical Engineering (ICITISEE)",2-Apr-20,2019,,,359,364,"This research carried out the label aspect classification, sentiment analysis, and topic trends on the Open-Ended Question (OEQ) section for Student Feedback Questionnaire (SFQ). Multi-Class aspect label classification for SFQ will choose the best classification model by comparing the results of the evaluation of accuracy, precision, recall, and Flscore for each feature combination and comparison of four classification algorithms namely Decision Tree (DT), Naive Bayes (NB), K-Nearest Neighbor (KNN), and Support Vector Machine (SVM). The results of this research are Classification Techniques using a combination of features of TFIDF, Unigranb and Bigram with the SVM algorithm which is the best Multi-Class classification model for labeling SFQ aspects. In addition, the SentiStrenghtID algorithm used to get sentiments and also the LDA (Latent Dirichlet Allocation) used to get annual topic trends on each survey aspect label. The findings can help Higher Education to support decision making in taking proactive actions towards improvement for self-evaluation and quality.",,978-1-7281-5118-2,10.1109/ICITISEE48480.2019.9003818,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9003818,Classification;Education Data Mining;Higher Education;Multi Label Classification;Sentiment Analysis;Student Feedback;Survey;Trend Topic,,Bayes methods;computer aided instruction;data mining;decision making;decision trees;further education;learning (artificial intelligence);nearest neighbour methods;pattern classification;support vector machines;Web sites,support vector machine;classification techniques;SVM algorithm;multiclass classification model;SFQ aspects;SentiStrenghtID algorithm;annual topic trends;survey aspect label;higher education;student feedback;multilabel classification;sentiment analysis;trend topic;label aspect classification;feature combination;classification algorithms;multiclass aspect label classification;student feedback questionnaire;open-ended question section,,,,20,,2-Apr-20,,,IEEE,IEEE Conferences
Hot keyword identification for extracting web public opinion,熱門關鍵詞識別提取網絡輿情,Z. Fang; Y. Ning; T. Zhu,"National Computer System Engineering Research Institute of China, Beijing 100083, China; Graduate University of Chinese Academy of Sciences Beijing 100190, China; Graduate University of Chinese Academy of Sciences Beijing 100190, China",5th International Conference on Pervasive Computing and Applications,28-Jan-11,2010,,,116,121,"Internet is becoming an increasingly important platform for ordinary life and work. It is expected that keyword extraction can help people quickly find hot spots on the web, since keywords in a document provide important information about the content of the document. In this paper, we propose to use text clustering method based on semi-supervised learning to get focuses of social topics in a large amount of text. We develop a novel keyword extraction method named NATF-PDF, which is based on TFPDF algorithm, combined with supervised learning theory for keyword extraction. We compare its performance with TFIDF in comparison, and the results show that our method get better accuracy and recall ratio.",,978-1-4244-9143-8,10.1109/ICPCA.2010.5704085,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5704085,Keyword Extraction;Semi-supervised learning;Clustering;NATF-PDF,Feature extraction;Clustering algorithms;Data mining;Mathematical model;Equations;Accuracy;Semantics,information retrieval;Internet;learning (artificial intelligence);text analysis,hot keyword identification;Web public opinion extraction;Internet;text clustering method;semi-supervised learning;keyword extraction method;NATF-PDF;TFPDF algorithm;supervised learning theory,,1,,13,,28-Jan-11,,,IEEE,IEEE Conferences
Machine Learning for Predicting Stock Market Movement using News Headlines,使用新聞頭條預測股票市場走勢的機器學習,Y. Liu; J. Trajkovic; H. -G. H. Yeh; W. Zhang,"California State University,Department of Computer Engineering and Computer Science,Long Beach,CA,90840; California State University,Department of Computer Engineering and Computer Science,Long Beach,CA,90840; California State University,Department of Electrical Engineering,Long Beach,CA,90840; California State University,Department of Computer Engineering and Computer Science,Long Beach,CA,90840",2020 IEEE Green Energy and Smart Systems Conference (IGESSC),11-Dec-20,2020,,,1,6,"There are many factors that affect performance of stock market, such as global and local economy, political events, supply and demand, and out of the ordinary events, as COVID-19 pandemic. The factors may not only influence the stock market movement, but also influence each other. We propose to observe the movement of Dow Jones Industrial Average in relations to daily news. We use top-5 news headlines from Reddit to create 1Day and 5-Day models to predict if Dow Jones Industrial Average movement will be in Down and Up direction from the moment the market opens till it closes. We propose use of shallow (traditional) Machine Learning algorithms and Deep Learning algorithms. Additionally, we explore the effect of word representation, using TF-IDF and GloVE approaches. Moreover, we evaluate our models in terms of accuracy of prediction on data sets containing data before pandemic and during pandemic. Our models show that Deep Learning models uniformly have higher accuracy than Machine Learning ones. Convolution Neural Network with TFIDF and 5 Days prediction performs the best for the dataset before the pandemic with accuracy of 59.6%. Gated Recurrent Unit (GRU), a class of Recurrent Neural Networks, with GloVe and 1 Day prediction outperforms the other models for dataset during the pandemic with the accuracy of 62.9%.",2640-0138,978-1-7281-8744-0,10.1109/IGESSC50231.2020.9285163,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9285163,Stock Movement;Text Classification;Text Mining;Machine Learning;Deep Learning,Deep learning;Machine learning algorithms;Supply and demand;Pandemics;Biological system modeling;Predictive models;Stock markets,,,,,,33,,11-Dec-20,,,IEEE,IEEE Conferences
On Learning Researchers' Dynamic Information Needs: An Entropy-Based Query Expansion Approach,學習研究人員的動態信息需求：基於熵的查詢擴展方法,I. Wu; C. Lin; G. Chen; Y. Lin,"Dept. of Inf. Manage., Fu-Jen Catholic Univ., Taipei, Taiwan; Dept. of Comput. Sci., Nat. Tsing Hua Univ., Hsinchu, Taiwan; Dept. of Inf. Manage., Fu-Jen Catholic Univ., Taipei, Taiwan; Dept. of Inf. Manage., Fu-Jen Catholic Univ., Taipei, Taiwan",2012 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology,2-May-13,2012,3,,200,204,"Literature survey is one of the most important steps in the process of academic research, allowing researchers to explore and understand topics. However, researchers without sufficient prior knowledge lack the skills to determine proper and accurate keywords for investigating the topics at hand. To tackle this problem, we proposed an entropy-based query expansion with a reweigh ting (E_QE) approach to revise queries during the iterative retrieval process. We designed a series of experiments that consider the researcher's changing information needs during task execution. Two topic change situations are considered in this work癒Xboth minor, and dramatic topic changes. The simulation-based pseudo-relevance feedback technique is applied during the search process to evaluate the effectiveness of the proposed approach without the intervention of human efforts. We measured the effectiveness of the TFIDF and E_QE approaches for different types of topic change situations. The preliminary results show that the proposed query expansion approach can achieve better results, helping researchers to revise queries.",,978-1-4673-6057-9,10.1109/WI-IAT.2012.35,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6511677,entropy;query expansion;pseudo-relevance feedback;topic change,,information needs;query processing,dynamic information needs;entropy based query expansion;academic research;iterative retrieval process;dramatic topic changes;pseudo relevance feedback;search process,,,,7,,2-May-13,,,IEEE,IEEE Conferences
Using Burstiness to Improve Clustering of Topics in News Streams,利用突發性來改善新聞流中的主題聚類,Q. He; K. Chang; E. Lim,"Nanyang Technol. Univ., Nanyang Avenue; Nanyang Technol. Univ., Nanyang Avenue; Nanyang Technol. Univ., Nanyang Avenue",Seventh IEEE International Conference on Data Mining (ICDM 2007),12-Mar-08,2007,,,493,498,"Specialists who analyze online news have a hard time separating the wheat from the chaff. Moreover, automatic data-mining techniques like clustering of news streams into topical groups can fully recover the underlying true class labels of data if and only if all classes are well separated. In reality, especially for news streams, this is clearly not the case. The question to ask is thus this: if we cannot recover the full C classes by clustering, what is the largest K < C clusters we can find that best resemble the K underlying classes? Using the intuition that bursty topics are more likely to correspond to important events that are of interest to analysts, we propose several new bursty vector space models (B-VSM)for representing a news document. B-VSM takes into account the burstiness (across the full corpus and whole duration) of each constituent word in a document at the time of publication. We benchmarked our B-VSM against the classical TFIDF-VSM on the task of clustering a collection of news stream articles with known topic labels. Experimental results show that B-VSM was able to find the burstiest clusters/topics. Further, it also significantly improved the recall and precision for the top K clusters/topics.",2374-8486,978-0-7695-3018-5,10.1109/ICDM.2007.17,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4470279,,Nominations and elections;Data mining;Helium;Data engineering;Functional analysis;Organizing;Clustering methods;Telecommunication traffic,data mining;document handling;information resources;media streaming,burstiness;topics clustering;online news analysis;automatic data mining;news stream clustering;bursty topics;bursty vector space model;news document representation;news stream article;topic label,,25,,25,,12-Mar-08,,,IEEE,IEEE Conferences
Semantic feature reduction in chinese document clustering,中文文檔聚類中的語義特徵約簡,Xianjun Meng; Qingcai Chen; Xiaolong Wang,"ICRC Lab, Shenzhen Graduate School, Harbin Institute of Technology, China; ICRC Lab, Shenzhen Graduate School, Harbin Institute of Technology, China; ICRC Lab, Shenzhen Graduate School, Harbin Institute of Technology, China","2008 IEEE International Conference on Systems, Man and Cybernetics",7-Apr-09,2008,,,3721,3726,"Text clustering techniques were usually used to structure the text documents into topic related groups which can facilitate users to get a comprehensive understanding on corpus or results from information retrieval system. Most of existing text clustering algorithm which derived from traditional formatted data clustering heavily rely on term analysis methods and adopted vector space model (VSM) as their document representation. But because of the essential characteristic underlying text such as high dimensionality features vector space, the problem of sparseness has a strong impact on the clustering algorithm. So feature reduction is an important preprocess step for improving the efficiency and accuracy of clustering algorithm by removing redundant and irrelevant terms from corpus. Even the clustering is considered as an unsupervised learning method, but in text, there is still some priori knowledge we can use from NLP analysis based approach. In this paper, we propose a semantic analysis based feature reduction method which used in Chinese text clustering. Our method bases on a dedicated Part-of-Speech tags selection and synonyms consolidation and can reduce the feature space of documents more effectively compared with traditional feature reduction method tfidf and stopwords removal; meanwhile it preserves or sometimes even improves the accuracy of clustering algorithm. In our experiment, we tested our feature reduction method using bisecting k-means algorithm which was proved be efficient in text clustering. The results show that our method can reduce the feature space significantly, and meanwhile have a better clustering accuracy in terms of the purity.",1062-922X,978-1-4244-2383-5,10.1109/ICSMC.2008.4811878,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4811878,text clustering;feature selection;part-of-speech;synonym,Clustering algorithms;Information retrieval;Unsupervised learning;Functional analysis;Algorithm design and analysis;Testing;Text mining;Navigation;Search engines;Clustering methods,information retrieval;natural language processing;text analysis;unsupervised learning,semantic feature reduction;Chinese document clustering;text clustering;information retrieval system;term analysis;vector space model;document representation;unsupervised learning;natural language processing;part-of-speech tags,,2,,27,,7-Apr-09,,,IEEE,IEEE Conferences
Cognitive location-aware information retrieval by agent-based semantic matching,通過基於代理的語義匹配進行認知位置感知信息檢索,E. C. L. Chan; G. Baciu; S. C. Mak,"Department of Computing, The Hong Kong Polytechnic University, Hung Hom, Kowloon, China; Department of Computing, The Hong Kong Polytechnic University, Hung Hom, Kowloon, China; Department of Computing, The Hong Kong Polytechnic University, Hung Hom, Kowloon, China",2009 8th IEEE International Conference on Cognitive Informatics,18-Sep-09,2009,,,435,440,"Agents operating in both wired and wireless networks find and retrieve location-aware information. Agents in our system are required to endow with the full range of cognitive abilities, including perception, use of natural language, learning and the ability to understand the user query. The speed and accuracy of retrieval and the usefulness of the retrieved data depends on a number of factors including constant or frequent changes in its content or status, the effects of environmental factors such as the weather and traffic and the techniques that are used to categorize the relevance of the retrieved data. In this paper, we propose semantic TFIDF, an agent-based system for retrieving location-aware information that can improves the speed of retrieval while maintaining or even improving the accuracy by making use of semantic information in the data to develop smaller training sets. In our method, intelligent agents first gather location-aware data and then, using semantic graphs in the WordNet English dictionary, they classify, match and organize the information to find a best match for a user query. Our experiments compared our proposed system with three other commonly used systems and showed it to be significantly faster and more accurate.",,978-1-4244-4642-1,10.1109/COGINF.2009.5250701,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5250701,Information Retreival;Semantic;Agent;Locationaware,Information retrieval;Computer networks;Content based retrieval;Dictionaries;Wireless networks;Natural languages;Environmental factors;Intelligent agent;Data mining;Databases,cognitive systems;information retrieval;mobile computing;multi-agent systems;natural languages,cognitive location-aware information retrieval;agent-based semantic matching;natural language;environmental factors effects;WordNet English dictionary;semantic graphs,,1,,20,,18-Sep-09,,,IEEE,IEEE Conferences
Document Retrieval Using Deep Learning,使用深度學習進行文檔檢索,S. Choudhary; H. Guttikonda; D. R. Chowdhury; G. P. Learmonth,"University of Virginia,School of Data Science,Charlottesville,VA; University of Virginia,School of Data Science,Charlottesville,VA; University of Virginia,School of Data Science,Charlottesville,VA; University of Virginia,School of Data Science,Charlottesville,VA",2020 Systems and Information Engineering Design Symposium (SIEDS),2-Jun-20,2020,,,1,6,"Document Retrieval has seen significant advancements in the last few decades. Latest developments in Natural Language Processing have made it possible to incorporate context and complex lexical patterns to document representations. This opens new possibilities for developing advanced retrieval systems. Traditional approaches for indexing documents suggest averaging word and sentence encoding to form fixed-length document embeddings. However, the common bag-of-word approach fails to incorporate the semantic context, which can be critical for understanding document-query relevancy. We address this by leveraging Bidirectional Encoder Representations from Transformers (BERT) to create semantically rich document embeddings. BERT compensates the limitations of the Term Frequency Inverse Document Frequency (TF-IDF) by incorporating contextual embeddings. In this paper, we propose an ensemble of BERT and TF-IDF for a document retrieval system, where TFIDF and BERT together score the documents against a query, to retrieve a final set of top K documents. We critically compare our model against the standard TF-IDF method and demonstrate a significant performance improvement on MS MARCO data (Microsoft-curated data of Bing queries).",,978-1-7281-7145-6,10.1109/SIEDS49339.2020.9106632,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9106632,information retrieval;bert;tf-idf;query expansion,,learning (artificial intelligence);natural language processing;neural nets;query processing;text analysis,deep learning;natural language processing;context patterns;lexical patterns;document-query relevancy;bidirectional encoder representations;BERT;term frequency inverse document frequency;TF-IDF;document retrieval system;document embeddings,,,,17,,2-Jun-20,,,IEEE,IEEE Conferences
Surveying public opinion using label prediction on social media data,使用標籤預測對社交媒體數據進行民意調查,M. Stanojevic; J. Alshehri; Z. Obradovic,"Center for Data Analytics and Biomedical Informatics, Temple University,Philadelphia,PA,USA; Center for Data Analytics and Biomedical Informatics, Temple University,Philadelphia,PA,USA; Center for Data Analytics and Biomedical Informatics, Temple University,Philadelphia,PA,USA",2019 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM),23-Apr-20,2019,,,188,195,"In this study, a procedure is proposed for surveying public opinion from big social media domain-specific textual data to minimize the difficulties associated with modeling public behavior. Strategies for labeling posts relevant to a topic are discussed. A two-part framework is proposed in which semiautomatic labeling is applied to a small subset of posts, referred to as the ?seed??in further text. This seed is used as bases for semi-supervised labeling of the rest of the data. The hypothesis is that the proposed method will achieve better labeling performance than existing classification models when applied to small amounts of labeled data. The seed is labeled using posts of users with a known and consistent view on the topic. A semi-supervised multi-class prediction model labels the remaining data iteratively. In each iteration, it adds context-label pairs to the training set if softmax-based label probabilities are above the threshold. The proposed method is characterized on four datasets by comparison to the three popular text modeling algorithms (n-grams + tfidf, fastText, VDCNN) for different sizes of labeled seeds (5,000 and 50,000 posts) and for several label-prediction significance thresholds. Our proposed semi-supervised method outperformed alternative algorithms by capturing additional contexts from the unlabeled data. The accuracy of the algorithm was increasing by (3-10%) when using a larger fraction of data as the seed. For the smaller seed, lower label probability threshold was clearly a better choice, while for larger seeds no predominant threshold was observed. The proposed framework, using fastText library for efficient text classification and representation learning, achieved the best results for a smaller seed, while VDCNN wrapped in the proposed framework achieved the best results for the bigger seed. The performance was negatively influenced by the number of classes. Finally, the model was applied to characterize a biased dataset of opinions related to gun control/rights advocacy. The proposed semi-automatic seed labeling is used to label 8,448 twitter posts of 171 advocates for guns control/rights. On this application, our approach performed better than existing models and it achieves 96.5% accuracy and 0.68 F1 score.",2473-991X,978-1-4503-6868-1,10.1145/3341161.3342861,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9073509,semi-supervised;label prediction;social media,Labeling;Social network services;Data models;Predictive models;Mathematical model;Training;Organizations,convolutional neural nets;data mining;pattern classification;sentiment analysis;social networking (online);supervised learning,public opinion;label prediction;social media data;semiautomatic labeling;context-label pairs;softmax-based label probabilities;labeled seeds;text classification;representation learning;semiautomatic seed labeling;Twitter posts;semisupervised multiclass prediction model labels;fastText library;convolutional neural networks,,,,30,,23-Apr-20,,,IEEE,IEEE Conferences
Vilokana - Lightweight COVID19 Document Analysis,Vilokana-輕量級COVID19文檔分析,S. Panja; A. K. Maan; A. P. James,"Indian Institute of Information Technology and Management,School of Electronics,Kerala; Indian Institute of Information Technology and Management,School of Electronics,Kerala; Indian Institute of Information Technology and Management,School of Electronics,Kerala",2020 IEEE 63rd International Midwest Symposium on Circuits and Systems (MWSCAS),2-Sep-20,2020,,,500,504,"An increase in the scientific literature related to COVID19 makes searching for scientific information a challenging task. In this paper, we present the implementation of a semantic search engine targeted at COVID19 research articles. The algorithm uses a modified Term Frequency-Inverse Document Frequency (TFIDF) features and cosine similarity with ontology maps for semantic search. The implementation includes sentiment analysis, keyword extraction, keyword-based search, phrase extraction, textual belief indication, and text summary. The system is lightweight and can be deployed as a standalone system on mobile devices. The analysis reported in the work is based on data from 50k research articles related to COVID19 research. The tool also assists the researchers to upload their own text or documents for performing analysis. The comparisons with state of the art algorithms such as BERT and Word2Vec indicate improved performance.",1558-3899,978-1-7281-8058-8,10.1109/MWSCAS48704.2020.9184598,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9184598,COVID19;document analysis;TF-IDF;sentiment;semantic analysis,Semantics;Search engines;Keyword search;Text analysis;Databases;Bit error rate;Metasearch,medical computing;mobile computing;ontologies (artificial intelligence);query formulation;search engines;sentiment analysis,textual belief indication;semantic search engine;COVID19 research articles;term frequency inverse document frequency;ontology maps;sentiment analysis;keyword extraction;keyword based search;phrase extraction;COVID19 document analysis;Vilokana;cosine similarity;text summary;mobile devices;information search,,,,31,,2-Sep-20,,,IEEE,IEEE Conferences
Term Weighting Schemes for Emerging Event Detection,新興事件檢測的術語加權方案,Y. Rao; Q. Li,"Dept. of Comput. Sci., City Univ. of Hong Kong, Hong Kong, China; Dept. of Comput. Sci., City Univ. of Hong Kong, Hong Kong, China",2012 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology,2-May-13,2012,1,,105,112,"As an event-based task, Emerging Event Detection (EED) faces the problems of multiple events on the same subject and the evolution of events. Current term weighting schemes for EED exploiting Named Entity, temporal information and Topic Modeling all have their limited utility. In this paper, a new term weighting scheme, which models the sparse aspect, global weight and local weight of each story, is proposed. Then, an unsupervised algorithm based on the new scheme is applied to EED. We evaluate our approach on two datasets from TDT5, and compare it with TFIDF and existing two schemes exploiting Topic Modeling. Experiments on Retrospective and On-line EED show that our scheme yields better results.",,978-1-4673-6057-9,10.1109/WI-IAT.2012.66,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6511872,emerging event detection;latent dirichlet allocation;synonymous;polysemous,,algorithm theory;temporal logic,term weighting schemes;emerging event detection;event based task;named entity;topic modeling;unsupervised algorithm;online EED,,5,,25,,2-May-13,,,IEEE,IEEE Conferences
